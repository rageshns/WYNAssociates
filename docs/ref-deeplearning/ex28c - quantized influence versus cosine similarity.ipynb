{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Quantized Influence versus Cosine Similarity\n",
        "\n",
        "Let's break down the tasks you've outlined, starting with writing the formulas for `quantized_influence()` and `cosine_similarity()` in LaTeX, and then moving on to the mathematical discussion and comparison.\n",
        "\n"
      ],
      "metadata": {
        "id": "osUyjs7aSH9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formulas in LaTeX\n",
        "\n",
        "#### Quantized Influence\n",
        "\n",
        "The `quantized_influence()` function computes a measure based on the difference in local averages from the global average of `arr2_4bit`, weighted by the square of the count of elements in each partition and normalized by the standard deviation of `arr2_4bit`. The formula for the quantized influence can be expressed as follows:\n",
        "\n",
        "$$ \\text{Quantized Influence} = \\frac{\\sum_{i=1}^{n} \\left( \\overline{y}_{\\text{local}, i} - \\overline{y}_{\\text{global}} \\right)^2 \\cdot N_i^2}{n \\cdot \\sigma_{\\text{arr2_4bit}}} $$\n",
        "\n",
        "Where:\n",
        "- $\\overline{y}_{\\text{local}, i}$ is the local average of `arr2_4bit` for the $i^{th}$ unique value in `arr1_4bit`.\n",
        "- $\\overline{y}_{\\text{global}}$ is the global average of `arr2_4bit`.\n",
        "- $N_i$ is the count of elements in `arr2_4bit` that correspond to the $i^{th}$ unique value in `arr1_4bit`.\n",
        "- $\\sigma_{\\text{arr2\\_4bit}}$ is the standard deviation of `arr2_4bit`.\n",
        "- $n$ is the total number of unique values in `arr1_4bit`.\n",
        "\n",
        "#### Cosine Similarity\n",
        "\n",
        "The `cosine_similarity()` function calculates the cosine of the angle between two vectors (arrays). The formula for cosine similarity is:\n",
        "\n",
        "$$ \\text{Cosine Similarity} = \\frac{\\vec{a} \\cdot \\vec{b}}{\\| \\vec{a} \\| \\cdot \\| \\vec{b} \\|} $$\n",
        "\n",
        "Where:\n",
        "- $\\vec{a}$ and $\\vec{b}$ are the vectors corresponding to `arr1` and `arr2`, respectively.\n",
        "- $\\| \\vec{a} \\|$ and $\\| \\vec{b} \\|$ are the Euclidean norms (magnitudes) of vectors $\\vec{a}$ and $\\vec{b}$, respectively.\n",
        "\n",
        "### Mathematical Discussion and Comparison\n",
        "\n",
        "Now, to discuss and prove the effect of the term $(N_i^2$ in the `quantized_influence()` formula on making its measure exponentially higher than the `cosine_similarity()`, especially as the numerical measure gets higher, we will focus on the impact of this term.\n",
        "\n",
        "The $N_i^2$ term in the `quantized_influence()` formula significantly increases the influence of partitions with more elements. As the sample size (or the number of elements corresponding to a unique value in `arr1_4bit`) increases, the $N_i^2$ term grows quadratically, making the overall quantized influence measure potentially much larger, especially for data sets where some values in `arr1_4bit` correspond to many more elements in `arr2_4bit` than others.\n",
        "\n",
        "#### Proving the Exponential Increase\n",
        "\n",
        "To illustrate the exponential increase and compare the two measures, let's consider the scenario where the sample size goes to infinity. We'll simplify the scenario to focus on the effect of the $N_i^2$ term. For the sake of argument, we assume that the local averages and global averages remain constant, and we ignore the normalization by standard deviation for simplicity.\n",
        "\n",
        "For `quantized_influence()`, as $N_i$ increases, the term $N_i^2$ will dominate the measure, causing it to increase quadratically.\n",
        "\n",
        "For `cosine_similarity()`, the measure is bounded between -1 and 1, as it is a ratio involving dot products and magnitudes of vectors, which do not increase quadratically with the size of the data.\n",
        "\n",
        "To formally compare them, one might look at the ratio or difference of these measures as the size of the dataset increases. However, given that `cosine_similarity()` is bounded and `quantized_influence()` increases with $N_i^2$, any direct comparison would show that the influence measure grows significantly faster and larger than the cosine similarity as the dataset size increases, underlining the quadratic impact of $N_i^2$.\n",
        "\n",
        "This demonstrates conceptually why the `quantized_influence()` measure could exponentially exceed `cosine_similarity()` as numerical measures get higher, particularly due to the quadratic growth contributed by the $N_i^2$ term. A formal proof would involve defining specific behaviors for the averages and distributions of `arr1` and `arr2`, which goes beyond this conceptual explanation."
      ],
      "metadata": {
        "id": "DKWcjkk-UclZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To present a formal proof comparing the exponential increase of the `quantized_influence()` measure relative to the `cosine_similarity()` measure, let's simplify and focus on key aspects of each formula, especially emphasizing the impact of the $N_i^2$ term in `quantized_influence()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "83rkB8vFSzIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assumptions\n",
        "\n",
        "1. The `cosine_similarity()` is bounded between $[-1, 1]$ due to its definition.\n",
        "2. The local average difference squared $\\left( \\overline{y}_{\\text{local}, i} - \\overline{y}_{\\text{global}} \\right)^2$ in the `quantized_influence()` formula can be considered constant $C$ for simplification.\n",
        "3. $N_i$ represents the size of partitions, and we let it approach infinity to analyze the impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "iiSUUWe_Um42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective\n",
        "\n",
        "Show that as $N_i$ (the size of partitions in `arr2_4bit` for each unique value in `arr1_4bit`) approaches infinity, the `quantized_influence()` measure increases at a rate that is significantly higher than any possible value of `cosine_similarity()`.\n",
        "\n"
      ],
      "metadata": {
        "id": "GHzASq99UosL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formulation\n",
        "\n",
        "Given the simplified `quantized_influence()` formula without normalization by standard deviation for illustration:\n",
        "\n",
        "$$ \\text{Quantized Influence} = \\frac{\\sum_{i=1}^{n} C \\cdot N_i^2}{n} $$\n",
        "\n",
        "Assuming $C$ is constant and ignoring the division by $n$ for the moment, the dominant term as $N_i$ grows is $N_i^2$.\n",
        "\n"
      ],
      "metadata": {
        "id": "ck3HC6CtUpdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proof\n",
        "\n",
        "For `cosine_similarity()`, the maximum value as $N \\rightarrow \\infty$ remains 1 (or -1 for inverse direction), which can be represented as:\n",
        "\n",
        "$$ \\lim_{N \\rightarrow \\infty} \\text{Cosine Similarity} = 1 $$\n",
        "\n",
        "For `quantized_influence()`, as $N_i$ increases:\n",
        "\n",
        "$$ \\lim_{N_i \\rightarrow \\infty} \\text{Quantized Influence} = \\lim_{N_i \\rightarrow \\infty} C \\cdot N_i^2 $$\n",
        "\n",
        "Since $C$ is a positive constant and $N_i^2$ increases quadratically:\n",
        "\n",
        "$$ \\lim_{N_i \\rightarrow \\infty} C \\cdot N_i^2 = \\infty $$\n",
        "\n"
      ],
      "metadata": {
        "id": "tdcbaPpQUqXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "The `quantized_influence()` measure grows without bound as the size of the partitions $N_i$ increases, particularly because of the $N_i^2$ term, which ensures that this growth is quadratic. In contrast, `cosine_similarity()` is inherently limited to a maximum value of 1, regardless of the size of the input vectors.\n",
        "\n",
        "This demonstrates that as the partition sizes $N_i$ increase, the difference between the `quantized_influence()` measure and the `cosine_similarity()` measure not only grows but does so in a manner that can be considered exponential due to the quadratic factor of $N_i^2$. Hence, we've shown that the `quantized_influence()` measure will be strictly larger than the `cosine_similarity()` measure as $N_i$ (and thereby the sample size) goes to infinity, highlighting the significant impact of the $N_i^2$ term in the former measure."
      ],
      "metadata": {
        "id": "GQ5N9fGOUrlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "lEAB1kPvaoTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JCp9T7vVUjg4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fake Data"
      ],
      "metadata": {
        "id": "uDUN5yhdaphT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "# labels\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "metadata": {
        "id": "zlnYs_paXr5b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define `soft_quantized_influence_measure`"
      ],
      "metadata": {
        "id": "WGlwRLwmaq3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customized `categorical_crossentropy`"
      ],
      "metadata": {
        "id": "H4Rk831aR-iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_categorical_crossentropy(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Custom implementation of the categorical crossentropy loss function.\n",
        "\n",
        "    Args:\n",
        "    - y_true: tf.Tensor. The true labels, one-hot encoded.\n",
        "    - y_pred: tf.Tensor. The predicted probabilities.\n",
        "\n",
        "    Returns:\n",
        "    - tf.Tensor: The categorical crossentropy loss.\n",
        "    \"\"\"\n",
        "    # Ensure y_pred is clipped to prevent log(0) which is undefined\n",
        "    epsilon = tf.keras.backend.epsilon()\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "    # Calculate the categorical crossentropy loss\n",
        "    loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "qH8xblWA62zT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `qim` function"
      ],
      "metadata": {
        "id": "HFYJNWhrSB3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_quantized_influence_measure(y_pred: tf.Tensor, y_true: tf.Tensor, threshold: float = 0.5) -> float:\n",
        "    \"\"\"\n",
        "    Calculates a custom loss measure that takes into account the mean squared error (MSE)\n",
        "    between predictions and true values, adjusted by a threshold for soft quantization.\n",
        "\n",
        "    Args:\n",
        "    - y_pred: tf.Tensor. The predicted values by the model.\n",
        "    - y_true: tf.Tensor. The true values.\n",
        "    - threshold: float. The threshold used to determine the categorization of errors.\n",
        "\n",
        "    Returns:\n",
        "    - float: The computed custom loss as a numerical value.\n",
        "    \"\"\"\n",
        "    # Ensure y_pred is clipped to prevent log(0) which is undefined\n",
        "    epsilon = tf.keras.backend.epsilon()\n",
        "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "    # Flatten the tensors\n",
        "    y_pred_flat = tf.reshape(y_pred, [-1])\n",
        "    y_true_flat = tf.reshape(y_true, [-1])\n",
        "\n",
        "    # Ensure predictions and true values are in float format\n",
        "    arr1 = tf.cast(y_pred_flat, dtype=tf.float32)\n",
        "    arr2 = tf.cast(y_true_flat, dtype=tf.float32)\n",
        "\n",
        "    # Calculate the mean and standard deviation of the true values\n",
        "    y_global_mean = tf.reduce_mean(arr2)\n",
        "    y_std = tf.math.reduce_std(arr2)\n",
        "\n",
        "    # Sort predictions in descending order and apply the same order to true values\n",
        "    sorted_indices = tf.argsort(arr1, direction='DESCENDING')\n",
        "    sorted_arr1 = tf.gather(arr1, sorted_indices)\n",
        "    sorted_arr2 = tf.gather(arr2, sorted_indices)\n",
        "\n",
        "    # Check if MSE is within the threshold, indicating small or large error\n",
        "    pi_1 = sorted_arr1 <= threshold\n",
        "    pi_2 = sorted_arr1 > threshold\n",
        "\n",
        "    # Count occurrences of small and large errors\n",
        "    n1 = tf.reduce_sum(tf.cast(pi_1, tf.float32))  # Small errors count\n",
        "    n2 = tf.reduce_sum(tf.cast(pi_2, tf.float32))  # Large errors count\n",
        "    N = n1 + n2\n",
        "\n",
        "    # Weight errors based on their classification and counts\n",
        "    local_mean_true = tf.reduce_mean(tf.where(pi_1, arr2, 0))\n",
        "    local_mean_false = tf.reduce_mean(tf.where(pi_2, arr2, 0))\n",
        "    true_error_loss = tf.square(arr1 - local_mean_true) * n1 ** 2\n",
        "    false_error_loss = tf.square(arr1 - local_mean_false) * n2 ** 2\n",
        "\n",
        "    # Conditionally apply weights and normalize the loss by the variance of true values\n",
        "    final = true_error_loss + false_error_loss\n",
        "    final_loss = final / (tf.square(y_std) ** 2) / N\n",
        "\n",
        "    # Convert the final tensor loss to a numerical value and return\n",
        "    final_loss = -tf.math.log(final_loss)\n",
        "\n",
        "    # Convert the final tensor loss to a numerical value and return\n",
        "    return final_loss\n",
        "\n",
        "def qim(threshold: float = 0.5) -> callable:\n",
        "    return lambda y_pred, y_true: soft_quantized_influence_measure(y_pred, y_true, threshold)"
      ],
      "metadata": {
        "id": "aKqHH-vDYR8d"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUKTqJjwYOmV"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "Let's build a simple model and train using a built-in loss function like the `mean_squared_error`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile and fit model\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "history0 = model.fit(xs, ys, epochs=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrM141zeZlcl",
        "outputId": "264c6477-4f63-4b46-93fd-9f03feaaf577"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 810ms/step - loss: 51.8292\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.1777\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 32.7894\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 26.1818\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.9754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile and fit model\n",
        "model.compile(optimizer='sgd', loss=qim(0.6))\n",
        "history1 = model.fit(xs, ys, epochs=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiUdP4l3Zm2D",
        "outputId": "103634a3-b611-4f55-8a1a-ef6bc511d991"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 385ms/step - loss: 2.0703\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2009\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3639\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3351\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Training Loss"
      ],
      "metadata": {
        "id": "431wYvb_auyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history0.history['loss'])\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.legend(['MSE', 'Soft QIM'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "StCG6c_lZpvE",
        "outputId": "2d396164-07b5-4ca4-c491-c4ff2b2945ed"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x78747b3bcf10>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test on the `MNIST` Dataset"
      ],
      "metadata": {
        "id": "MXZ4HUG-b6GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "OosKbNUGb8QO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the input data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqcoQuWqcrFi",
        "outputId": "146ab67c-d296-44ee-ed2d-7391635aadd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a 3-layer neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(128, activation='relu'),  # First hidden layer with 128 units and ReLU activation\n",
        "    Dense(128, activation='relu'),  # Second hidden layer with 128 units and ReLU activation\n",
        "    Dense(128, activation='relu'),  # Third hidden layer with 128 units and ReLU activation\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 units for 10 classes and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=custom_categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3XNfyg0csjG",
        "outputId": "a933bed7-03ba-4bac-f79f-8207bc44b582"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2556 - accuracy: 0.9227 - val_loss: 0.1420 - val_accuracy: 0.9568\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1065 - accuracy: 0.9671 - val_loss: 0.1015 - val_accuracy: 0.9706\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0745 - accuracy: 0.9763 - val_loss: 0.1075 - val_accuracy: 0.9678\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0589 - accuracy: 0.9815 - val_loss: 0.1057 - val_accuracy: 0.9695\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0488 - accuracy: 0.9844 - val_loss: 0.0923 - val_accuracy: 0.9731\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0885 - accuracy: 0.9750\n",
            "Test Loss: 0.08847285062074661, Test Accuracy: 0.9750000238418579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a 3-layer neural network model\n",
        "model1 = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten the input images\n",
        "    Dense(128, activation='relu'),  # First hidden layer with 128 units and ReLU activation\n",
        "    Dense(128, activation='relu'),  # Second hidden layer with 128 units and ReLU activation\n",
        "    Dense(128, activation='relu'),  # Third hidden layer with 128 units and ReLU activation\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 units for 10 classes and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam',\n",
        "              loss=qim(0.5),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history1 = model1.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model1.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_hGT0JKcBlT",
        "outputId": "85d290a2-b368-4cbf-cbd3-30d2bafe1623"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: nan - accuracy: 0.0985 - val_loss: nan - val_accuracy: 0.0995\n",
            "313/313 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0980\n",
            "Test Loss: nan, Test Accuracy: 0.09799999743700027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.legend(['Categorical CE', 'Soft QIM'])"
      ],
      "metadata": {
        "id": "WPGQ2pK9cP14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}