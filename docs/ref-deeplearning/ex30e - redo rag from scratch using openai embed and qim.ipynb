{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Create Data"
      ],
      "metadata": {
        "id": "bpeXbSlQteRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3YbWg1PrinQ"
      },
      "outputs": [],
      "source": [
        "# Sample sentences for the list\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"She opened her book and started to read.\",\n",
        "    \"Today is a sunny day.\",\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"He loves to play soccer.\",\n",
        "    \"I need to buy some groceries.\",\n",
        "    \"Python programming is fun.\",\n",
        "    \"The lake is deep and beautiful.\",\n",
        "    \"She sings beautifully.\",\n",
        "    \"They are planning a trip to Paris.\"\n",
        "]\n",
        "\n",
        "# Print the list of sentences\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "AsoAZR-otfgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "id": "oRCZ8TVqsVwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grab Secrets"
      ],
      "metadata": {
        "id": "xfxyAjgix_-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "g3yG_Lb0sjYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "mKkDqxjiyBPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from typing import List\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "def list_to_nums(sentences: List[str]) -> List[List[float]]:\n",
        "    \"\"\"\n",
        "    Converts a list of sentences into a list of numerical embeddings using OpenAI's embedding model.\n",
        "\n",
        "    Args:\n",
        "    - sentences (List[str]): A list of sentences (strings).\n",
        "\n",
        "    Returns:\n",
        "    - List[List[float]]: A list of lists of numerical embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the list to store embeddings\n",
        "    embeddings = []\n",
        "\n",
        "    # Loop through each sentence to convert to embeddings\n",
        "    for sentence in sentences:\n",
        "        # Use the OpenAI API to get embeddings for the sentence\n",
        "\n",
        "        response = client.embeddings.create(\n",
        "            input=sentence,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "\n",
        "        embeddings.append(response.data[0].embedding)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "yAfKdHxUruh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Call the function\n",
        "query_database = list_to_nums(sentences)"
      ],
      "metadata": {
        "id": "bf7XwSIzsolQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is the meaning of life?\""
      ],
      "metadata": {
        "id": "OHwPJCDIswXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "prompt_embed_ = list_to_nums([prompt])\n",
        "print(type(prompt_embed_), len(prompt_embed_[0]))"
      ],
      "metadata": {
        "id": "GMiAYbyEtsIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized Influence Measure (QIM)"
      ],
      "metadata": {
        "id": "CNohM6RTyDah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Any, Dict, List, Tuple, Union\n",
        "\n",
        "\n",
        "def quantize_to_kbit(arr: Union[np.ndarray, Any], k: int = 16) -> np.ndarray:\n",
        "    \"\"\"Converts an array to a k-bit representation by normalizing and scaling its values.\n",
        "\n",
        "    Args:\n",
        "        arr (Union[np.ndarray, Any]): The input array to be quantized.\n",
        "        k (int): The number of levels to quantize to. Defaults to 16 for 4-bit quantization.\n",
        "    Returns:\n",
        "        np.ndarray: The quantized array with values scaled to 0 to k-1.\n",
        "    \"\"\"\n",
        "    if not isinstance(arr, np.ndarray):  # Check if input is not a numpy array\n",
        "        arr = np.array(arr)  # Convert input to a numpy array\n",
        "    arr_min = arr.min()  # Calculate the minimum value in the array\n",
        "    arr_max = arr.max()  # Calculate the maximum value in the array\n",
        "    normalized_arr = (arr - arr_min) / (arr_max - arr_min)  # Normalize array values to [0, 1]\n",
        "    return np.round(normalized_arr * (k - 1)).astype(int)  # Scale normalized values to 0-(k-1) and convert to integer\n",
        "\n",
        "\n",
        "def quantized_influence(arr1: np.ndarray, arr2: np.ndarray, k: int = 16, use_dagger: bool = False) -> Tuple[float, List[float]]:\n",
        "    \"\"\"\n",
        "    Calculates a weighted measure of influence based on quantized version of input arrays and optionally applies a transformation.\n",
        "\n",
        "    Args:\n",
        "        arr1 (np.ndarray): First input array to be quantized and analyzed.\n",
        "        arr2 (np.ndarray): Second input array to be quantized and used for influence measurement.\n",
        "        k (int): The quantization level, defaults to 16 for 4-bit quantization.\n",
        "        use_dagger (bool): Flag to apply a transformation based on local averages, defaults to False.\n",
        "    Returns:\n",
        "        Tuple[float, List[float]]: A tuple containing the quantized influence measure and an optional list of transformed values based on local estimates.\n",
        "    \"\"\"\n",
        "    # Quantize both arrays to k levels\n",
        "    arr1_quantized = quantize_to_kbit(arr1, k)\n",
        "    arr2_quantized = quantize_to_kbit(arr2, k)\n",
        "\n",
        "    # Find unique quantized values in arr1\n",
        "    unique_values = np.unique(arr1_quantized)\n",
        "\n",
        "    # Compute the global average of quantized arr2\n",
        "    total_samples = len(arr2_quantized)\n",
        "    y_bar_global = np.mean(arr2_quantized)\n",
        "\n",
        "    # Compute weighted local averages and normalize\n",
        "    weighted_local_averages = [(np.mean(arr2_quantized[arr1_quantized == val]) - y_bar_global)**2 * len(arr2_quantized[arr1_quantized == val])**2 for val in unique_values]\n",
        "    qim = np.sum(weighted_local_averages) / (total_samples * np.std(arr2_quantized))  # Calculate the quantized influence measure\n",
        "\n",
        "    if use_dagger:\n",
        "        # If use_dagger is True, compute local estimates and map them to unique quantized values\n",
        "        local_estimates = [np.mean(arr2_quantized[arr1_quantized == val]) for val in unique_values]\n",
        "        daggers = {unique_values[i]: v for i, v in enumerate(local_estimates)}  # Map unique values to local estimates\n",
        "\n",
        "        def find_val_(i: int) -> float:\n",
        "            \"\"\"Helper function to map quantized values to their local estimates.\"\"\"\n",
        "            return daggers[i]\n",
        "\n",
        "        # Apply transformation based on local estimates\n",
        "        daggered_values = list(map(find_val_, arr1_quantized))\n",
        "        return qim, daggered_values\n",
        "    else:\n",
        "        # If use_dagger is False, return the original quantized arr1 values\n",
        "        daggered_values = arr1_quantized.tolist()\n",
        "        return qim"
      ],
      "metadata": {
        "id": "NsH5THH0tt6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(prompt_embed_[0]), len(query_database[0])"
      ],
      "metadata": {
        "id": "sv8bavKNuuOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MKWaxcZQu3XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "current_qim = quantized_influence(prompt_embed_[0], query_database[0], k=16, use_dagger=False)\n",
        "print(current_qim)"
      ],
      "metadata": {
        "id": "YXo39TSPuR5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "current_qim = quantized_influence(prompt_embed_[0], query_database[0], k=3, use_dagger=False)\n",
        "print(current_qim)"
      ],
      "metadata": {
        "id": "OlC5CvtluSNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_database)"
      ],
      "metadata": {
        "id": "bf6ujG0uvDfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "scores = [[sentences[i], query_database[i], quantized_influence(prompt_embed_[0], query_database[i], k=3, use_dagger=False)] for i in range(len(query_database))]\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "9pwAjyoXu9v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "eNU_g-SHwBGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "refs = pd.DataFrame(scores)\n",
        "refs = refs.rename(columns={0: \"sentences\", 1: \"query_embeddings\", 2: \"qim\"})"
      ],
      "metadata": {
        "id": "9ERJLNTpwvYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refs.sort_values(by=\"qim\", ascending=False)"
      ],
      "metadata": {
        "id": "kSPInXQFwyDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Search"
      ],
      "metadata": {
        "id": "CkL9_eSEyGDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "def query_search(prompt: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Takes a text prompt and searches a predefined database by converting the prompt\n",
        "    and database entries to embeddings, and then calculating a quantized influence metric.\n",
        "\n",
        "    Args:\n",
        "    - prompt (str): A text prompt to search for in the database.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A pandas DataFrame sorted by the quantized influence metric in descending order.\n",
        "                     The DataFrame contains the original sentences, their embeddings, and the computed scores.\n",
        "    \"\"\"\n",
        "    # Convert the prompt to its numerical embedding\n",
        "    prompt_embed_ = list_to_nums([prompt])\n",
        "\n",
        "    # Calculate scores for each item in the database using the quantized influence metric\n",
        "    scores = [\n",
        "        [\n",
        "            sentences[i],  # The sentence itself\n",
        "            query_database[i],  # Embedding of the sentence\n",
        "            quantized_influence(prompt_embed_[0], query_database[i], k=3, use_dagger=False)  # Score calculation\n",
        "        ]\n",
        "        for i in range(len(query_database))\n",
        "    ]\n",
        "\n",
        "    # Convert the list of scores into a DataFrame\n",
        "    refs = pd.DataFrame(scores)\n",
        "    # Rename columns for clarity\n",
        "    refs = refs.rename(columns={0: \"sentences\", 1: \"query_embeddings\", 2: \"qim\"})\n",
        "    # Sort the DataFrame based on the 'qim' score in descending order\n",
        "    refs = refs.sort_values(by=\"qim\", ascending=False)\n",
        "\n",
        "    return refs"
      ],
      "metadata": {
        "id": "mPrt-MdexBrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_search(\"What is the meaning of life?\")"
      ],
      "metadata": {
        "id": "vtsSLaYuxqvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_search(\"The lake is dup and beauti\")"
      ],
      "metadata": {
        "id": "oIVW6TUjxsLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_search(\"The planning to paris is not good\")"
      ],
      "metadata": {
        "id": "jsxAtCVwxyB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Data"
      ],
      "metadata": {
        "id": "2r_EiCxYyvwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "HydZetZEy1V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "import PyPDF2\n",
        "\n",
        "def read_and_textify(files: List[str]) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Reads PDF files from given paths and extracts text from each page.\n",
        "\n",
        "    This function iterates over a list of PDF file paths, opens each file, extracts text from each page,\n",
        "    and compiles a list of texts and corresponding source information.\n",
        "\n",
        "    Args:\n",
        "    files (List[str]): A list of paths to PDF files.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[str], List[str]]: A tuple containing two lists:\n",
        "        1. A list of strings, where each string is the text extracted from a PDF page.\n",
        "        2. A list of strings indicating the source of each text (file name and page number).\n",
        "    \"\"\"\n",
        "\n",
        "    text_list = []  # List to store extracted text\n",
        "    sources_list = []  # List to store source information\n",
        "\n",
        "    # Iterate over each file path\n",
        "    for file_path in files:\n",
        "        # Open the PDF file\n",
        "        with open(file_path, \"rb\") as file:\n",
        "            pdfReader = PyPDF2.PdfReader(file)  # Create a PDF reader object\n",
        "            # Iterate over each page in the PDF\n",
        "            for i in range(len(pdfReader.pages)):\n",
        "                pageObj = pdfReader.pages[i]  # Get the page object\n",
        "                text = pageObj.extract_text()  # Extract text from the page\n",
        "                text_list.append(text)  # Add extracted text to the list\n",
        "                # Extract the file name from the path and append the source info\n",
        "                sources_list.append(f\"{file_path.split('/')[-1]}_page_{i}\")\n",
        "\n",
        "    return text_list, sources_list\n"
      ],
      "metadata": {
        "id": "jAijrTCXyTkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "uploaded_files = \"/content/Understanding_and_Improving_Use_Tax_Compliance__A_Theory_of_Plann.pdf\"\n",
        "\n",
        "# Process the uploaded files to extract text and source information\n",
        "textify_output = read_and_textify([uploaded_files])\n",
        "\n",
        "# Separate the output into documents (text) and their corresponding sources\n",
        "documents, sources = textify_output"
      ],
      "metadata": {
        "id": "-G2ahzSlyxdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents), type(sources)"
      ],
      "metadata": {
        "id": "WMVt7oBSzI2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0]"
      ],
      "metadata": {
        "id": "GAitItfIzsOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents), len(sources)"
      ],
      "metadata": {
        "id": "40_lC2Dkzs3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0], sources[0]"
      ],
      "metadata": {
        "id": "6WDGlJ610VuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Call the function\n",
        "query_database = list_to_nums(documents)"
      ],
      "metadata": {
        "id": "3j9Wltrs0opO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "def query_search(prompt: str, sentences: list[str], query_database: list[list[float]], sources: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Takes a text prompt and searches a predefined database by converting the prompt\n",
        "    and database entries to embeddings, and then calculating a quantized influence metric.\n",
        "\n",
        "    Args:\n",
        "    - prompt (str): A text prompt to search for in the database.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: A pandas DataFrame sorted by the quantized influence metric in descending order.\n",
        "                     The DataFrame contains the original sentences, their embeddings, and the computed scores.\n",
        "    \"\"\"\n",
        "    # Convert the prompt to its numerical embedding\n",
        "    prompt_embed_ = list_to_nums([prompt])\n",
        "\n",
        "    # Calculate scores for each item in the database using the quantized influence metric\n",
        "    scores = [\n",
        "        [\n",
        "            sentences[i],  # The sentence itself\n",
        "            query_database[i],  # Embedding of the sentence\n",
        "            sources[i],  # Source of the sentence\n",
        "            quantized_influence(prompt_embed_[0], query_database[i], k=3, use_dagger=False)  # Score calculation\n",
        "        ]\n",
        "        for i in range(len(query_database))\n",
        "    ]\n",
        "\n",
        "    # Convert the list of scores into a DataFrame\n",
        "    refs = pd.DataFrame(scores)\n",
        "    # Rename columns for clarity\n",
        "    refs = refs.rename(columns={0: \"sentences\", 1: \"query_embeddings\", 2: \"page no\", 3: \"qim\"})\n",
        "    # Sort the DataFrame based on the 'qim' score in descending order\n",
        "    refs = refs.sort_values(by=\"qim\", ascending=False)\n",
        "\n",
        "    return refs"
      ],
      "metadata": {
        "id": "sS7b1O39z03a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "ref_tab = query_search(\"pful for understanding federal income\", documents, query_database, sources)"
      ],
      "metadata": {
        "id": "c2XjBjl0014i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_tab.to_json()"
      ],
      "metadata": {
        "id": "Ma2YhEkJ04Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QsF_U9dEHEo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}