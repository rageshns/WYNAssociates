{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install openai PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjG_FvHuISq_",
        "outputId": "dbea4097-1f7e-4d31-83a5-91402fbfe245"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: PyMuPDFb, h11, PyMuPDF, httpcore, httpx, openai\n",
            "Successfully installed PyMuPDF-1.24.5 PyMuPDFb-1.24.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zYli1GrOILUb"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import openai\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "class PDFQnAGenerator:\n",
        "    def __init__(self, pdf_path: str, openai_api_key: str):\n",
        "        self.pdf_path = pdf_path\n",
        "        self.openai_api_key = openai_api_key\n",
        "        self.scraped_content = self.read_pdf_content()\n",
        "        self.openai_client = openai.OpenAI(api_key=self.openai_api_key)\n",
        "        self.raw_content_questions = []\n",
        "        self.raw_content_answers = []\n",
        "\n",
        "    def read_pdf_content(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Reads a PDF and returns its content as a list of strings.\n",
        "\n",
        "        Returns:\n",
        "        list of str: A list where each element is the text content of a PDF page.\n",
        "        \"\"\"\n",
        "        content_list = []\n",
        "        with fitz.open(self.pdf_path) as doc:\n",
        "            for page in doc:\n",
        "                content_list.append(page.get_text())\n",
        "\n",
        "        return content_list\n",
        "\n",
        "    def process_scraped_content(self):\n",
        "        \"\"\"\n",
        "        Process scraped content to replace special characters and split into sentences.\n",
        "        \"\"\"\n",
        "        self.scraped_content = ' '.join(self.scraped_content)\n",
        "        self.scraped_content = [self.scraped_content.split('. ')[i].replace('\\n', '').replace('   ', '').replace('  ', '') for i in range(len(self.scraped_content.split('. ')))]\n",
        "\n",
        "    def call_chatgpt(self, query: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
        "        \"\"\"\n",
        "        Generates a response to a query using the specified language model.\n",
        "        Args:\n",
        "            query (str): The user's query that needs to be processed.\n",
        "            model (str, optional): The language model to be used. Defaults to \"gpt-3.5-turbo\".\n",
        "        Returns:\n",
        "            str: The generated response to the query.\n",
        "        \"\"\"\n",
        "\n",
        "        # Prepare the conversation context with system and user messages.\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Question: {query}.\"},\n",
        "        ]\n",
        "\n",
        "        # Use the OpenAI client to generate a response based on the model and the conversation context.\n",
        "        response = self.openai_client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "        )\n",
        "\n",
        "        # Extract the content of the response from the first choice.\n",
        "        content: str = response.choices[0].message.content\n",
        "\n",
        "        # Return the generated content.\n",
        "        return content\n",
        "\n",
        "    def prompt_engineered_api(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate a question based on the provided text content.\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"\n",
        "            I have the following content: {text}\n",
        "\n",
        "            Write one question based on the content above. Just write ONE question in a sentence. No more.\n",
        "        \"\"\"\n",
        "\n",
        "        resp = self.call_chatgpt(prompt)\n",
        "\n",
        "        return resp\n",
        "\n",
        "    def generate_questions_answers(self):\n",
        "        \"\"\"\n",
        "        Generate questions and answers from the scraped content.\n",
        "        \"\"\"\n",
        "        for i in tqdm(range(len(self.scraped_content))):\n",
        "            quest = self.scraped_content[i]\n",
        "            resp = self.prompt_engineered_api(quest)\n",
        "            this_sample_question = resp.split(\"###\")[0]\n",
        "            this_sample_answer = self.scraped_content[i]\n",
        "            self.raw_content_questions.append(this_sample_question)\n",
        "            self.raw_content_answers.append(this_sample_answer)\n",
        "\n",
        "    def convert_to_dataframe(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Converts a list of questions and answers into a Pandas DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            - Pandas DataFrame: The resulting data frame with columns for each question-answer pair.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert lists to Series objects for easier indexing\n",
        "        qns_series = pd.Series([question + \"\\n\" for question in self.raw_content_questions])\n",
        "        ans_series = pd.Series(self.raw_content_answers)\n",
        "\n",
        "        # Create a data frame from the Series objects\n",
        "        df = pd.DataFrame({\"Question\": qns_series, \"Answer\": ans_series})\n",
        "\n",
        "        # Split the question column by \\n character and split the answer column by newline characters (\\r\\n or \\n). This ensures that each row contains only one question and its corresponding answer.\n",
        "        df[\"Question\"] = df[\"Question\"].str.split(\"\\n\")\n",
        "        df[\"Answer\"] = df[\"Answer\"].str.split(\"\\r\\n|\\n\")\n",
        "\n",
        "        # Reshape the data frame so that it has one row for each question and its corresponding answer. Drop any rows where there are no answers provided.\n",
        "        df = df.explode(\"Question\").reset_index().dropna()\n",
        "\n",
        "        # Save a .csv file\n",
        "        file_path_collapsed = self.pdf_path.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
        "        df.to_csv(f\"questions_answers__{file_path_collapsed}.csv\", index=False)\n",
        "\n",
        "        return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "SmYDxYNiIy4x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "pdf_path = \"/content/1 - Individual Research Program - Syllabus - Amogh.pdf\"\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "generator = PDFQnAGenerator(pdf_path, openai_api_key)\n",
        "generator.process_scraped_content()\n",
        "generator.generate_questions_answers()\n",
        "df = generator.convert_to_dataframe()\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfkxnwdCIPRV",
        "outputId": "7f216c6a-3520-4161-9108-a551eb763daf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:23<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    index                                           Question  \\\n",
            "0       0  What is the motivation behind the project prop...   \n",
            "1       0                                                      \n",
            "2       1  What pre-trained model will students use in th...   \n",
            "3       1                                                      \n",
            "4       2  What steps will be taken to ensure that studen...   \n",
            "..    ...                                                ...   \n",
            "65     32                                                      \n",
            "66     33  What steps should be taken to ensure all feedb...   \n",
            "67     33                                                      \n",
            "68     34  What steps are needed to finalize the submissi...   \n",
            "69     34                                                      \n",
            "\n",
            "                                               Answer  \n",
            "0   [Independent Research Program | Data Science, ...  \n",
            "1   [Independent Research Program | Data Science, ...  \n",
            "2   [The motivation for this project is to utilize...  \n",
            "3   [The motivation for this project is to utilize...  \n",
            "4   [The project will involve integrating the mode...  \n",
            "..                                                ...  \n",
            "65  [Draft the introductionand abstract of the pap...  \n",
            "66  [Solicitfeedback from peers or mentors and mak...  \n",
            "67  [Solicitfeedback from peers or mentors and mak...  \n",
            "68  [Submit the paperto the chosen journal or conf...  \n",
            "69  [Submit the paperto the chosen journal or conf...  \n",
            "\n",
            "[70 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEDrXhiHI6Ko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}