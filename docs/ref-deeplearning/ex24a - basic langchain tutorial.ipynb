{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VOwJpcZqOXag-ZXi-52ibOx6L5Pw-YJi","timestamp":1711823536114}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Copyright © 2023 Patrick Loeber"],"metadata":{"id":"DOycdBmh0FBf"}},{"cell_type":"markdown","source":["# LangChain\n","\n","LangChain is a framework for developing applications powered by language models.\n","\n","- GitHub: https://github.com/hwchase17/langchain\n","- Docs: https://python.langchain.com/en/latest/index.html\n","\n","### Overview:\n","- Installation\n","- LLMs\n","- Prompt Templates\n","- Chains\n","- Agents and Tools\n","- Memory\n","- Document Loaders\n","- Indexes"],"metadata":{"id":"nTDgRy0jKDkP"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"5WGtOYYTKfz3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcrn7QRyQXGj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823582155,"user_tz":240,"elapsed":26050,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"68203e69-f85e-4f5c-a9a1-fdc49ad82b8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n","  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n","  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.38-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.36 langchain-text-splitters-0.0.1 langsmith-0.1.38 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"]}],"source":["!pip install langchain"]},{"cell_type":"markdown","source":["## 1. LLMs\n","\n","A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"],"metadata":{"id":"NkGGSdmtta6s"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"id":"H_dfy6G_aBtY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823595470,"user_tz":240,"elapsed":13319,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"83fa27ab-60e6-4aad-f61b-bb8b6a122b4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.14.3\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"OPENAI_API_KEY\"] =\"sk-xxx\""],"metadata":{"id":"RlxEmS1CaM5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","\n","llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n","text = \"What would be a good company name for a company that makes colorful socks?\"\n","print(llm(text))"],"metadata":{"id":"pY09s9cmZ6nQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823598412,"user_tz":240,"elapsed":2943,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"8b68dbb3-7b9e-441c-a3d6-36eacbb7fb95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n","  warn_deprecated(\n","/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\"Funky Feet Co.\" \n","\n"]}]},{"cell_type":"code","source":["!pip install huggingface_hub"],"metadata":{"id":"idkq_aVyaceF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823608056,"user_tz":240,"elapsed":9648,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"301aa7f7-7769-4877-d83b-e2333634f818"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"]}]},{"cell_type":"code","source":["os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"xxx\""],"metadata":{"id":"i4DKOWjyaRmO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain import HuggingFaceHub"],"metadata":{"id":"QmtH72oCaU32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://huggingface.co/openai-community/gpt2\n","llm = HuggingFaceHub(repo_id=\"openai-community/gpt2\", model_kwargs={\"temperature\":0.5, \"max_length\":64})\n","\n","llm(\"translate English to German: How old are you?\")"],"metadata":{"id":"8uK5TtJPc49I","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1711823733801,"user_tz":240,"elapsed":13025,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"9167615a-4588-4486-96af-f90dcc7b0fb5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'translate English to German: How old are you?\\n\\nA: I am 23.\\n\\nQ: You are a student at the University of Wisconsin. How many years have you been in the classroom?\\n\\nA: I have been in the classroom for about 15 years now.\\n\\nQ: How'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## 2. Prompt Templates\n","\n","LangChain faciliates prompt management and optimization.\n","\n","Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."],"metadata":{"id":"3O-7dO1htdO4"}},{"cell_type":"code","source":["llm(\"Can Barack Obama have a conversation with George Washington?\")"],"metadata":{"id":"_FDS9IDRapOt","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1711823741342,"user_tz":240,"elapsed":1668,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"d0a84951-1f21-4a4e-ec65-e254f884670a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Can Barack Obama have a conversation with George Washington?\\n\\nI think he's doing a good job. But I think he's not the kind of guy who is going to do a good job. And I think he's not going to be a great leader.\\n\\nThe other thing to watch is that he has\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["prompt = \"\"\"Question: Can Barack Obama have a conversation with George Washington?\n","\n","Let's think step by step.\n","\n","Answer: \"\"\"\n","llm(prompt)"],"metadata":{"id":"lB4W8dM1tPAY","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1711823743275,"user_tz":240,"elapsed":1188,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"e5bda421-9c0e-43a7-cc53-c7666f2183c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: ____________\\n\\nThe answer is no.\\n\\nLet's think about the first two questions.\\n\\nFirst, what was the name of the president? ___________\\n\\nThe\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from langchain import PromptTemplate\n","\n","template = \"\"\"Question: {question}\n","\n","Let's think step by step.\n","\n","Answer: \"\"\"\n","\n","prompt = PromptTemplate(template=template, input_variables=[\"question\"])"],"metadata":{"id":"UU1VyMMvtsCE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"],"metadata":{"id":"-Yzpc_0aHHeE","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1711823804375,"user_tz":240,"elapsed":4,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"8797f511-10af-487b-c0f7-c29069690bce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["## 3. Chains\n","\n","Combine LLMs and Prompts in multi-step workflows"],"metadata":{"id":"1zw1KlSeuUOY"}},{"cell_type":"code","source":["from langchain import LLMChain\n","\n","llm_chain = LLMChain(prompt=prompt, llm=llm)\n","\n","question = \"Can Barack Obama have a conversation with George Washington?\"\n","\n","print(llm_chain.run(question))"],"metadata":{"id":"eE6n-jbAuOxt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823872197,"user_tz":240,"elapsed":574,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"8044b76e-8634-42dd-ccb8-ca2a349f2786"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Question: Can Barack Obama have a conversation with George Washington?\n","\n","Let's think step by step.\n","\n","Answer: ____________\n","\n","The answer is no.\n","\n","Let's think about the first two questions.\n","\n","First, what was the name of the president? ___________\n","\n","The\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"markdown","source":["## 4. Agents and Tools\n","\n","Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n","\n","\n","When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n","\n","- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n","- LLM: The language model powering the agent.\n","- Agent: The agent to use.\n","\n","Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n","\n","Agent Types: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html"],"metadata":{"id":"Zp-UlOK0bMVQ"}},{"cell_type":"code","source":["from langchain.agents import load_tools\n","from langchain.agents import initialize_agent"],"metadata":{"id":"79JcjhFXwv0J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install wikipedia"],"metadata":{"id":"dOSpaurEb1MR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823902731,"user_tz":240,"elapsed":9208,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"fee46725-43cf-4d93-ed3d-b5b4a365bd8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=5bfd2feb94d850e40bdb65f5f19bc0b7fe372e7cb8a6deb5f8e4e96a9765a45d\n","  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"]}]},{"cell_type":"code","source":["from langchain.llms import OpenAI\n","llm = OpenAI(temperature=0)\n","tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"],"metadata":{"id":"RgV4kny1bgy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"],"metadata":{"id":"iQUOsWLrbjKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711823907933,"user_tz":240,"elapsed":341,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"97a80bd9-3e06-4ef1-bf1c-fcbb92868075"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n","  warn_deprecated(\n"]}]},{"cell_type":"code","source":["some_random_message_ = \"Tell me about the company nvidia and revenues.\"\n","output_ = agent.run(f\"Tell me about {some_random_message_}\")"],"metadata":{"id":"M8Rob2Wsb_l9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711826956488,"user_tz":240,"elapsed":7090,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"003ba03e-0383-48d9-90c9-e68a03438236"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m I should use wikipedia to find information about the company nvidia.\n","Action: wikipedia\n","Action Input: nvidia\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mPage: Nvidia\n","Summary: Nvidia Corporation (, en-VID-ee-ə) is an American multinational corporation and technology company headquartered in Santa Clara, California, and incorporated in Delaware. It is a software and fabless company which designs and supplies graphics processing units (GPUs), application programming interfaces (APIs) for data science and high-performance computing as well as system on a chip units (SoCs) for the mobile computing and automotive market. Nvidia is also a dominant supplier of artificial intelligence (AI) hardware and software.Nvidia's professional line of GPUs are used for edge-to-cloud computing and in supercomputers and workstations for applications in such fields as architecture, engineering and construction, media and entertainment, automotive, scientific research, and manufacturing design. Its GeForce line of GPUs are aimed at the consumer market and are used in applications such as video editing, 3D rendering and PC gaming. In the second quarter of 2023, Nvidia had a market share of 80.2% in the discrete desktop GPU market. The company expanded its presence in the gaming industry with the introduction of the Shield Portable (a handheld game console), Shield Tablet (a gaming tablet) and Shield TV (a digital media player), as well as its cloud gaming service GeForce Now.In addition to GPU design and manufacturing, Nvidia provides the CUDA software platform and API that allows the creation of massively parallel programs which utilize GPUs. They are deployed in supercomputing sites around the world. In the late 2000s, Nvidia had moved into the mobile computing market, where it produces Tegra mobile processors for smartphones and tablets as well as vehicle navigation and entertainment systems. Its competitors include AMD, Intel, Qualcomm and AI accelerator companies such as Cerebras and Graphcore. It also makes AI-powered software for audio and video processing, e.g. Nvidia Maxine.Nvidia's offer to acquire Arm from SoftBank in September 2020 failed to materialize following extended regulatory scrutiny, leading to the termination of the deal in February 2022 in what would have been the largest semiconductor acquisition. In 2023, Nvidia became the seventh public U.S. company to be valued at over $1 trillion, and, as of March 2024, it is the third most-valuable publicly-traded company based in the United States after Microsoft and Apple, with a market capitalization of $2.3 trillion.\n","\n","\n","\n","Page: List of Nvidia graphics processing units\n","Summary: This list contains general information about graphics processing units (GPUs) and video cards from Nvidia, based on official specifications. In addition some Nvidia motherboards come with integrated onboard GPUs. Limited/Special/Collectors' Editions or AIB versions are not included.\n","\n","\n","\n","Page: Nvidia GTC\n","Summary: Nvidia GTC (GPU Technology Conference) is a global artificial intelligence (AI) conference for developers that brings together developers, engineers, researchers, inventors, and IT professionals. Topics focus on AI, computer graphics, data science, machine learning and autonomous machines. Each conference begins with a keynote from Nvidia CEO and Founder Jensen Huang, followed by a variety of sessions and talks with experts from around the world.\n","It originated in 2009 in San Jose, California, with an initial focus on the potential for solving computing challenges through GPUs. In recent years, the conference focus has shifted to various applications of artificial intelligence and deep learning, including: self-driving cars, healthcare, high performance computing, professional visualization, and Nvidia Deep Learning Institute (DLI) training.\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n","Final Answer: Nvidia is an American multinational corporation and technology company that designs and supplies graphics processing units (GPUs) for various industries, including gaming, artificial intelligence, and high-performance computing. In addition to GPUs, Nvidia also offers software platforms and APIs for parallel programming and has expanded into the mobile computing market with its Tegra processors. The company also hosts an annual conference, Nvidia GTC, focused on AI and deep learning applications. As of March 2024, Nvidia is the third most valuable publicly-traded company in the United States.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"code","source":["output_"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"kdXTiXJyqD-q","executionInfo":{"status":"ok","timestamp":1711826292036,"user_tz":240,"elapsed":6,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"c718f0e4-65b7-4831-9c6a-a4ae2c711d8c"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'NVDA is a technology company that specializes in graphics processing units and artificial intelligence. META is a multinational technology conglomerate that owns and operates Facebook, Instagram, and other products and services. AMAT is a company that specializes in meta-analysis, a statistical method used in research.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["## 5. Memory\n","\n","Add State to Chains and Agents.\n","\n","Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."],"metadata":{"id":"8AuQNfhYm48A"}},{"cell_type":"code","source":["from langchain import OpenAI, ConversationChain\n","\n","llm = OpenAI(temperature=0)\n","conversation = ConversationChain(llm=llm, verbose=True)\n","\n","conversation.predict(input=\"Hi there!\")"],"metadata":{"id":"Ujwj29G2cDPN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Can we talk about AI?\")"],"metadata":{"id":"XkKv8n7ZnB2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"I'm interested in Reinforcement Learning.\")"],"metadata":{"id":"r4P3zWCmoDST"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Document Loaders\n","\n","Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into “documents” - a fancy way of say some pieces of text. This module is aimed at making this easy.\n","\n","https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"],"metadata":{"id":"9wMttXM-CuPK"}},{"cell_type":"code","source":["from langchain.document_loaders import NotionDirectoryLoader\n","\n","loader = NotionDirectoryLoader(\"Notion_DB\")\n","\n","docs = loader.load()"],"metadata":{"id":"iAiISOcboPKR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Indexes\n","\n","Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents\n","\n","- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n","- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n","- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results."],"metadata":{"id":"Q_zcj8MLDGfQ"}},{"cell_type":"code","source":["import requests\n","\n","url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n","res = requests.get(url)\n","with open(\"state_of_the_union.txt\", \"w\") as f:\n","  f.write(res.text)"],"metadata":{"id":"qLU79cyCozYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Document Loader\n","from langchain.document_loaders import TextLoader\n","loader = TextLoader('./state_of_the_union.txt')\n","documents = loader.load()"],"metadata":{"id":"XGyZXiJZBsov"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text Splitter\n","from langchain.text_splitter import CharacterTextSplitter\n","text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n","docs = text_splitter.split_documents(documents)"],"metadata":{"id":"OklI0xTvp2KE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentence_transformers"],"metadata":{"id":"skvXSMXHCxyq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Embeddings\n","from langchain.embeddings import HuggingFaceEmbeddings\n","embeddings = HuggingFaceEmbeddings()\n","\n","#text = \"This is a test document.\"\n","#query_result = embeddings.embed_query(text)\n","#doc_result = embeddings.embed_documents([text])"],"metadata":{"id":"V1yCdAhSCi64"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install faiss-cpu"],"metadata":{"id":"8R3pT55b-uBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n","from langchain.vectorstores import FAISS\n","\n","db = FAISS.from_documents(docs, embeddings)\n","\n","query = \"What did the president say about Ketanji Brown Jackson\"\n","docs = db.similarity_search(query)"],"metadata":{"id":"W7sRydnlC7rb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(docs[0].page_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CB7lvDWzDHZy","executionInfo":{"status":"ok","timestamp":1680783626513,"user_tz":-420,"elapsed":6,"user":{"displayName":"Python Engineer","userId":"17548894429742869312"}},"outputId":"3b0399d0-6c04-4cef-a029-e48cbd41eedd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n","\n","Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n","\n","One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n","\n","And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"]}]},{"cell_type":"code","source":["db.save_local(\"faiss_index\")\n","new_db = FAISS.load_local(\"faiss_index\", embeddings)\n","docs = new_db.similarity_search(query)\n","print(docs[0].page_content)"],"metadata":{"id":"nu-AmhDLEK0h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## End-to-end example\n","\n","https://github.com/hwchase17/chat-langchain\n"],"metadata":{"id":"K1lGH_g2--Si"}}]}