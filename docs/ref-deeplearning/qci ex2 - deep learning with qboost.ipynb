{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "xPbokkfOMgTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to directly solving optimization, quadratic unconstrained binary optimization solvers like ours have machine learning applications. The specific application we demonstrate here is one known as boosting. Particularly we are demonstrating a variant of boosting that has been adapted to quadratic solvers known as QBoost. The underlying idea of boosting is to use many sources of imperfect information to build a strong prediction. In machine learning language, we find a collection of weak classifiers that together can form a strong classifier. A weighted combination of these sources of partial information can provide a powerful tool if combined in the right way. The task that the Dirac device will be doing is to find this combination. An obvious constraint is to include the classifiers that give the most accurate information, but there is another concern. We want ones that give complementary information. Statistically speaking, we want to take classifiers that have high correlations with the information that we want to classify, but have weak correlations between them. In the extreme case, two classifiers could give the exact same information, in which case including both is wasteful. However, avoiding waste isn't the only concern here. Including too many classifiers can also lead to overfitting if they capture spurious information specific to the training data, rather than information that will generalize well to unseen cases. In this tutorial, we show an implementation of QBoost and test it on a simple binary classification problem using the IRIS dataset."
      ],
      "metadata": {
        "id": "7s3YBih8MiOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importance\n",
        "\n",
        "An advantage of boosting is that once the strong classifier is built, it can be applied without having to re-solve the QUBO. As a result, the classifier can be applied in settings where access to Dirac is not available. As Dirac only gets used in the training phase, it also can be reused many times in the future. This simple application provides one example of many potential machine learning applications of our hardware.\n",
        "\n"
      ],
      "metadata": {
        "id": "6sNzjlJJMkQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Classification, the task that QBoost performs, appears in a number of settings. A simple example of a classification problem that you are probably impacted by every day is email spam filtering. Here, the goal is to categorize email as \"spam\" or \"legitimate\", and it is relatively straightforward to see how the boosting approach can be applied. A variety of weak rules can be derived, (for example, a spam email is probably slightly more likely to contain the word \"money\"). These are of little use individually, but can be made into a powerful filter when combined through boosting. Disease diagnosis is also fundamentally a classification problem with a concrete example being the use of boosting to predict chronic kidney disease. The weak classifiers would come from patient medical history, such as whether they have other conditions or not, as well as other factors such as age. Also, boosting approaches can be applied to image recognition. This is done by using simple features (for example, a nose between two eyes represented by a lighter rectangle between two darker ones) as weak classifiers, and checking for combinations of them, as was done here for facial recognition."
      ],
      "metadata": {
        "id": "x9AnF55_MnPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methodology\n",
        "\n",
        "# Methodology\n",
        "\n",
        "The idea is based on the concept of boosting. Let us assume that we have a collection of $N$ *weak* classifiers $h_i$ where $i = 1, 2, \\ldots, N$. The goal is to construct a *strong* classifier as a linear superposition of these weak classifiers, that is:\n",
        "\n",
        "$$\n",
        "y = \\sum_{i=1}^N w_i \\, h_i(x)\n",
        "$$\n",
        "\n",
        "where $x$ is a vector of input features and $y \\in \\{-1, 1\\}$. The goal is to find $\\{w_i\\}$, the weights associated with the weak classifiers.\n",
        "\n",
        "Let us have a training set $\\{(x_s, y_s) \\mid s = 1, 2, \\ldots, S\\}$ of size $S$. We can determine optimal weights $w_i$ by minimizing:\n",
        "\n",
        "$$\n",
        "\\min_w \\sum_{s=1}^S \\Biggl[\\sum_{i=1}^N w_i \\, h_i(x_s) - y_s\\Biggr]^2\n",
        "\\;+\\; \\lambda \\sum_{i=1}^N (w_i)^0\n",
        "$$\n",
        "\n",
        "where the regularization term $\\lambda \\sum_{i=1}^N (w_i)^0$ penalizes non-zero weights; $\\lambda$ is the regularization coefficient. Re-arranging the above equation yields,\n",
        "\n",
        "$$\n",
        "\\min_w \\;\n",
        "\\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^N w_i \\, w_j \\sum_{s=1}^S h_i(x_s)\\,h_j(x_s)\n",
        "\\;-\\; \\frac{2}{N}\\sum_{i=1}^N \\sum_{s=1}^S y_s \\, h_i(x_s) \\, w_i\n",
        "\\;+\\; \\lambda \\sum_{i=1}^N (w_i)^0\n",
        "$$\n",
        "\n",
        "where we assume that each weight $w_i$ is an integer. Each weight can be constructed using $D$ qubits as\n",
        "\n",
        "$$\n",
        "w_i\n",
        "= \\sum_{d=0}^{D-1} 2^d\\,x_{i,d}\n",
        "$$\n",
        "\n",
        "where $x_{i,d}$ are binary variables. Navin et al. ([arXiv:0811.0416](https://arxiv.org/abs/0811.0416)) reported that using $D = 1$ yields similar or improved generalized errors compared to $D > 1$. The regularization term $\\lambda \\sum_{i=1}^N (w_i)^0$ only works when $D = 1$, that is, when the weights are binary. The corresponding QUBO is then\n",
        "\n",
        "$$\n",
        "\\min_x \\; x^T (Q + P)\\, x\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "Q_{ij} = \\frac{1}{N} \\sum_{s=1}^S h_i(x_s)\\,h_j(x_s)\n",
        "$$\n",
        "\n",
        "and\n",
        "\n",
        "$$\n",
        "P_{ij}\n",
        "= \\delta_{ij} \\Bigl(\\lambda\n",
        "  - \\frac{2}{N} \\sum_{s=1}^S h_i(x_s)\\,y_s \\Bigr).\n",
        "$$\n",
        "\n",
        "Note that the regularization term is designed to push many weights to zero, so only a subset of the weak classifiers is chosen. In the implementation that follows, we have used decision tree classifiers based on one, two, or three of the features as the weak classifiers.\n"
      ],
      "metadata": {
        "id": "vtNo3vK-MsJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of `qci-client`"
      ],
      "metadata": {
        "id": "TaD5NI4C14mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade \"qci-client<5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8cbfpMd73u2",
        "outputId": "d45ecba2-8273-4de9-dfa5-e70f129032bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qci-client<5\n",
            "  Downloading qci_client-4.5.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: requests<3,>=2.22.1 in /usr/local/lib/python3.10/dist-packages (from qci-client<5) (2.32.3)\n",
            "Collecting requests-futures<2,>=1.0.0 (from qci-client<5)\n",
            "  Downloading requests_futures-1.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx<3,>=2.6.3 (from qci-client<5)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qci-client<5) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from qci-client<5) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.22.1->qci-client<5) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.22.1->qci-client<5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.22.1->qci-client<5) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.22.1->qci-client<5) (2024.12.14)\n",
            "Downloading qci_client-4.5.0-py3-none-any.whl (35 kB)\n",
            "Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_futures-1.0.2-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: networkx, requests-futures, qci-client\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nx-cugraph-cu12 24.10.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\n",
            "scikit-image 0.25.0 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-2.8.8 qci-client-4.5.0 requests-futures-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation QBoost Algorithm\n",
        "\n",
        "We have implemented the QBoost algorithm that was explained above as a class in Python.\n",
        "\n"
      ],
      "metadata": {
        "id": "RrGltR6hTlAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3Miujaw7Vd5"
      },
      "outputs": [],
      "source": [
        "from qci_client import QciClient\n",
        "token = \"xxx\"\n",
        "api_url = \"https://api.qci-prod.com\"\n",
        "qci = QciClient(api_token=token, url=api_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libs\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from functools import wraps\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "\n",
        "PLOT_FLAG = False\n",
        "\n",
        "\n",
        "def timer(func):\n",
        "    @wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        beg_time = time.time()\n",
        "        val = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        tot_time = end_time - beg_time\n",
        "\n",
        "        print(\"Runtime of %s: %0.2f seconds!\" % (func.__name__, tot_time,))\n",
        "\n",
        "        return val\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "class WeakClassifierMLP:\n",
        "    \"\"\"\n",
        "    A simple wrapper that uses a TensorFlow model on a chosen subset of features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, fea_ind_list: List[int], X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the weak classifier.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        fea_ind_list : List[int]\n",
        "            Indices of features to use for this classifier.\n",
        "        X_train : np.ndarray\n",
        "            Training data of shape (num_samples, num_features).\n",
        "        y_train : np.ndarray\n",
        "            Training labels of shape (num_samples,).\n",
        "        \"\"\"\n",
        "        # Validate the shapes\n",
        "        assert X_train.shape[0] == len(y_train), \\\n",
        "            \"X_train and y_train must have the same number of samples.\"\n",
        "\n",
        "        self.fea_ind_list = fea_ind_list\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "        # Create a small TensorFlow model with 3 Dense layers to act as our \"weak\" learner.\n",
        "        # Adjust hidden layer sizes, activations, or optimizer settings as needed.\n",
        "        self.model = Sequential([\n",
        "            Dense(8, activation='relu'),   # First hidden layer\n",
        "            Dense(8, activation='relu'),   # Second hidden layer\n",
        "            Dense(1, activation='sigmoid') # Final output layer for binary classification\n",
        "        ])\n",
        "\n",
        "        self.model.compile(\n",
        "            loss='binary_crossentropy',\n",
        "            optimizer='adam',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"\"\"\n",
        "        Fit the TensorFlow model on the subset of features.\n",
        "        \"\"\"\n",
        "        # Slice X_train to keep only the chosen features\n",
        "        X_subset = self.X_train[:, self.fea_ind_list]\n",
        "\n",
        "        # Fit the classifier. For brevity, we use fewer epochs. Adjust as needed.\n",
        "        self.model.fit(\n",
        "            X_subset,\n",
        "            self.y_train,\n",
        "            epochs=10,       # Lower epoch count to keep it \"weak\"\n",
        "            batch_size=32,\n",
        "            verbose=0        # Suppress training output\n",
        "        )\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Predict labels (+1/-1) for the given samples X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Input data of shape (num_samples, num_features).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Array of predictions (+1 or -1) for each sample.\n",
        "        \"\"\"\n",
        "        # Keep only the chosen features\n",
        "        X_subset = X[:, self.fea_ind_list]\n",
        "\n",
        "        # Model outputs probabilities in [0, 1].\n",
        "        probs = self.model.predict(X_subset)\n",
        "\n",
        "        # Convert to {0,1} by thresholding at 0.5\n",
        "        raw_preds = (probs >= 0.5).astype(int).flatten()\n",
        "\n",
        "        # Convert predictions to {-1, +1} if necessary\n",
        "        unique_labels = np.unique(self.y_train)\n",
        "        if set(unique_labels) == {0, 1}:\n",
        "            # Convert 0 -> -1\n",
        "            converted_preds = np.where(raw_preds == 0, -1, 1)\n",
        "        else:\n",
        "            # If already in {-1, +1}, no conversion needed\n",
        "            converted_preds = raw_preds\n",
        "\n",
        "        return converted_preds\n",
        "\n",
        "\n",
        "class QBoost:\n",
        "    def __init__(\n",
        "        self,\n",
        "        lambda_coef,\n",
        "        num_eqc_samples=10,\n",
        "        alpha=1.0,\n",
        "        theta=0.0,\n",
        "        mode=\"dct\",\n",
        "    ):\n",
        "\n",
        "        self.lambda_coef = lambda_coef\n",
        "        self.num_eqc_samples = num_eqc_samples\n",
        "        self.alpha = alpha\n",
        "        self.theta = theta\n",
        "        self.mode = mode\n",
        "        self.weights = None\n",
        "        self.h_list = None\n",
        "\n",
        "\n",
        "    @timer\n",
        "    def _build_weak_classifiers_dct(self, X: np.ndarray, y: np.ndarray):\n",
        "        S = X.shape[0]\n",
        "        M = X.shape[1]\n",
        "        assert len(y) == S\n",
        "\n",
        "        h_list = []\n",
        "\n",
        "        # Single-feature classifiers\n",
        "        print('Single-feature classifiers')\n",
        "        for l in range(M):\n",
        "            weak_classifier = WeakClassifierMLP([l], X, y)\n",
        "            weak_classifier.train()\n",
        "            h_list.append(weak_classifier)\n",
        "            print('finished with l=', l)\n",
        "\n",
        "        # Pairs of features\n",
        "        print('Pairs of features')\n",
        "        for i in range(M):\n",
        "            for j in range(i + 1, M):\n",
        "                weak_classifier = WeakClassifierMLP([i, j], X, y)\n",
        "                weak_classifier.train()\n",
        "                h_list.append(weak_classifier)\n",
        "                print('finished with i=', i, 'j=', j)\n",
        "\n",
        "        # Triplets of features\n",
        "        # print('Triplets of features')\n",
        "        # for i in range(M):\n",
        "        #     for j in range(i + 1, M):\n",
        "        #         for k in range(j + 1, M):\n",
        "        #             weak_classifier = WeakClassifierMLP([i, j, k], X, y)\n",
        "        #             weak_classifier.train()\n",
        "        #             h_list.append(weak_classifier)\n",
        "        #             print('finished with i=', i, 'j=', j, 'k=', k)\n",
        "\n",
        "        return h_list\n",
        "\n",
        "    @timer\n",
        "    def _get_hamiltonian(self, X, y):\n",
        "\n",
        "        S = X.shape[0]\n",
        "        M = X.shape[1]\n",
        "\n",
        "        if self.mode == \"dct\":\n",
        "            h_list = self._build_weak_classifiers_dct(X, y)\n",
        "            print('h_list', h_list)\n",
        "        else:\n",
        "            assert False, \"Incorrect mode <%s>!\" % self.mode\n",
        "\n",
        "        self.h_list = h_list\n",
        "\n",
        "        N = len(h_list)\n",
        "        print(\"Number of weak classifiers:\", N)\n",
        "\n",
        "        Q = np.zeros(shape=(N, N), dtype=\"d\")\n",
        "        P = np.zeros(shape=(N, N), dtype=\"d\")\n",
        "\n",
        "        h_vals = np.array([h_list[i].predict(X) for i in range(N)])\n",
        "\n",
        "        assert h_vals.shape[0] == N\n",
        "        assert h_vals.shape[1] == S\n",
        "\n",
        "        for i in range(N):\n",
        "            P[i][i] = self.lambda_coef - (2.0 / N) * np.sum(h_vals[i] * y)\n",
        "            for j in range(N):\n",
        "                Q[i][j] = (1.0 / N ** 2) * np.sum(h_vals[i] * h_vals[j])\n",
        "\n",
        "        # Calculate the Hamiltonian\n",
        "        H = Q + P\n",
        "\n",
        "        # make sure H is symmetric up to machine precision\n",
        "        H = 0.5 * (H + H.transpose())\n",
        "\n",
        "        print(\"The size of the hamiltonian is %d by %d\" % (N, N))\n",
        "\n",
        "        return H\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.weights = weights\n",
        "\n",
        "    @timer\n",
        "    def train(self, X, y):\n",
        "\n",
        "        H = self._get_hamiltonian(X, y)\n",
        "\n",
        "        N = H.shape[0]\n",
        "\n",
        "        qubo_json = {\n",
        "            \"file_name\": \"qboost.json\",\n",
        "            \"file_config\": {\n",
        "                \"qubo\": {\"data\": H, \"num_variables\": N},\n",
        "            }\n",
        "        }\n",
        "\n",
        "        job_json = {\n",
        "            \"job_name\": \"qboost_classifier\",\n",
        "            \"job_tags\": [\"qboost\"],\n",
        "            \"params\": {\n",
        "                \"device_type\": \"eqc1\",\n",
        "                \"num_samples\": self.num_eqc_samples,\n",
        "                \"alpha\": self.alpha,\n",
        "            },\n",
        "        }\n",
        "\n",
        "        # Solve the optimization problem\n",
        "        #qci = QciClient()\n",
        "\n",
        "        response_json = qci.upload_file(file=qubo_json)\n",
        "        qubo_file_id = response_json[\"file_id\"]\n",
        "\n",
        "        # Setup job json\n",
        "        job_params = {\n",
        "            \"device_type\": \"dirac-1\",\n",
        "            \"alpha\": self.alpha,\n",
        "            \"num_samples\": self.num_eqc_samples,\n",
        "\n",
        "        }\n",
        "        job_json = qci.build_job_body(\n",
        "            job_type=\"sample-qubo\",\n",
        "            job_params=job_params,\n",
        "            qubo_file_id=qubo_file_id,\n",
        "            job_name=\"tutorial_eqc1\",\n",
        "            job_tags=[\"tutorial_eqc1\"],\n",
        "        )\n",
        "        print(job_json)\n",
        "\n",
        "        # Run the job\n",
        "        job_response_json = qci.process_job(\n",
        "            job_body=job_json,\n",
        "        )\n",
        "\n",
        "        print(job_response_json)\n",
        "\n",
        "        results = job_response_json[\"results\"]\n",
        "        energies = results[\"energies\"]\n",
        "        samples = results[\"solutions\"]\n",
        "\n",
        "        if True:\n",
        "            print(\"Energies:\", energies)\n",
        "\n",
        "        # The sample solutions are sorted by energy\n",
        "        sol = samples[0]\n",
        "\n",
        "        assert len(sol) == N, \"Inconsistent solution size!\"\n",
        "\n",
        "        self.weights = np.array(sol)\n",
        "\n",
        "        return\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        assert self.weights is not None, \"Model is not trained!\"\n",
        "        assert self.h_list is not None, \"Model is not trained!\"\n",
        "\n",
        "        assert len(self.weights) == len(self.h_list), \"Inconsisent sizes!\"\n",
        "\n",
        "        N = len(self.weights)\n",
        "        tmp_vals = np.zeros(shape=(X.shape[0]), dtype=\"d\")\n",
        "\n",
        "        fct = sum(self.weights)\n",
        "        if fct > 0:\n",
        "            fct = 1.0 / fct\n",
        "\n",
        "        for i in range(N):\n",
        "            tmp_vals += self.weights[i] * self.h_list[i].predict(X)\n",
        "\n",
        "        tmp_vals = fct * tmp_vals\n",
        "\n",
        "        pred_vals = np.sign(tmp_vals - self.theta)\n",
        "\n",
        "        for i in range(len(pred_vals)):\n",
        "            if pred_vals[i] == 0:\n",
        "                pred_vals[i] = -1.0\n",
        "\n",
        "        return pred_vals\n",
        "\n",
        "    def save_weights(self, file_name):\n",
        "        np.save(file_name, self.weights)"
      ],
      "metadata": {
        "id": "jbdzyLqd7_hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquire Data: Iris\n",
        "\n",
        "The above class can then be used to build a classifier using the IRIS dataset. We have used 80% of the data for training and the rest is used for testing."
      ],
      "metadata": {
        "id": "TM0X6VjjTqO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "vnwZ0QUQ8Gy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some parameters\n",
        "TEST_SIZE = 0.2\n",
        "LAMBDA_COEF = 1.0"
      ],
      "metadata": {
        "id": "X_xanCLn3LH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "JRrZndFS3PAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtUQHThx8QAo",
        "outputId": "1cd2965b-2a23-4bc5-f8f5-f32dcde01a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquire Data: MNIST"
      ],
      "metadata": {
        "id": "ZC9TLJlxTsw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class DataProcessor:\n",
        "    def __init__(self, patch_size: int = 2, output_dim: int = 128):\n",
        "        \"\"\"\n",
        "        Initializes the DataProcessor with a given patch size and output dimension.\n",
        "\n",
        "        Args:\n",
        "        patch_size (int): The size of the patches to be created.\n",
        "        output_dim (int): The dimensionality of the self-attention output.\n",
        "        \"\"\"\n",
        "        self.patch_size = patch_size\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def normalize_data(self, data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Normalizes the data so that all values are between 0 and 1.\n",
        "\n",
        "        Args:\n",
        "        data (np.ndarray): Input image data.\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Normalized data.\n",
        "        \"\"\"\n",
        "        return data.astype(np.float32) / 255.0\n",
        "\n",
        "    def generate_patches(self, data: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generates patches from the input data. If the image dimensions are not perfectly divisible by patch_size,\n",
        "        it will crop the image to the nearest size divisible by patch_size.\n",
        "\n",
        "        Args:\n",
        "        data (np.ndarray): Input image data of shape (N, H, W, C).\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Patches of shape (N, num_patches, patch_size * patch_size * C).\n",
        "        \"\"\"\n",
        "        batch_size, height, width, channels = data.shape\n",
        "        crop_height = height - (height % self.patch_size)\n",
        "        crop_width = width - (width % self.patch_size)\n",
        "\n",
        "        # Crop the data to make dimensions divisible by patch_size\n",
        "        cropped_data = data[:, :crop_height, :crop_width, :]\n",
        "\n",
        "        num_patches = (crop_height // self.patch_size) * (crop_width // self.patch_size)\n",
        "        patches = np.zeros((batch_size, num_patches, self.patch_size * self.patch_size * channels))\n",
        "\n",
        "        patch_idx = 0\n",
        "        for i in range(0, crop_height, self.patch_size):\n",
        "            for j in range(0, crop_width, self.patch_size):\n",
        "                patch = cropped_data[:, i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "                patches[:, patch_idx, :] = patch.reshape(batch_size, -1)\n",
        "                patch_idx += 1\n",
        "\n",
        "        return patches\n",
        "\n",
        "    def self_attention(self, patches: np.ndarray, batch_size: int = 1024) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies self-attention to the patches to produce an output vector, processing in smaller batches to reduce memory usage.\n",
        "\n",
        "        Args:\n",
        "        patches (np.ndarray): Patches of shape (N, num_patches, patch_dim).\n",
        "        batch_size (int): Number of samples to process in each batch.\n",
        "\n",
        "        Returns:\n",
        "        np.ndarray: Output vectors of shape (N, output_dim).\n",
        "        \"\"\"\n",
        "        num_samples, num_patches, patch_dim = patches.shape\n",
        "        attention_outputs = []\n",
        "\n",
        "        for start in range(0, num_samples, batch_size):\n",
        "            end = min(start + batch_size, num_samples)\n",
        "            batch_patches = patches[start:end]\n",
        "\n",
        "            # Use patches themselves for Query, Key, and Value\n",
        "            queries = batch_patches  # Shape: (batch_size, num_patches, patch_dim)\n",
        "            keys = batch_patches     # Shape: (batch_size, num_patches, patch_dim)\n",
        "            values = batch_patches   # Shape: (batch_size, num_patches, patch_dim)\n",
        "\n",
        "            # Compute attention scores\n",
        "            scores = np.matmul(queries, keys.transpose(0, 2, 1))  # Shape: (batch_size, num_patches, num_patches)\n",
        "            scores = scores / np.sqrt(patch_dim)                  # Scale scores\n",
        "\n",
        "            # Apply softmax to get attention weights\n",
        "            attention_weights = tf.nn.softmax(scores, axis=-1).numpy()  # Shape: (batch_size, num_patches, num_patches)\n",
        "\n",
        "            # Compute the weighted sum of values\n",
        "            weighted_sum = np.matmul(attention_weights, values)  # Shape: (batch_size, num_patches, patch_dim)\n",
        "\n",
        "            # Aggregate output across patches (e.g., mean pooling)\n",
        "            aggregated_output = np.mean(weighted_sum, axis=1)  # Shape: (batch_size, patch_dim)\n",
        "\n",
        "            # Append to results\n",
        "            attention_outputs.append(aggregated_output)\n",
        "\n",
        "        # Concatenate results for all batches\n",
        "        return np.vstack(attention_outputs)\n"
      ],
      "metadata": {
        "id": "FZYWgUDu8SRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Example Usage\n",
        "# Load MNIST data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "X = np.concatenate([x_train, x_test], axis=0)  # Combine training and test images\n",
        "y = np.concatenate([y_train, y_test], axis=0)  # Combine training and test labels\n",
        "\n",
        "# Add channel dimension to images (N, 28, 28, 1)\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "# Initialize DataProcessor\n",
        "processor = DataProcessor(patch_size=3, output_dim=128)\n",
        "\n",
        "# Normalize data\n",
        "X_normalized = processor.normalize_data(X)\n",
        "\n",
        "# Generate patches\n",
        "patches = processor.generate_patches(X_normalized)\n",
        "\n",
        "# Apply self-attention mechanism\n",
        "attention_output = processor.self_attention(patches)\n",
        "\n",
        "# Check dimensions\n",
        "print(\"Original shape:\", X.shape)\n",
        "print(\"Patches shape:\", patches.shape)\n",
        "print(\"Attention output shape:\", attention_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAa_UJnc8XwK",
        "outputId": "7004155e-2c6f-4cb4-dd2f-8cf6ed7b90ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (70000, 28, 28, 1)\n",
            "Patches shape: (70000, 81, 9)\n",
            "Attention output shape: (70000, 9)\n",
            "CPU times: user 7.19 s, sys: 7.07 s, total: 14.3 s\n",
            "Wall time: 14.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_dagger = attention_output\n",
        "\n",
        "print(X.shape)\n",
        "print(X_dagger.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjBms3hz-qY2",
        "outputId": "020251ae-709f-4cc4-f47b-77f9cfd40eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 28, 28, 1)\n",
            "(70000, 9)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzbdSuH6NF_t",
        "outputId": "e71a8cc7-df5b-484b-d4d1-915d000fbb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(y == 6, -1, 1)"
      ],
      "metadata": {
        "id": "G9ixrXgW8PBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training: Calling `QBoost` Model"
      ],
      "metadata": {
        "id": "o2gGgZ1IidoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_dagger, y, test_size=TEST_SIZE, random_state=42,\n",
        ")\n",
        "\n",
        "obj = QBoost(lambda_coef=LAMBDA_COEF, num_eqc_samples=10, alpha=1.0, mode=\"dct\")\n",
        "\n",
        "obj.train(X_train, y_train)\n",
        "\n",
        "y_train_prd = obj.predict(X_train)\n",
        "y_test_prd = obj.predict(X_test)"
      ],
      "metadata": {
        "id": "zG8J4aiJQaLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6ec443-3da1-4b0f-fc9d-e700dd7425d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single-feature classifiers\n",
            "finished with l= 0\n",
            "finished with l= 1\n",
            "finished with l= 2\n",
            "finished with l= 3\n",
            "finished with l= 4\n",
            "finished with l= 5\n",
            "finished with l= 6\n",
            "finished with l= 7\n",
            "finished with l= 8\n",
            "Pairs of features\n",
            "finished with i= 0 j= 1\n",
            "finished with i= 0 j= 2\n",
            "finished with i= 0 j= 3\n",
            "finished with i= 0 j= 4\n",
            "finished with i= 0 j= 5\n",
            "finished with i= 0 j= 6\n",
            "finished with i= 0 j= 7\n",
            "finished with i= 0 j= 8\n",
            "finished with i= 1 j= 2\n",
            "finished with i= 1 j= 3\n",
            "finished with i= 1 j= 4\n",
            "finished with i= 1 j= 5\n",
            "finished with i= 1 j= 6\n",
            "finished with i= 1 j= 7\n",
            "finished with i= 1 j= 8\n",
            "finished with i= 2 j= 3\n",
            "finished with i= 2 j= 4\n",
            "finished with i= 2 j= 5\n",
            "finished with i= 2 j= 6\n",
            "finished with i= 2 j= 7\n",
            "finished with i= 2 j= 8\n",
            "finished with i= 3 j= 4\n",
            "finished with i= 3 j= 5\n",
            "finished with i= 3 j= 6\n",
            "finished with i= 3 j= 7\n",
            "finished with i= 3 j= 8\n",
            "finished with i= 4 j= 5\n",
            "finished with i= 4 j= 6\n",
            "finished with i= 4 j= 7\n",
            "finished with i= 4 j= 8\n",
            "finished with i= 5 j= 6\n",
            "finished with i= 5 j= 7\n",
            "finished with i= 5 j= 8\n",
            "finished with i= 6 j= 7\n",
            "finished with i= 6 j= 8\n",
            "finished with i= 7 j= 8\n",
            "Runtime of _build_weak_classifiers_dct: 1012.57 seconds!\n",
            "h_list [<__main__.WeakClassifierMLP object at 0x7dbef66cab30>, <__main__.WeakClassifierMLP object at 0x7dbef6266290>, <__main__.WeakClassifierMLP object at 0x7dbef4ec3790>, <__main__.WeakClassifierMLP object at 0x7dbed4511a20>, <__main__.WeakClassifierMLP object at 0x7dbed422b3d0>, <__main__.WeakClassifierMLP object at 0x7dbed41528c0>, <__main__.WeakClassifierMLP object at 0x7dbeb055e020>, <__main__.WeakClassifierMLP object at 0x7dbeb03e0370>, <__main__.WeakClassifierMLP object at 0x7dbe9054b5e0>, <__main__.WeakClassifierMLP object at 0x7dbe905b1570>, <__main__.WeakClassifierMLP object at 0x7dbe8bf3c730>, <__main__.WeakClassifierMLP object at 0x7dbe8bf9c550>, <__main__.WeakClassifierMLP object at 0x7dbe842ae7d0>, <__main__.WeakClassifierMLP object at 0x7dbeb06ccca0>, <__main__.WeakClassifierMLP object at 0x7dbe906ea650>, <__main__.WeakClassifierMLP object at 0x7dbe36d77d30>, <__main__.WeakClassifierMLP object at 0x7dbe36a74310>, <__main__.WeakClassifierMLP object at 0x7dbe905b0a90>, <__main__.WeakClassifierMLP object at 0x7dbe306eaf80>, <__main__.WeakClassifierMLP object at 0x7dbe34c9bcd0>, <__main__.WeakClassifierMLP object at 0x7dbe34eb12a0>, <__main__.WeakClassifierMLP object at 0x7dbe304333a0>, <__main__.WeakClassifierMLP object at 0x7dbe34abf400>, <__main__.WeakClassifierMLP object at 0x7dbe30151db0>, <__main__.WeakClassifierMLP object at 0x7dbe36845690>, <__main__.WeakClassifierMLP object at 0x7dbe29d030d0>, <__main__.WeakClassifierMLP object at 0x7dbe29b7caf0>, <__main__.WeakClassifierMLP object at 0x7dbe36904820>, <__main__.WeakClassifierMLP object at 0x7dbe36a744c0>, <__main__.WeakClassifierMLP object at 0x7dbe294ac580>, <__main__.WeakClassifierMLP object at 0x7dbe29e5af20>, <__main__.WeakClassifierMLP object at 0x7dbe29128040>, <__main__.WeakClassifierMLP object at 0x7dbe2840c4c0>, <__main__.WeakClassifierMLP object at 0x7dbe21f93670>, <__main__.WeakClassifierMLP object at 0x7dbe21f3e620>, <__main__.WeakClassifierMLP object at 0x7dbe291283a0>, <__main__.WeakClassifierMLP object at 0x7dbe373d9660>, <__main__.WeakClassifierMLP object at 0x7dbe371a48b0>, <__main__.WeakClassifierMLP object at 0x7dbe37c6b040>, <__main__.WeakClassifierMLP object at 0x7dbe37323340>, <__main__.WeakClassifierMLP object at 0x7dbe37742650>, <__main__.WeakClassifierMLP object at 0x7dbe21c2d0f0>, <__main__.WeakClassifierMLP object at 0x7dbe3784dab0>, <__main__.WeakClassifierMLP object at 0x7dbe219270a0>, <__main__.WeakClassifierMLP object at 0x7dbe21cd4580>]\n",
            "Number of weak classifiers: 45\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 995us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 951us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 988us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step   \n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1000us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 953us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 992us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 969us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 933us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 938us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 952us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 997us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 970us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 996us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977us/step\n",
            "The size of the hamiltonian is 45 by 45\n",
            "Runtime of _get_hamiltonian: 1122.79 seconds!\n",
            "{'job_submission': {'problem_config': {'quadratic_unconstrained_binary_optimization': {'qubo_file_id': '676cc9b65e0855263227517e'}}, 'device_config': {'dirac-1': {'num_samples': 10}}, 'job_name': 'tutorial_eqc1', 'job_tags': ['tutorial_eqc1']}}\n",
            "2024-12-26 03:12:55 - Dirac allocation balance = 585 s\n",
            "2024-12-26 03:12:56 - Job submitted: job_id='676cc9b88dd54d8a9ea6050c'\n",
            "2024-12-26 03:12:56 - QUEUED\n",
            "2024-12-26 03:12:59 - RUNNING\n",
            "2024-12-26 03:15:13 - COMPLETED\n",
            "2024-12-26 03:15:16 - Dirac allocation balance = 581 s\n",
            "{'job_info': {'job_id': '676cc9b88dd54d8a9ea6050c', 'job_submission': {'job_name': 'tutorial_eqc1', 'job_tags': ['tutorial_eqc1'], 'problem_config': {'quadratic_unconstrained_binary_optimization': {'qubo_file_id': '676cc9b65e0855263227517e'}}, 'device_config': {'dirac-1': {'num_samples': 10}}}, 'job_status': {'submitted_at_rfc3339nano': '2024-12-26T03:12:56.103Z', 'queued_at_rfc3339nano': '2024-12-26T03:12:56.104Z', 'running_at_rfc3339nano': '2024-12-26T03:12:56.394Z', 'completed_at_rfc3339nano': '2024-12-26T03:15:12.166Z'}, 'job_result': {'file_id': '676cca405e08552632275180', 'device_usage_s': 4}}, 'status': 'COMPLETED', 'results': {'counts': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'energies': [-36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015], 'solutions': [[0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}}\n",
            "Energies: [-36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015, -36188.000000000015]\n",
            "Runtime of train: 1266.33 seconds!\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1000us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 949us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 974us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 989us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 984us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 949us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 949us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 963us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 974us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step\n",
            "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 965us/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "CPU times: user 26min 20s, sys: 2min 40s, total: 29min 1s\n",
            "Wall time: 23min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_prd.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAtl4iSI-g8k",
        "outputId": "55433518-5c80-4889-ad73-398c99760094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference and Performance"
      ],
      "metadata": {
        "id": "rs85hM1digTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "\n",
        "print(\n",
        "    \"Train precision:\",\n",
        "    precision_score(y_train, y_train_prd, labels=[-1, 1], pos_label=1),\n",
        ")\n",
        "print(\n",
        "    \"Train recall:\",\n",
        "    recall_score(y_train, y_train_prd, labels=[-1, 1], pos_label=1),\n",
        ")\n",
        "print(\n",
        "    \"Train accuracy:\",\n",
        "    accuracy_score(y_train, y_train_prd),\n",
        ")\n",
        "\n",
        "sn.set(font_scale=1.4)\n",
        "train_conf_mat = confusion_matrix(y_train, y_train_prd, labels=[-1, 1])\n",
        "sn.heatmap(train_conf_mat, annot=True, annot_kws={\"size\": 16})\n",
        "plt.show()\n",
        "\n",
        "print(\n",
        "    \"Test precision:\",\n",
        "    precision_score(y_test, y_test_prd, labels=[-1, 1], pos_label=1),\n",
        ")\n",
        "print(\n",
        "    \"Test recall:\",\n",
        "    recall_score(y_test, y_test_prd, labels=[-1, 1], pos_label=1),\n",
        ")\n",
        "print(\n",
        "    \"Test accuracy:\",\n",
        "    accuracy_score(y_test, y_test_prd),\n",
        ")\n",
        "\n",
        "test_conf_mat = confusion_matrix(y_test, y_test_prd, labels=[-1, 1])\n",
        "sn.heatmap(test_conf_mat, annot=True, annot_kws={\"size\": 16})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TGN-Ivno---x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "outputId": "cd24b151-a6c2-4266-b9e4-f2f4b28729df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train precision: 0.9021428571428571\n",
            "Train recall: 1.0\n",
            "Train accuracy: 0.9021428571428571\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test precision: 0.9002857142857142\n",
            "Test recall: 1.0\n",
            "Test accuracy: 0.9002857142857142\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7fh1383xO162"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}