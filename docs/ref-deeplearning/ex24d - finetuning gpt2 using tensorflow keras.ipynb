{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOfEVwYkomCbTdL7Fm0Bh+B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wyz0VY5uCBwO","executionInfo":{"status":"ok","timestamp":1735402304584,"user_tz":300,"elapsed":58640,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"491610c5-c849-4801-f82e-b8e813b676e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for keras-hub (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["! pip install git+https://github.com/keras-team/keras-hub.git -q"]},{"cell_type":"markdown","source":["Large Language Models are complex to build and expensive to train from scratch. Luckily there are pretrained LLMs available for use right away. KerasHub provides a large number of pre-trained checkpoints that allow you to experiment with SOTA models without needing to train them yourself.\n","\n","KerasHub is a natural language processing library that supports users through their entire development cycle. KerasHub offers both pretrained models and modularized building blocks, so developers could easily reuse pretrained models or stack their own LLM.\n","\n","In a nutshell, for generative LLM, KerasHub offers:\n","\n","Pretrained models with generate() method, e.g., keras_hub.models.GPT2CausalLM and keras_hub.models.OPTCausalLM.\n","Sampler class that implements generation algorithms such as Top-K, Beam and contrastive search. These samplers can be used to generate text with custom models."],"metadata":{"id":"rmREJQnQCUx0"}},{"cell_type":"code","source":["import os\n","\n","os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n","\n","import keras_hub\n","import keras\n","import tensorflow as tf\n","import time\n","\n","keras.mixed_precision.set_global_policy(\"mixed_float16\")"],"metadata":{"id":"HayWyxmyCHsW","executionInfo":{"status":"ok","timestamp":1735402308438,"user_tz":300,"elapsed":3865,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["KerasHub provides a number of pre-trained models, such as Google Bert and GPT-2. You can see the list of models available in the KerasHub repository.\n","\n","It's very easy to load the GPT-2 model as you can see below:"],"metadata":{"id":"HzHfInEzCRsD"}},{"cell_type":"code","source":["# To speed up training and generation, we use preprocessor of length 128\n","# instead of full length 1024.\n","preprocessor = keras_hub.models.GPT2CausalLMPreprocessor.from_preset(\n","    \"gpt2_base_en\",\n","    sequence_length=128,\n",")\n","gpt2_lm = keras_hub.models.GPT2CausalLM.from_preset(\n","    \"gpt2_base_en\", preprocessor=preprocessor\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8STdlkk4CLio","executionInfo":{"status":"ok","timestamp":1735402371082,"user_tz":300,"elapsed":62661,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"d6b88038-0a9b-4b80-a846-2aeefd4c5168"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/3/download/config.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 431/431 [00:00<00:00, 494kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/3/download/tokenizer.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 618/618 [00:00<00:00, 721kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/3/download/assets/tokenizer/vocabulary.json...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 0.99M/0.99M [00:01<00:00, 658kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/3/download/assets/tokenizer/merges.txt...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 446k/446k [00:01<00:00, 438kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gpt2/keras/gpt2_base_en/3/download/model.weights.h5...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 475M/475M [00:31<00:00, 16.0MB/s]\n"]}]},{"cell_type":"code","source":["start = time.time()\n","\n","output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n","print(\"\\nGPT-2 output:\")\n","print(output)\n","\n","end = time.time()\n","print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9q7_VTZCOxA","executionInfo":{"status":"ok","timestamp":1735402406438,"user_tz":300,"elapsed":9444,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"444be6ad-2fc7-447d-ce29-0e4e86b76113"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","GPT-2 output:\n","My trip to Yosemite was the most interesting part of my trip. The first time I went, it was the first time I ever spent in Yosemite. It was the first time I ever went out on my own. The only time I've ever been to Yosemite was during my first day of hiking and my first day of camping. The first time I ever went to Yosemite was during my first day of hiking and my first day of camping.\n","\n","I was a little surprised to find that the only time I went to Yosemite was in the winter months. I was not in the winter months. I was not hiking in the fall or winter months. I was in the winter months, and I didn't even think of the winter months as winter months. I was not in Yosemite. My only time there was in the winter months was when I was at my first campground.\n","\n","I was surprised to find that the only time I ever went to Yosemite was during my first day of hiking\n","TOTAL TIME ELAPSED: 9.18s\n"]}]},{"cell_type":"markdown","source":["Try another one:"],"metadata":{"id":"bFfMtJOYC4gh"}},{"cell_type":"code","source":["start = time.time()\n","\n","output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n","print(\"\\nGPT-2 output:\")\n","print(output)\n","\n","end = time.time()\n","print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BAU6SUShCxwP","executionInfo":{"status":"ok","timestamp":1735402430053,"user_tz":300,"elapsed":1985,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"8fff38ef-aa11-4e5d-d149-eba4d00b9646"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","GPT-2 output:\n","That Italian restaurant is called \"Bella Bella\" in Italy and is the place where the \"Bella Bella\" restaurant was founded in 1885.\n","\n","\"It was a very important Italian restaurant,\" said Italian restaurant historian and author Giuseppe Giorgi. \"The name was given because it was an Italian restaurant and not because it was a good restaurant.\"\n","\n","The restaurant was opened in 1885, and its name changed in the 1920s.\n","\n","\"It's a very popular place in Florence, but we don't see any restaurants here,\" said Giuseppe. \"The place is still in a very good condition, and it's a good place. The restaurant is a good restaurant and is a good restaurant in a good state. But we have a problem with the fact the restaurant is a good restaurant. It's not good in Italy, because the Italians were always very good at Italian food, so the Italians are the ones who made it.\"\n","\n","TOTAL TIME ELAPSED: 1.70s\n"]}]},{"cell_type":"markdown","source":["Now you have the knowledge of the GPT-2 model from KerasHub, you can take one step further to finetune the model so that it generates text in a specific style, short or long, strict or casual. In this tutorial, we will use reddit dataset for example."],"metadata":{"id":"EsFvig96C9Lr"}},{"cell_type":"code","source":["!# Load chinese poetry dataset.\n","!git clone https://github.com/chinese-poetry/chinese-poetry.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcNSpmFpC5V2","executionInfo":{"status":"ok","timestamp":1735402519939,"user_tz":300,"elapsed":22364,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"f5cb822e-d9ef-4206-882a-a93061aa509e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'chinese-poetry'...\n","remote: Enumerating objects: 7326, done.\u001b[K\n","remote: Counting objects: 100% (7/7), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 7326 (delta 4), reused 2 (delta 2), pack-reused 7319 (from 2)\u001b[K\n","Receiving objects: 100% (7326/7326), 236.98 MiB | 14.48 MiB/s, done.\n","Resolving deltas: 100% (5005/5005), done.\n","Updating files: 100% (2285/2285), done.\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","\n","poem_collection = []\n","for file in os.listdir(\"chinese-poetry/全唐诗\"):\n","    if \".json\" not in file or \"poet\" not in file:\n","        continue\n","    full_filename = \"%s/%s\" % (\"chinese-poetry/全唐诗\", file)\n","    with open(full_filename, \"r\") as f:\n","        content = json.load(f)\n","        poem_collection.extend(content)\n","\n","paragraphs = [\"\".join(data[\"paragraphs\"]) for data in poem_collection]"],"metadata":{"id":"1zN5MeWmC_rd","executionInfo":{"status":"ok","timestamp":1735402526253,"user_tz":300,"elapsed":2516,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["type(paragraphs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orbssf9CDQrV","executionInfo":{"status":"ok","timestamp":1735402529398,"user_tz":300,"elapsed":3,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"239de46f-cf47-4259-a433-c3f8e27b54c1"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["len(paragraphs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTKov8acDSA8","executionInfo":{"status":"ok","timestamp":1735402534208,"user_tz":300,"elapsed":255,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"f9e48b16-15e1-4db4-d59f-446a34dd57b4"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["311855"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["paragraphs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"jnm7w5EhDTMk","executionInfo":{"status":"ok","timestamp":1735402541795,"user_tz":300,"elapsed":269,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"7e15219c-cf7e-452e-8a31-d5ac4e9714a2"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'半依籬脚半依城，多傍梅邊水際亭。最是晚晴斜照裏，黄金日射萬銀星。'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["Convert to TF dataset, and only use partial data to train"],"metadata":{"id":"Ha9G1mrhDZhW"}},{"cell_type":"code","source":["train_ds = (\n","    tf.data.Dataset.from_tensor_slices(paragraphs)\n","    .batch(16)\n","    .cache()\n","    .prefetch(tf.data.AUTOTUNE)\n",")"],"metadata":{"id":"TwfL0HmiDacO","executionInfo":{"status":"ok","timestamp":1735402571830,"user_tz":300,"elapsed":1401,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["type(train_ds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"sHS_zFL1DcGS","executionInfo":{"status":"ok","timestamp":1735402573817,"user_tz":300,"elapsed":4,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"0e33002f-fe71-436b-ab07-cf0104ff383b"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.data.ops.prefetch_op._PrefetchDataset"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 31);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["%%time\n","\n","# Running through the whole dataset takes long, only take `500` and run 1\n","# epochs for demo purposes.\n","train_ds = train_ds.take(500)\n","num_epochs = 1\n","\n","learning_rate = keras.optimizers.schedules.PolynomialDecay(\n","    5e-4,\n","    decay_steps=train_ds.cardinality() * num_epochs,\n","    end_learning_rate=0.0,\n",")\n","loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","gpt2_lm.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate),\n","    loss=loss,\n","    weighted_metrics=[\"accuracy\"],\n",")\n","\n","gpt2_lm.fit(train_ds, epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14K0bW1LDc2d","executionInfo":{"status":"ok","timestamp":1735402749603,"user_tz":300,"elapsed":124879,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"8748e4e7-9c3b-44ce-d4ed-d8f60e3cdfc8"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 180ms/step - accuracy: 0.2564 - loss: 2.5333\n","CPU times: user 2min 16s, sys: 2.95 s, total: 2min 19s\n","Wall time: 2min 3s\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7d55bc2bb610>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["output = gpt2_lm.generate(\"昨夜雨疏风骤\", max_length=200)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxRd53tIDpWg","executionInfo":{"status":"ok","timestamp":1735402781177,"user_tz":300,"elapsed":6890,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"b1b82930-8bd1-43a2-d401-48a1a80b8dae"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["昨夜雨疏风骤，曾風臺知時秦。頭聞頭求書書，秋風雲樹自香。\n"]}]}]}