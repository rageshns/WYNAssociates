{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDOTqUaFcOgE"
      },
      "source": [
        "# Create and Train Transformer from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zynAdpcGbr7v"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI5IQVJma4ru"
      },
      "source": [
        "This code implements key components for building a Transformer model in TensorFlow. It includes a function for scaled dot-product attention, which calculates attention scores between query, key, and value tensors. The `MultiHeadAttention` class extends TensorFlow's Layer class to apply multiple attention heads in parallel, enhancing the model's ability to focus on different parts of the input. Additionally, a position-wise feed-forward network and positional encoding functions are defined, essential for capturing the sequence order of the input data. The positional encoding function computes positional encodings using sine and cosine functions to maintain the order of input tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdNdlevtCzu5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n",
        "import numpy as np\n",
        "\n",
        "# Define a scaled dot-product attention function\n",
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    if mask is not None:\n",
        "        logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "# Define multi-head attention layer\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = Dense(d_model)\n",
        "        self.wk = Dense(d_model)\n",
        "        self.wv = Dense(d_model)\n",
        "\n",
        "        self.dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask=None):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, _ = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Define position-wise feed-forward network\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        Dense(dff, activation='relu'),\n",
        "        Dense(d_model)\n",
        "    ])\n",
        "\n",
        "# Define positional encoding\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiSVncUObu6B"
      },
      "source": [
        "## Define `EncoderLayer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWslS1mOa9uc"
      },
      "source": [
        "The code defines a Transformer encoder using TensorFlow's Keras API. The `EncoderLayer` class represents a single encoder layer with multi-head attention and a feed-forward neural network, each followed by layer normalization and dropout for regularization. The `Encoder` class constructs a stack of multiple `EncoderLayer` instances, embedding input sequences and adding positional encodings to capture sequence information. The encoder processes input sequences through these layers, applying attention mechanisms and feed-forward networks iteratively, ultimately outputting a processed representation suitable for tasks like machine translation or text classification. Both classes utilize dropout for regularization and are designed to handle variable-length input sequences with optional masking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPGOcKEtasx0"
      },
      "outputs": [],
      "source": [
        "# Define encoder layer\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        attn_output = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n",
        "\n",
        "# Define the Transformer encoder\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GBmO6Fzbxez"
      },
      "source": [
        "## Define `TransformerModel`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmI1mN7ibC9C"
      },
      "source": [
        "The provided code defines a custom TensorFlow Transformer model class `TransformerModel` using Keras. The class is decorated with `@tf.keras.utils.register_keras_serializable()` to enable serialization and deserialization. It initializes with model parameters such as the number of layers, model dimensions, attention heads, feed-forward network size, input vocabulary size, position encoding, and dropout rate. The model consists of an encoder layer and a final dense output layer. The `call` method performs a forward pass through the encoder and final layer. `get_config` and `from_config` methods handle the model's configuration serialization and deserialization, allowing the model to be saved and loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_ijbg-WWMZr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class TransformerModel(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1, **kwargs):\n",
        "        # Pass any additional keyword arguments to the parent class\n",
        "        super(TransformerModel, self).__init__(**kwargs)\n",
        "\n",
        "        # Store the model parameters\n",
        "        self.num_layers = num_layers\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dff = dff\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.maximum_position_encoding = maximum_position_encoding\n",
        "        self.rate = rate\n",
        "\n",
        "        # Define the layers\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate)\n",
        "        self.final_layer = tf.keras.layers.Dense(input_vocab_size)\n",
        "\n",
        "    def call(self, x, training=False, mask=None):\n",
        "        enc_output = self.encoder(x, training=training, mask=mask)\n",
        "        final_output = self.final_layer(enc_output)\n",
        "        return final_output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerModel, self).get_config()\n",
        "        config.update({\n",
        "            \"num_layers\": self.num_layers,\n",
        "            \"d_model\": self.d_model,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dff\": self.dff,\n",
        "            \"input_vocab_size\": self.input_vocab_size,\n",
        "            \"maximum_position_encoding\": self.maximum_position_encoding,\n",
        "            \"rate\": self.rate\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obZaoobHbz6T"
      },
      "source": [
        "### Run a `.fit` method with toy data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuI-9_FwVSSY",
        "outputId": "c538884c-2a8e-4344-a354-29382373b152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 15.9414\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 15.3905\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0014 - loss: 14.8311    \n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0014 - loss: 14.4278    \n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 8.2237e-04 - loss: 14.3109\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ca99617e3b0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "num_layers = 2\n",
        "d_model = 64\n",
        "dff = 128\n",
        "num_heads = 4\n",
        "input_vocab_size = 8500\n",
        "maximum_position_encoding = 10000\n",
        "\n",
        "# Instantiate the Transformer model\n",
        "transformer = TransformerModel(num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding)\n",
        "\n",
        "# Compile the model\n",
        "transformer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generate random sample data\n",
        "sample_data = np.random.randint(0, input_vocab_size, size=(64, 38))\n",
        "\n",
        "# Fit the model on the random sample data\n",
        "transformer.fit(sample_data, sample_data, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YySx9ZoIbMUd"
      },
      "source": [
        "The code imports TensorFlow, pandas, numpy, and Keras preprocessing utilities, then creates a pandas DataFrame containing sample question-answer pairs. The DataFrame, `df`, is manually populated with a dictionary containing questions (e.g., \"What is the capital of France?\") and their corresponding answers (e.g., \"The capital of France is Paris.\"). An alternative option to create the DataFrame from a CSV file is provided but commented out. The code initializes the data processing environment, potentially for further natural language processing (NLP) tasks such as tokenization or sequence padding using TensorFlow and Keras tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyAIZNZDb395"
      },
      "source": [
        "## Create a `pd` dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "7rqHJODjFyhm",
        "outputId": "5c140050-a7e5-4173-b4d0-41a18430ab43"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"How many continents are there?\",\n          \"Who wrote the play Hamlet?\",\n          \"What is the capital of France?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"There are seven continents.\",\n          \"William Shakespeare wrote Hamlet.\",\n          \"The capital of France is Paris.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3b97cf2f-a47c-4fa1-bc45-54d097f38f82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How many continents are there?</td>\n",
              "      <td>There are seven continents.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the largest mammal?</td>\n",
              "      <td>The blue whale is the largest mammal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who wrote the play Hamlet?</td>\n",
              "      <td>William Shakespeare wrote Hamlet.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b97cf2f-a47c-4fa1-bc45-54d097f38f82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b97cf2f-a47c-4fa1-bc45-54d097f38f82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b97cf2f-a47c-4fa1-bc45-54d097f38f82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-250273d9-91ee-4cd3-973f-e505fe06a737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-250273d9-91ee-4cd3-973f-e505fe06a737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-250273d9-91ee-4cd3-973f-e505fe06a737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a99122d6-5ccb-4ec1-a839-f3b134b780ec\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a99122d6-5ccb-4ec1-a839-f3b134b780ec button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                         question                                 answer\n",
              "0  What is the capital of France?        The capital of France is Paris.\n",
              "1  How many continents are there?            There are seven continents.\n",
              "2     What is the largest mammal?  The blue whale is the largest mammal.\n",
              "3      Who wrote the play Hamlet?      William Shakespeare wrote Hamlet."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Create a sample pandas DataFrame\n",
        "data = {\n",
        "    'question': [\n",
        "        'What is the capital of France?',\n",
        "        'How many continents are there?',\n",
        "        'What is the largest mammal?',\n",
        "        'Who wrote the play Hamlet?'\n",
        "    ],\n",
        "    'answer': [\n",
        "        'The capital of France is Paris.',\n",
        "        'There are seven continents.',\n",
        "        'The blue whale is the largest mammal.',\n",
        "        'William Shakespeare wrote Hamlet.'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Or read it from directory\n",
        "# data = pd.DataFrame(\"test.csv\")\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N4twszBMBMw_",
        "outputId": "8c725bf3-fa8d-46cc-890e-4a50eb38d22c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"questions\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Please help me create a picture book with the theme of\\nTwo brave rabbit siblings embark on a journey to find the legendary Gravity Carrot, said to grant the power of defying gravity to those brave enough to eat it.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\",\n          \"Please help me create a picture book with the theme of\\nTwo adventurous mice stumble upon a mysterious old book that brings their favorite fairy tales to life, leading them on a whirlwind journey through classic stories.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\",\n          \"Please help me create a picture book with the theme of\\nA courageous young hedgehog named Clover sets off to find the legendary Four-Leaf Clover, the key to bringing good luck and prosperity to her village.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \" Title: The Quest for the Gravity Carrot\\n\\n---\\n\\n# Cover Page:\\n(Illustration: Two adventurous-looking rabbit siblings, one wearing a tiny backpack and the other with a map, standing at the edge of a lush, mysterious forest, gazing up at a twinkling star.)\\n\\n---\\n\\n# Page 1:\\n(Illustration: The two rabbit siblings, Lily and Max, in their cozy burrow, surrounded by old books and maps.)\\nText: In the heart of Whispering Woods, young Lily and Max had heard tales of a magical carrot, buried deep within the Enchanted Glade. This was no ordinary carrot; it was the legendary Gravity Carrot, said to give the power to hop as high as the sky!\\n\\n---\\n\\n# Page 2:\\n(Illustration: The siblings setting off at dawn, with the rising sun behind them and the forest ahead, filled with colorful birds and flowers.)\\nText: With a map in one paw and determination in their hearts, Lily and Max set out at the break of day. Their journey promised great adventures, and perhaps, a touch of danger.\\n\\n---\\n\\n# Page 3:\\n(Illustration: Encountering a tricky river, its waters swirling with shimmering fish.)\\nText: Their first challenge was the Mirror River, which flowed faster than the wind. But working together, Lily cleverly built a bridge with fallen logs while Max kept a lookout for sneaky foxes.\\n\\n---\\n\\n# Page 4:\\n(Illustration: Climbing a steep, rocky hill, their faces showing strain but also excitement.)\\nText: Next came the Rocky Rise, a hill so steep that each step seemed a battle against gravity itself. \\\"Imagine how easy this climb will be once we find the Gravity Carrot!\\\" Max panted, smiling through the effort.\\n\\n---\\n\\n# Page 5:\\n(Illustration: A wise old owl in a tree, speaking to the intrepid siblings.)\\nText: At the hill\\u2019s peak, they met Old Oswald, the wise owl. He spoke in riddles but offered them a clue, \\\"The Gravity Carrot lies hidden where the ground touches the sky.\\\"\\n\\n---\\n\\n# Page 6:\\n(Illustration: Entering a mysterious cave that glows with an ethereal light.)\\nText: Their clue led them to the Whispering Cave, lit by glowworms that cast eerie shadows. It was here, amidst whispers of the past, that the path to the Enchanted Glade was revealed.\\n\\n---\\n\\n# Page 7:\\n(Illustration: The siblings, looking in awe at a spectacular glade with floating stones and beams of light piercing through.)\\nText: The Enchanted Glade was more beautiful than they had imagined. Stones floated, defying gravity, and there, in the center, shone the bright orange Gravity Carrot.\\n\\n---\\n\\n# Page 8:\\n(Illustration: Lily reaching out to grab the Gravity Carrot, as the flora and fauna around seem to watch in silent anticipation.)\\nText: With hearts racing, Lily reached for the carrot. As her fingers touched its smooth surface, the glade shimmered, and a gentle breeze lifted them off their feet.\\n\\n---\\n\\n# Page 9:\\n(Illustration: Joyfully hopping high above the trees, the siblings experiencing the thrill of floating with a backdrop of the setting sun.)\\nText: With the power of the Gravity Carrot, Lily and Max could hop higher than ever before. Laughing joyfully, they realized that the real magic was not just in the carrot, but in the bravery and love shared between them on their incredible journey.\\n\\n---\\n\\n# Page 10:\\n(Illustration: Returning home under starlight, the siblings share their story with their family, who listen in amazement.)\\nText: As they returned home, their spirits as light as their hops, Lily and Max knew that this adventure would be one of many. For the world was wide, and their curiosity was endless.\\n\\n---\\n\\nThis picture book invites young readers into a world of adventure, promoting courage, teamwork, and the joys of discovering the unknown together. Each illustration aims to capture the essence of the journey, pulling children into the magical world of Lily and Max.\",\n          \" Title: ***Mice and Magic: A Fairy Tale Adventure***\\n\\n---\\n\\n# Cover Page\\n**Illustration:** Two small, eager-eyed mice with backpacks standing on a stack of giant books, the topmost book aglow with shimmering, golden light spilling from its slightly open cover.\\n\\n---\\n\\n# Page 1\\n**Text:** In the quiet corner of an old library, Minnie and Max, two curious mice, discovered a book unlike any other. Its cover shimmered with a mysterious glow that whispered secrets of old.\\n\\n**Illustration:** A dusty library corner with books piled high. Minnie and Max, with tiny lanterns, are approaching a large, glowing book.\\n\\n---\\n\\n# Page 2\\n**Text:** As Max gently opened the book, a whirlwind of light enveloped them. When the light settled, they found themselves in a vast forest, the world of \\\"Little Red Riding Hood.\\\"\\n\\n**Illustration:** The mice, looking surprised and a bit tousled, standing in a lush, green forest. A path and a distant cottage are visible.\\n\\n---\\n\\n# Page 3\\n**Text:** They helped Red Riding Hood find her way to Grandma's house and outsmart the sly wolf hiding in the woods. Their courage had never been so tested!\\n\\n**Illustration:** Minnie and Max, advising a small girl in a red cape, pointing towards a safe path, while eyeing a shadowy figure behind a tree.\\n\\n---\\n\\n# Page 4\\n**Text:** With a flicker of light, the forest faded, and they landed next in the world of \\\"Jack and the Beanstalk.\\\" A giant beanstalk towered into the clouds above them.\\n\\n**Illustration:** Max and Minnie looking up in awe at a towering beanstalk that stretches up beyond the clouds.\\n\\n---\\n\\n# Page 5\\n**Text:** Climbing the beanstalk, they reached the giant\\u2019s castle in the sky. With cleverness and stealth, they helped Jack steal back the golden harp and escape.\\n\\n**Illustration:** The mice, tiptoeing behind Jack, as they sneak past a sleeping giant. A golden harp glimmers on the table.\\n\\n---\\n\\n# Page 6\\n**Text:** No sooner had they descended than the book whisked them away to Cinderella\\u2019s ball. They helped Cinderella find her glass slipper, lost in the flurry of her midnight escape.\\n\\n**Illustration:** A grand ballroom with a prince holding a glass slipper. Minnie and Max are helping a distressed Cinderella.\\n\\n---\\n\\n# Page 7\\n**Text:** Each tale brought new friends and adventures. As dawn approached, the magic book began to glow softly, signaling the time to return.\\n\\n**Illustration:** The two mice, surrounded by all the characters they've met, near the glowing book.\\n\\n---\\n\\n# Page 8\\n**Text:** With a final burst of light, Minnie and Max found themselves back in their library corner, the book closed gently before them. The magic of fairy tales had become part of their own story.\\n\\n**Illustration:** The mice, exhausted but happy, nestled among their library books, the magical book closed and still glowing faintly.\\n\\n---\\n\\n# Page 9\\n**Text:** Now, whenever they felt the urge for adventure, Minnie and Max knew that incredible journeys were just a page turn away.\\n\\n**Illustration:** The mice, now comfortably reading the magical book, with faint images of their adventures visible in the glow around them.\\n\\n---\\n\\nThis picture book combines the charm of classic fairy tales with the thrill of new adventures, inspiring children to read and imagine themselves in their favorite stories.\",\n          \" Title: Clover's Quest for Luck\\n\\n Cover Page Illustration:\\nA vibrant illustration of Clover, a small, determined hedgehog with a bright green backpack, standing at the edge of a lush, winding forest path that disappears into a mysterious, magical forest.\\n\\n Page 1 Illustration:\\nClover waves goodbye to her fellow villagers, a variety of small, cheerful animals gathered at the edge of the village.\\n\\n**Text:** In the heart of a bustling woodland, where creatures big and small lived in harmony, there stood a village facing tough times. Food was scarce, and spirits were low. But Clover, the youngest hedgehog, believed in legends and tales, especially one: the legendary Four-Leaf Clover that promised endless good luck and prosperity.\\n\\n Page 2 Illustration:\\nClover at her home, pouring over old books and maps by candlelight, her face lit with determination and curiosity.\\n\\n**Text:** Night after night, Clover researched and planned. She knew her journey wouldn\\u2019t be easy, but her heart was as fierce as her quills. With a map she\\u2019d drawn herself and a backpack filled with essentials, she was ready to find the legendary clover to save her village.\\n\\n Page 3 Illustration:\\nClover stepping bravely into the forest, the trees tall and the path curvy and narrow, sunbeams piercing through the leaves.\\n\\n**Text:** The forest was thick with whispering winds and rustling leaves. Clover walked with courage, her tiny feet steady on the uneven path. The deeper she went, the more the forest seemed alive, watching her every move with curious eyes.\\n\\n Page 4 Illustration:\\nClover meeting a wise old owl perched on a gnarled tree branch, under the moonlight.\\n\\n**Text:** As night fell, Clover met a wise old owl who spoke of the clover\\u2019s guarded location. \\u201cBeneath the moon\\u2019s peak, through the thickest part of the forest, lies the glade of fortune where the four-leaf clover grows,\\u201d hooted the owl. Clover listened intently, her resolve growing stronger.\\n\\n Page 5 Illustration:\\nClover navigating through a tricky part of the forest, avoiding thorns and pits, using a stick to help her along.\\n\\n**Text:** The path became treacherous, filled with thorns and hidden pits. But Clover cleverly used a stick to check the ground and pushed through the underbrush with brave, careful steps. Each obstacle she overcame filled her with pride and confidence.\\n\\n Page 6 Illustration:\\nA magical glade illuminated by moonlight, the four-leaf clover glowing in the center, surrounded by other normal clovers.\\n\\n**Text:** Finally, after what seemed like an eternity, Clover entered a moonlit glade. There, right in the center, was the glowing Four-Leaf Clover. It was more beautiful than she had imagined, its leaves shimmering with an enchanting light.\\n\\n Page 7 Illustration:\\nClover reaching out gently to pluck the clover, with various woodland creatures watching in awe and hope.\\n\\n**Text:** With a gentle touch, Clover plucked the clover, feeling a warm rush of energy. The woodland creatures gathered around, their eyes wide with wonder and hope. They knew their village was saved.\\n\\n Page 8 Illustration:\\nClover returning to her village, greeted as a hero by the joyful villagers. Celebrations and joyous scenes fill the page.\\n\\n**Text:** Clover returned as a hero, her journey a testament to her bravery and determination. With the legendary Four-Leaf Clover in hand, her village flourished. Food was plentiful, and happiness returned. Clover\\u2019s adventure taught everyone the power of courage and belief in the magical.\\n\\n Back Cover:\\nA serene illustration of the village in prosperity, Clover playing joyfully with other young animals, the four-leaf clover framed proudly in the village square.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"### Human: Please help me create a picture book with the theme of\\nTwo brave rabbit siblings embark on a journey to find the legendary Gravity Carrot, said to grant the power of defying gravity to those brave enough to eat it.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: The Quest for the Gravity Carrot\\n\\n---\\n\\n# Cover Page:\\n(Illustration: Two adventurous-looking rabbit siblings, one wearing a tiny backpack and the other with a map, standing at the edge of a lush, mysterious forest, gazing up at a twinkling star.)\\n\\n---\\n\\n# Page 1:\\n(Illustration: The two rabbit siblings, Lily and Max, in their cozy burrow, surrounded by old books and maps.)\\nText: In the heart of Whispering Woods, young Lily and Max had heard tales of a magical carrot, buried deep within the Enchanted Glade. This was no ordinary carrot; it was the legendary Gravity Carrot, said to give the power to hop as high as the sky!\\n\\n---\\n\\n# Page 2:\\n(Illustration: The siblings setting off at dawn, with the rising sun behind them and the forest ahead, filled with colorful birds and flowers.)\\nText: With a map in one paw and determination in their hearts, Lily and Max set out at the break of day. Their journey promised great adventures, and perhaps, a touch of danger.\\n\\n---\\n\\n# Page 3:\\n(Illustration: Encountering a tricky river, its waters swirling with shimmering fish.)\\nText: Their first challenge was the Mirror River, which flowed faster than the wind. But working together, Lily cleverly built a bridge with fallen logs while Max kept a lookout for sneaky foxes.\\n\\n---\\n\\n# Page 4:\\n(Illustration: Climbing a steep, rocky hill, their faces showing strain but also excitement.)\\nText: Next came the Rocky Rise, a hill so steep that each step seemed a battle against gravity itself. \\\"Imagine how easy this climb will be once we find the Gravity Carrot!\\\" Max panted, smiling through the effort.\\n\\n---\\n\\n# Page 5:\\n(Illustration: A wise old owl in a tree, speaking to the intrepid siblings.)\\nText: At the hill\\u2019s peak, they met Old Oswald, the wise owl. He spoke in riddles but offered them a clue, \\\"The Gravity Carrot lies hidden where the ground touches the sky.\\\"\\n\\n---\\n\\n# Page 6:\\n(Illustration: Entering a mysterious cave that glows with an ethereal light.)\\nText: Their clue led them to the Whispering Cave, lit by glowworms that cast eerie shadows. It was here, amidst whispers of the past, that the path to the Enchanted Glade was revealed.\\n\\n---\\n\\n# Page 7:\\n(Illustration: The siblings, looking in awe at a spectacular glade with floating stones and beams of light piercing through.)\\nText: The Enchanted Glade was more beautiful than they had imagined. Stones floated, defying gravity, and there, in the center, shone the bright orange Gravity Carrot.\\n\\n---\\n\\n# Page 8:\\n(Illustration: Lily reaching out to grab the Gravity Carrot, as the flora and fauna around seem to watch in silent anticipation.)\\nText: With hearts racing, Lily reached for the carrot. As her fingers touched its smooth surface, the glade shimmered, and a gentle breeze lifted them off their feet.\\n\\n---\\n\\n# Page 9:\\n(Illustration: Joyfully hopping high above the trees, the siblings experiencing the thrill of floating with a backdrop of the setting sun.)\\nText: With the power of the Gravity Carrot, Lily and Max could hop higher than ever before. Laughing joyfully, they realized that the real magic was not just in the carrot, but in the bravery and love shared between them on their incredible journey.\\n\\n---\\n\\n# Page 10:\\n(Illustration: Returning home under starlight, the siblings share their story with their family, who listen in amazement.)\\nText: As they returned home, their spirits as light as their hops, Lily and Max knew that this adventure would be one of many. For the world was wide, and their curiosity was endless.\\n\\n---\\n\\nThis picture book invites young readers into a world of adventure, promoting courage, teamwork, and the joys of discovering the unknown together. Each illustration aims to capture the essence of the journey, pulling children into the magical world of Lily and Max.\",\n          \"### Human: Please help me create a picture book with the theme of\\nTwo adventurous mice stumble upon a mysterious old book that brings their favorite fairy tales to life, leading them on a whirlwind journey through classic stories.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: ***Mice and Magic: A Fairy Tale Adventure***\\n\\n---\\n\\n# Cover Page\\n**Illustration:** Two small, eager-eyed mice with backpacks standing on a stack of giant books, the topmost book aglow with shimmering, golden light spilling from its slightly open cover.\\n\\n---\\n\\n# Page 1\\n**Text:** In the quiet corner of an old library, Minnie and Max, two curious mice, discovered a book unlike any other. Its cover shimmered with a mysterious glow that whispered secrets of old.\\n\\n**Illustration:** A dusty library corner with books piled high. Minnie and Max, with tiny lanterns, are approaching a large, glowing book.\\n\\n---\\n\\n# Page 2\\n**Text:** As Max gently opened the book, a whirlwind of light enveloped them. When the light settled, they found themselves in a vast forest, the world of \\\"Little Red Riding Hood.\\\"\\n\\n**Illustration:** The mice, looking surprised and a bit tousled, standing in a lush, green forest. A path and a distant cottage are visible.\\n\\n---\\n\\n# Page 3\\n**Text:** They helped Red Riding Hood find her way to Grandma's house and outsmart the sly wolf hiding in the woods. Their courage had never been so tested!\\n\\n**Illustration:** Minnie and Max, advising a small girl in a red cape, pointing towards a safe path, while eyeing a shadowy figure behind a tree.\\n\\n---\\n\\n# Page 4\\n**Text:** With a flicker of light, the forest faded, and they landed next in the world of \\\"Jack and the Beanstalk.\\\" A giant beanstalk towered into the clouds above them.\\n\\n**Illustration:** Max and Minnie looking up in awe at a towering beanstalk that stretches up beyond the clouds.\\n\\n---\\n\\n# Page 5\\n**Text:** Climbing the beanstalk, they reached the giant\\u2019s castle in the sky. With cleverness and stealth, they helped Jack steal back the golden harp and escape.\\n\\n**Illustration:** The mice, tiptoeing behind Jack, as they sneak past a sleeping giant. A golden harp glimmers on the table.\\n\\n---\\n\\n# Page 6\\n**Text:** No sooner had they descended than the book whisked them away to Cinderella\\u2019s ball. They helped Cinderella find her glass slipper, lost in the flurry of her midnight escape.\\n\\n**Illustration:** A grand ballroom with a prince holding a glass slipper. Minnie and Max are helping a distressed Cinderella.\\n\\n---\\n\\n# Page 7\\n**Text:** Each tale brought new friends and adventures. As dawn approached, the magic book began to glow softly, signaling the time to return.\\n\\n**Illustration:** The two mice, surrounded by all the characters they've met, near the glowing book.\\n\\n---\\n\\n# Page 8\\n**Text:** With a final burst of light, Minnie and Max found themselves back in their library corner, the book closed gently before them. The magic of fairy tales had become part of their own story.\\n\\n**Illustration:** The mice, exhausted but happy, nestled among their library books, the magical book closed and still glowing faintly.\\n\\n---\\n\\n# Page 9\\n**Text:** Now, whenever they felt the urge for adventure, Minnie and Max knew that incredible journeys were just a page turn away.\\n\\n**Illustration:** The mice, now comfortably reading the magical book, with faint images of their adventures visible in the glow around them.\\n\\n---\\n\\nThis picture book combines the charm of classic fairy tales with the thrill of new adventures, inspiring children to read and imagine themselves in their favorite stories.\",\n          \"### Human: Please help me create a picture book with the theme of\\nA courageous young hedgehog named Clover sets off to find the legendary Four-Leaf Clover, the key to bringing good luck and prosperity to her village.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: Clover's Quest for Luck\\n\\n Cover Page Illustration:\\nA vibrant illustration of Clover, a small, determined hedgehog with a bright green backpack, standing at the edge of a lush, winding forest path that disappears into a mysterious, magical forest.\\n\\n Page 1 Illustration:\\nClover waves goodbye to her fellow villagers, a variety of small, cheerful animals gathered at the edge of the village.\\n\\n**Text:** In the heart of a bustling woodland, where creatures big and small lived in harmony, there stood a village facing tough times. Food was scarce, and spirits were low. But Clover, the youngest hedgehog, believed in legends and tales, especially one: the legendary Four-Leaf Clover that promised endless good luck and prosperity.\\n\\n Page 2 Illustration:\\nClover at her home, pouring over old books and maps by candlelight, her face lit with determination and curiosity.\\n\\n**Text:** Night after night, Clover researched and planned. She knew her journey wouldn\\u2019t be easy, but her heart was as fierce as her quills. With a map she\\u2019d drawn herself and a backpack filled with essentials, she was ready to find the legendary clover to save her village.\\n\\n Page 3 Illustration:\\nClover stepping bravely into the forest, the trees tall and the path curvy and narrow, sunbeams piercing through the leaves.\\n\\n**Text:** The forest was thick with whispering winds and rustling leaves. Clover walked with courage, her tiny feet steady on the uneven path. The deeper she went, the more the forest seemed alive, watching her every move with curious eyes.\\n\\n Page 4 Illustration:\\nClover meeting a wise old owl perched on a gnarled tree branch, under the moonlight.\\n\\n**Text:** As night fell, Clover met a wise old owl who spoke of the clover\\u2019s guarded location. \\u201cBeneath the moon\\u2019s peak, through the thickest part of the forest, lies the glade of fortune where the four-leaf clover grows,\\u201d hooted the owl. Clover listened intently, her resolve growing stronger.\\n\\n Page 5 Illustration:\\nClover navigating through a tricky part of the forest, avoiding thorns and pits, using a stick to help her along.\\n\\n**Text:** The path became treacherous, filled with thorns and hidden pits. But Clover cleverly used a stick to check the ground and pushed through the underbrush with brave, careful steps. Each obstacle she overcame filled her with pride and confidence.\\n\\n Page 6 Illustration:\\nA magical glade illuminated by moonlight, the four-leaf clover glowing in the center, surrounded by other normal clovers.\\n\\n**Text:** Finally, after what seemed like an eternity, Clover entered a moonlit glade. There, right in the center, was the glowing Four-Leaf Clover. It was more beautiful than she had imagined, its leaves shimmering with an enchanting light.\\n\\n Page 7 Illustration:\\nClover reaching out gently to pluck the clover, with various woodland creatures watching in awe and hope.\\n\\n**Text:** With a gentle touch, Clover plucked the clover, feeling a warm rush of energy. The woodland creatures gathered around, their eyes wide with wonder and hope. They knew their village was saved.\\n\\n Page 8 Illustration:\\nClover returning to her village, greeted as a hero by the joyful villagers. Celebrations and joyous scenes fill the page.\\n\\n**Text:** Clover returned as a hero, her journey a testament to her bravery and determination. With the legendary Four-Leaf Clover in hand, her village flourished. Food was plentiful, and happiness returned. Clover\\u2019s adventure taught everyone the power of courage and belief in the magical.\\n\\n Back Cover:\\nA serene illustration of the village in prosperity, Clover playing joyfully with other young animals, the four-leaf clover framed proudly in the village square.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3cff0d32-2a4b-4265-99a7-f4d8d857b362\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Whisker's Magical Forest Adventure\\n\\n...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **Mia and Mico’s Treasure Quest**\\n\\n ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: The Enchanted Doorway\\n\\n---\\n\\n# Cove...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: \"The Cave of Dragon Friends\"\\n\\n---\\n\\...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Pip's Quest for the Golden Cheese\\n\\n ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **The Bear Cubs' Prehistoric Express**...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Ember's Quest for the Rainbow Feather\\...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **Stella and Fidget in Starlight Adven...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: The Quest for the Wishing Carrot\\n\\n C...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: \"Milo's Forest Adventure\"\\n\\n---\\n\\n# ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cff0d32-2a4b-4265-99a7-f4d8d857b362')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cff0d32-2a4b-4265-99a7-f4d8d857b362 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cff0d32-2a4b-4265-99a7-f4d8d857b362');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9850cd84-8692-4ab4-a355-de4977de518b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9850cd84-8692-4ab4-a355-de4977de518b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9850cd84-8692-4ab4-a355-de4977de518b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ad2a0857-03ab-4adb-a38a-9e6a0d6da569\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ad2a0857-03ab-4adb-a38a-9e6a0d6da569 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            questions  \\\n",
              "0   Please help me create a picture book with the ...   \n",
              "1   Please help me create a picture book with the ...   \n",
              "2   Please help me create a picture book with the ...   \n",
              "3   Please help me create a picture book with the ...   \n",
              "4   Please help me create a picture book with the ...   \n",
              "..                                                ...   \n",
              "95  Please help me create a picture book with the ...   \n",
              "96  Please help me create a picture book with the ...   \n",
              "97  Please help me create a picture book with the ...   \n",
              "98  Please help me create a picture book with the ...   \n",
              "99  Please help me create a picture book with the ...   \n",
              "\n",
              "                                              answers  \\\n",
              "0    Title: Whisker's Magical Forest Adventure\\n\\n...   \n",
              "1    Title: **Mia and Mico’s Treasure Quest**\\n\\n ...   \n",
              "2    Title: The Enchanted Doorway\\n\\n---\\n\\n# Cove...   \n",
              "3    Title: \"The Cave of Dragon Friends\"\\n\\n---\\n\\...   \n",
              "4    Title: Pip's Quest for the Golden Cheese\\n\\n ...   \n",
              "..                                                ...   \n",
              "95   Title: **The Bear Cubs' Prehistoric Express**...   \n",
              "96   Title: Ember's Quest for the Rainbow Feather\\...   \n",
              "97   Title: **Stella and Fidget in Starlight Adven...   \n",
              "98   Title: The Quest for the Wishing Carrot\\n\\n C...   \n",
              "99   Title: \"Milo's Forest Adventure\"\\n\\n---\\n\\n# ...   \n",
              "\n",
              "                                                 text  \n",
              "0   ### Human: Please help me create a picture boo...  \n",
              "1   ### Human: Please help me create a picture boo...  \n",
              "2   ### Human: Please help me create a picture boo...  \n",
              "3   ### Human: Please help me create a picture boo...  \n",
              "4   ### Human: Please help me create a picture boo...  \n",
              "..                                                ...  \n",
              "95  ### Human: Please help me create a picture boo...  \n",
              "96  ### Human: Please help me create a picture boo...  \n",
              "97  ### Human: Please help me create a picture boo...  \n",
              "98  ### Human: Please help me create a picture boo...  \n",
              "99  ### Human: Please help me create a picture boo...  \n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet(\"hf://datasets/eagle0504/storySeed-v1/data/train-00000-of-00001.parquet\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ri3jMsv8Ba0g",
        "outputId": "ce30e4a1-b446-42ea-a452-971f2650ef4a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Please help me create a picture book with the theme of\\nTwo brave rabbit siblings embark on a journey to find the legendary Gravity Carrot, said to grant the power of defying gravity to those brave enough to eat it.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\",\n          \"Please help me create a picture book with the theme of\\nTwo adventurous mice stumble upon a mysterious old book that brings their favorite fairy tales to life, leading them on a whirlwind journey through classic stories.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\",\n          \"Please help me create a picture book with the theme of\\nA courageous young hedgehog named Clover sets off to find the legendary Four-Leaf Clover, the key to bringing good luck and prosperity to her village.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \" Title: The Quest for the Gravity Carrot\\n\\n---\\n\\n# Cover Page:\\n(Illustration: Two adventurous-looking rabbit siblings, one wearing a tiny backpack and the other with a map, standing at the edge of a lush, mysterious forest, gazing up at a twinkling star.)\\n\\n---\\n\\n# Page 1:\\n(Illustration: The two rabbit siblings, Lily and Max, in their cozy burrow, surrounded by old books and maps.)\\nText: In the heart of Whispering Woods, young Lily and Max had heard tales of a magical carrot, buried deep within the Enchanted Glade. This was no ordinary carrot; it was the legendary Gravity Carrot, said to give the power to hop as high as the sky!\\n\\n---\\n\\n# Page 2:\\n(Illustration: The siblings setting off at dawn, with the rising sun behind them and the forest ahead, filled with colorful birds and flowers.)\\nText: With a map in one paw and determination in their hearts, Lily and Max set out at the break of day. Their journey promised great adventures, and perhaps, a touch of danger.\\n\\n---\\n\\n# Page 3:\\n(Illustration: Encountering a tricky river, its waters swirling with shimmering fish.)\\nText: Their first challenge was the Mirror River, which flowed faster than the wind. But working together, Lily cleverly built a bridge with fallen logs while Max kept a lookout for sneaky foxes.\\n\\n---\\n\\n# Page 4:\\n(Illustration: Climbing a steep, rocky hill, their faces showing strain but also excitement.)\\nText: Next came the Rocky Rise, a hill so steep that each step seemed a battle against gravity itself. \\\"Imagine how easy this climb will be once we find the Gravity Carrot!\\\" Max panted, smiling through the effort.\\n\\n---\\n\\n# Page 5:\\n(Illustration: A wise old owl in a tree, speaking to the intrepid siblings.)\\nText: At the hill\\u2019s peak, they met Old Oswald, the wise owl. He spoke in riddles but offered them a clue, \\\"The Gravity Carrot lies hidden where the ground touches the sky.\\\"\\n\\n---\\n\\n# Page 6:\\n(Illustration: Entering a mysterious cave that glows with an ethereal light.)\\nText: Their clue led them to the Whispering Cave, lit by glowworms that cast eerie shadows. It was here, amidst whispers of the past, that the path to the Enchanted Glade was revealed.\\n\\n---\\n\\n# Page 7:\\n(Illustration: The siblings, looking in awe at a spectacular glade with floating stones and beams of light piercing through.)\\nText: The Enchanted Glade was more beautiful than they had imagined. Stones floated, defying gravity, and there, in the center, shone the bright orange Gravity Carrot.\\n\\n---\\n\\n# Page 8:\\n(Illustration: Lily reaching out to grab the Gravity Carrot, as the flora and fauna around seem to watch in silent anticipation.)\\nText: With hearts racing, Lily reached for the carrot. As her fingers touched its smooth surface, the glade shimmered, and a gentle breeze lifted them off their feet.\\n\\n---\\n\\n# Page 9:\\n(Illustration: Joyfully hopping high above the trees, the siblings experiencing the thrill of floating with a backdrop of the setting sun.)\\nText: With the power of the Gravity Carrot, Lily and Max could hop higher than ever before. Laughing joyfully, they realized that the real magic was not just in the carrot, but in the bravery and love shared between them on their incredible journey.\\n\\n---\\n\\n# Page 10:\\n(Illustration: Returning home under starlight, the siblings share their story with their family, who listen in amazement.)\\nText: As they returned home, their spirits as light as their hops, Lily and Max knew that this adventure would be one of many. For the world was wide, and their curiosity was endless.\\n\\n---\\n\\nThis picture book invites young readers into a world of adventure, promoting courage, teamwork, and the joys of discovering the unknown together. Each illustration aims to capture the essence of the journey, pulling children into the magical world of Lily and Max.\",\n          \" Title: ***Mice and Magic: A Fairy Tale Adventure***\\n\\n---\\n\\n# Cover Page\\n**Illustration:** Two small, eager-eyed mice with backpacks standing on a stack of giant books, the topmost book aglow with shimmering, golden light spilling from its slightly open cover.\\n\\n---\\n\\n# Page 1\\n**Text:** In the quiet corner of an old library, Minnie and Max, two curious mice, discovered a book unlike any other. Its cover shimmered with a mysterious glow that whispered secrets of old.\\n\\n**Illustration:** A dusty library corner with books piled high. Minnie and Max, with tiny lanterns, are approaching a large, glowing book.\\n\\n---\\n\\n# Page 2\\n**Text:** As Max gently opened the book, a whirlwind of light enveloped them. When the light settled, they found themselves in a vast forest, the world of \\\"Little Red Riding Hood.\\\"\\n\\n**Illustration:** The mice, looking surprised and a bit tousled, standing in a lush, green forest. A path and a distant cottage are visible.\\n\\n---\\n\\n# Page 3\\n**Text:** They helped Red Riding Hood find her way to Grandma's house and outsmart the sly wolf hiding in the woods. Their courage had never been so tested!\\n\\n**Illustration:** Minnie and Max, advising a small girl in a red cape, pointing towards a safe path, while eyeing a shadowy figure behind a tree.\\n\\n---\\n\\n# Page 4\\n**Text:** With a flicker of light, the forest faded, and they landed next in the world of \\\"Jack and the Beanstalk.\\\" A giant beanstalk towered into the clouds above them.\\n\\n**Illustration:** Max and Minnie looking up in awe at a towering beanstalk that stretches up beyond the clouds.\\n\\n---\\n\\n# Page 5\\n**Text:** Climbing the beanstalk, they reached the giant\\u2019s castle in the sky. With cleverness and stealth, they helped Jack steal back the golden harp and escape.\\n\\n**Illustration:** The mice, tiptoeing behind Jack, as they sneak past a sleeping giant. A golden harp glimmers on the table.\\n\\n---\\n\\n# Page 6\\n**Text:** No sooner had they descended than the book whisked them away to Cinderella\\u2019s ball. They helped Cinderella find her glass slipper, lost in the flurry of her midnight escape.\\n\\n**Illustration:** A grand ballroom with a prince holding a glass slipper. Minnie and Max are helping a distressed Cinderella.\\n\\n---\\n\\n# Page 7\\n**Text:** Each tale brought new friends and adventures. As dawn approached, the magic book began to glow softly, signaling the time to return.\\n\\n**Illustration:** The two mice, surrounded by all the characters they've met, near the glowing book.\\n\\n---\\n\\n# Page 8\\n**Text:** With a final burst of light, Minnie and Max found themselves back in their library corner, the book closed gently before them. The magic of fairy tales had become part of their own story.\\n\\n**Illustration:** The mice, exhausted but happy, nestled among their library books, the magical book closed and still glowing faintly.\\n\\n---\\n\\n# Page 9\\n**Text:** Now, whenever they felt the urge for adventure, Minnie and Max knew that incredible journeys were just a page turn away.\\n\\n**Illustration:** The mice, now comfortably reading the magical book, with faint images of their adventures visible in the glow around them.\\n\\n---\\n\\nThis picture book combines the charm of classic fairy tales with the thrill of new adventures, inspiring children to read and imagine themselves in their favorite stories.\",\n          \" Title: Clover's Quest for Luck\\n\\n Cover Page Illustration:\\nA vibrant illustration of Clover, a small, determined hedgehog with a bright green backpack, standing at the edge of a lush, winding forest path that disappears into a mysterious, magical forest.\\n\\n Page 1 Illustration:\\nClover waves goodbye to her fellow villagers, a variety of small, cheerful animals gathered at the edge of the village.\\n\\n**Text:** In the heart of a bustling woodland, where creatures big and small lived in harmony, there stood a village facing tough times. Food was scarce, and spirits were low. But Clover, the youngest hedgehog, believed in legends and tales, especially one: the legendary Four-Leaf Clover that promised endless good luck and prosperity.\\n\\n Page 2 Illustration:\\nClover at her home, pouring over old books and maps by candlelight, her face lit with determination and curiosity.\\n\\n**Text:** Night after night, Clover researched and planned. She knew her journey wouldn\\u2019t be easy, but her heart was as fierce as her quills. With a map she\\u2019d drawn herself and a backpack filled with essentials, she was ready to find the legendary clover to save her village.\\n\\n Page 3 Illustration:\\nClover stepping bravely into the forest, the trees tall and the path curvy and narrow, sunbeams piercing through the leaves.\\n\\n**Text:** The forest was thick with whispering winds and rustling leaves. Clover walked with courage, her tiny feet steady on the uneven path. The deeper she went, the more the forest seemed alive, watching her every move with curious eyes.\\n\\n Page 4 Illustration:\\nClover meeting a wise old owl perched on a gnarled tree branch, under the moonlight.\\n\\n**Text:** As night fell, Clover met a wise old owl who spoke of the clover\\u2019s guarded location. \\u201cBeneath the moon\\u2019s peak, through the thickest part of the forest, lies the glade of fortune where the four-leaf clover grows,\\u201d hooted the owl. Clover listened intently, her resolve growing stronger.\\n\\n Page 5 Illustration:\\nClover navigating through a tricky part of the forest, avoiding thorns and pits, using a stick to help her along.\\n\\n**Text:** The path became treacherous, filled with thorns and hidden pits. But Clover cleverly used a stick to check the ground and pushed through the underbrush with brave, careful steps. Each obstacle she overcame filled her with pride and confidence.\\n\\n Page 6 Illustration:\\nA magical glade illuminated by moonlight, the four-leaf clover glowing in the center, surrounded by other normal clovers.\\n\\n**Text:** Finally, after what seemed like an eternity, Clover entered a moonlit glade. There, right in the center, was the glowing Four-Leaf Clover. It was more beautiful than she had imagined, its leaves shimmering with an enchanting light.\\n\\n Page 7 Illustration:\\nClover reaching out gently to pluck the clover, with various woodland creatures watching in awe and hope.\\n\\n**Text:** With a gentle touch, Clover plucked the clover, feeling a warm rush of energy. The woodland creatures gathered around, their eyes wide with wonder and hope. They knew their village was saved.\\n\\n Page 8 Illustration:\\nClover returning to her village, greeted as a hero by the joyful villagers. Celebrations and joyous scenes fill the page.\\n\\n**Text:** Clover returned as a hero, her journey a testament to her bravery and determination. With the legendary Four-Leaf Clover in hand, her village flourished. Food was plentiful, and happiness returned. Clover\\u2019s adventure taught everyone the power of courage and belief in the magical.\\n\\n Back Cover:\\nA serene illustration of the village in prosperity, Clover playing joyfully with other young animals, the four-leaf clover framed proudly in the village square.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"### Human: Please help me create a picture book with the theme of\\nTwo brave rabbit siblings embark on a journey to find the legendary Gravity Carrot, said to grant the power of defying gravity to those brave enough to eat it.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: The Quest for the Gravity Carrot\\n\\n---\\n\\n# Cover Page:\\n(Illustration: Two adventurous-looking rabbit siblings, one wearing a tiny backpack and the other with a map, standing at the edge of a lush, mysterious forest, gazing up at a twinkling star.)\\n\\n---\\n\\n# Page 1:\\n(Illustration: The two rabbit siblings, Lily and Max, in their cozy burrow, surrounded by old books and maps.)\\nText: In the heart of Whispering Woods, young Lily and Max had heard tales of a magical carrot, buried deep within the Enchanted Glade. This was no ordinary carrot; it was the legendary Gravity Carrot, said to give the power to hop as high as the sky!\\n\\n---\\n\\n# Page 2:\\n(Illustration: The siblings setting off at dawn, with the rising sun behind them and the forest ahead, filled with colorful birds and flowers.)\\nText: With a map in one paw and determination in their hearts, Lily and Max set out at the break of day. Their journey promised great adventures, and perhaps, a touch of danger.\\n\\n---\\n\\n# Page 3:\\n(Illustration: Encountering a tricky river, its waters swirling with shimmering fish.)\\nText: Their first challenge was the Mirror River, which flowed faster than the wind. But working together, Lily cleverly built a bridge with fallen logs while Max kept a lookout for sneaky foxes.\\n\\n---\\n\\n# Page 4:\\n(Illustration: Climbing a steep, rocky hill, their faces showing strain but also excitement.)\\nText: Next came the Rocky Rise, a hill so steep that each step seemed a battle against gravity itself. \\\"Imagine how easy this climb will be once we find the Gravity Carrot!\\\" Max panted, smiling through the effort.\\n\\n---\\n\\n# Page 5:\\n(Illustration: A wise old owl in a tree, speaking to the intrepid siblings.)\\nText: At the hill\\u2019s peak, they met Old Oswald, the wise owl. He spoke in riddles but offered them a clue, \\\"The Gravity Carrot lies hidden where the ground touches the sky.\\\"\\n\\n---\\n\\n# Page 6:\\n(Illustration: Entering a mysterious cave that glows with an ethereal light.)\\nText: Their clue led them to the Whispering Cave, lit by glowworms that cast eerie shadows. It was here, amidst whispers of the past, that the path to the Enchanted Glade was revealed.\\n\\n---\\n\\n# Page 7:\\n(Illustration: The siblings, looking in awe at a spectacular glade with floating stones and beams of light piercing through.)\\nText: The Enchanted Glade was more beautiful than they had imagined. Stones floated, defying gravity, and there, in the center, shone the bright orange Gravity Carrot.\\n\\n---\\n\\n# Page 8:\\n(Illustration: Lily reaching out to grab the Gravity Carrot, as the flora and fauna around seem to watch in silent anticipation.)\\nText: With hearts racing, Lily reached for the carrot. As her fingers touched its smooth surface, the glade shimmered, and a gentle breeze lifted them off their feet.\\n\\n---\\n\\n# Page 9:\\n(Illustration: Joyfully hopping high above the trees, the siblings experiencing the thrill of floating with a backdrop of the setting sun.)\\nText: With the power of the Gravity Carrot, Lily and Max could hop higher than ever before. Laughing joyfully, they realized that the real magic was not just in the carrot, but in the bravery and love shared between them on their incredible journey.\\n\\n---\\n\\n# Page 10:\\n(Illustration: Returning home under starlight, the siblings share their story with their family, who listen in amazement.)\\nText: As they returned home, their spirits as light as their hops, Lily and Max knew that this adventure would be one of many. For the world was wide, and their curiosity was endless.\\n\\n---\\n\\nThis picture book invites young readers into a world of adventure, promoting courage, teamwork, and the joys of discovering the unknown together. Each illustration aims to capture the essence of the journey, pulling children into the magical world of Lily and Max.\",\n          \"### Human: Please help me create a picture book with the theme of\\nTwo adventurous mice stumble upon a mysterious old book that brings their favorite fairy tales to life, leading them on a whirlwind journey through classic stories.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: ***Mice and Magic: A Fairy Tale Adventure***\\n\\n---\\n\\n# Cover Page\\n**Illustration:** Two small, eager-eyed mice with backpacks standing on a stack of giant books, the topmost book aglow with shimmering, golden light spilling from its slightly open cover.\\n\\n---\\n\\n# Page 1\\n**Text:** In the quiet corner of an old library, Minnie and Max, two curious mice, discovered a book unlike any other. Its cover shimmered with a mysterious glow that whispered secrets of old.\\n\\n**Illustration:** A dusty library corner with books piled high. Minnie and Max, with tiny lanterns, are approaching a large, glowing book.\\n\\n---\\n\\n# Page 2\\n**Text:** As Max gently opened the book, a whirlwind of light enveloped them. When the light settled, they found themselves in a vast forest, the world of \\\"Little Red Riding Hood.\\\"\\n\\n**Illustration:** The mice, looking surprised and a bit tousled, standing in a lush, green forest. A path and a distant cottage are visible.\\n\\n---\\n\\n# Page 3\\n**Text:** They helped Red Riding Hood find her way to Grandma's house and outsmart the sly wolf hiding in the woods. Their courage had never been so tested!\\n\\n**Illustration:** Minnie and Max, advising a small girl in a red cape, pointing towards a safe path, while eyeing a shadowy figure behind a tree.\\n\\n---\\n\\n# Page 4\\n**Text:** With a flicker of light, the forest faded, and they landed next in the world of \\\"Jack and the Beanstalk.\\\" A giant beanstalk towered into the clouds above them.\\n\\n**Illustration:** Max and Minnie looking up in awe at a towering beanstalk that stretches up beyond the clouds.\\n\\n---\\n\\n# Page 5\\n**Text:** Climbing the beanstalk, they reached the giant\\u2019s castle in the sky. With cleverness and stealth, they helped Jack steal back the golden harp and escape.\\n\\n**Illustration:** The mice, tiptoeing behind Jack, as they sneak past a sleeping giant. A golden harp glimmers on the table.\\n\\n---\\n\\n# Page 6\\n**Text:** No sooner had they descended than the book whisked them away to Cinderella\\u2019s ball. They helped Cinderella find her glass slipper, lost in the flurry of her midnight escape.\\n\\n**Illustration:** A grand ballroom with a prince holding a glass slipper. Minnie and Max are helping a distressed Cinderella.\\n\\n---\\n\\n# Page 7\\n**Text:** Each tale brought new friends and adventures. As dawn approached, the magic book began to glow softly, signaling the time to return.\\n\\n**Illustration:** The two mice, surrounded by all the characters they've met, near the glowing book.\\n\\n---\\n\\n# Page 8\\n**Text:** With a final burst of light, Minnie and Max found themselves back in their library corner, the book closed gently before them. The magic of fairy tales had become part of their own story.\\n\\n**Illustration:** The mice, exhausted but happy, nestled among their library books, the magical book closed and still glowing faintly.\\n\\n---\\n\\n# Page 9\\n**Text:** Now, whenever they felt the urge for adventure, Minnie and Max knew that incredible journeys were just a page turn away.\\n\\n**Illustration:** The mice, now comfortably reading the magical book, with faint images of their adventures visible in the glow around them.\\n\\n---\\n\\nThis picture book combines the charm of classic fairy tales with the thrill of new adventures, inspiring children to read and imagine themselves in their favorite stories.\",\n          \"### Human: Please help me create a picture book with the theme of\\nA courageous young hedgehog named Clover sets off to find the legendary Four-Leaf Clover, the key to bringing good luck and prosperity to her village.\\nThe format should include a title, followed by a cover page with an illustration only, and the remaining pages should each have both text and illustrations. ### Assistant:  Title: Clover's Quest for Luck\\n\\n Cover Page Illustration:\\nA vibrant illustration of Clover, a small, determined hedgehog with a bright green backpack, standing at the edge of a lush, winding forest path that disappears into a mysterious, magical forest.\\n\\n Page 1 Illustration:\\nClover waves goodbye to her fellow villagers, a variety of small, cheerful animals gathered at the edge of the village.\\n\\n**Text:** In the heart of a bustling woodland, where creatures big and small lived in harmony, there stood a village facing tough times. Food was scarce, and spirits were low. But Clover, the youngest hedgehog, believed in legends and tales, especially one: the legendary Four-Leaf Clover that promised endless good luck and prosperity.\\n\\n Page 2 Illustration:\\nClover at her home, pouring over old books and maps by candlelight, her face lit with determination and curiosity.\\n\\n**Text:** Night after night, Clover researched and planned. She knew her journey wouldn\\u2019t be easy, but her heart was as fierce as her quills. With a map she\\u2019d drawn herself and a backpack filled with essentials, she was ready to find the legendary clover to save her village.\\n\\n Page 3 Illustration:\\nClover stepping bravely into the forest, the trees tall and the path curvy and narrow, sunbeams piercing through the leaves.\\n\\n**Text:** The forest was thick with whispering winds and rustling leaves. Clover walked with courage, her tiny feet steady on the uneven path. The deeper she went, the more the forest seemed alive, watching her every move with curious eyes.\\n\\n Page 4 Illustration:\\nClover meeting a wise old owl perched on a gnarled tree branch, under the moonlight.\\n\\n**Text:** As night fell, Clover met a wise old owl who spoke of the clover\\u2019s guarded location. \\u201cBeneath the moon\\u2019s peak, through the thickest part of the forest, lies the glade of fortune where the four-leaf clover grows,\\u201d hooted the owl. Clover listened intently, her resolve growing stronger.\\n\\n Page 5 Illustration:\\nClover navigating through a tricky part of the forest, avoiding thorns and pits, using a stick to help her along.\\n\\n**Text:** The path became treacherous, filled with thorns and hidden pits. But Clover cleverly used a stick to check the ground and pushed through the underbrush with brave, careful steps. Each obstacle she overcame filled her with pride and confidence.\\n\\n Page 6 Illustration:\\nA magical glade illuminated by moonlight, the four-leaf clover glowing in the center, surrounded by other normal clovers.\\n\\n**Text:** Finally, after what seemed like an eternity, Clover entered a moonlit glade. There, right in the center, was the glowing Four-Leaf Clover. It was more beautiful than she had imagined, its leaves shimmering with an enchanting light.\\n\\n Page 7 Illustration:\\nClover reaching out gently to pluck the clover, with various woodland creatures watching in awe and hope.\\n\\n**Text:** With a gentle touch, Clover plucked the clover, feeling a warm rush of energy. The woodland creatures gathered around, their eyes wide with wonder and hope. They knew their village was saved.\\n\\n Page 8 Illustration:\\nClover returning to her village, greeted as a hero by the joyful villagers. Celebrations and joyous scenes fill the page.\\n\\n**Text:** Clover returned as a hero, her journey a testament to her bravery and determination. With the legendary Four-Leaf Clover in hand, her village flourished. Food was plentiful, and happiness returned. Clover\\u2019s adventure taught everyone the power of courage and belief in the magical.\\n\\n Back Cover:\\nA serene illustration of the village in prosperity, Clover playing joyfully with other young animals, the four-leaf clover framed proudly in the village square.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-db795d65-bcfe-4646-b949-a724e5cf5068\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Whisker's Magical Forest Adventure\\n\\n...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **Mia and Mico’s Treasure Quest**\\n\\n ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: The Enchanted Doorway\\n\\n---\\n\\n# Cove...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: \"The Cave of Dragon Friends\"\\n\\n---\\n\\...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Pip's Quest for the Golden Cheese\\n\\n ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **The Bear Cubs' Prehistoric Express**...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: Ember's Quest for the Rainbow Feather\\...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: **Stella and Fidget in Starlight Adven...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: The Quest for the Wishing Carrot\\n\\n C...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Please help me create a picture book with the ...</td>\n",
              "      <td>Title: \"Milo's Forest Adventure\"\\n\\n---\\n\\n# ...</td>\n",
              "      <td>### Human: Please help me create a picture boo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db795d65-bcfe-4646-b949-a724e5cf5068')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db795d65-bcfe-4646-b949-a724e5cf5068 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db795d65-bcfe-4646-b949-a724e5cf5068');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e46ee306-f74e-49be-8e3c-08c15bfd5092\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e46ee306-f74e-49be-8e3c-08c15bfd5092')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e46ee306-f74e-49be-8e3c-08c15bfd5092 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4acc4a6e-d23d-4f79-9c79-bf2b134c2722\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4acc4a6e-d23d-4f79-9c79-bf2b134c2722 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   Please help me create a picture book with the ...   \n",
              "1   Please help me create a picture book with the ...   \n",
              "2   Please help me create a picture book with the ...   \n",
              "3   Please help me create a picture book with the ...   \n",
              "4   Please help me create a picture book with the ...   \n",
              "..                                                ...   \n",
              "95  Please help me create a picture book with the ...   \n",
              "96  Please help me create a picture book with the ...   \n",
              "97  Please help me create a picture book with the ...   \n",
              "98  Please help me create a picture book with the ...   \n",
              "99  Please help me create a picture book with the ...   \n",
              "\n",
              "                                               answer  \\\n",
              "0    Title: Whisker's Magical Forest Adventure\\n\\n...   \n",
              "1    Title: **Mia and Mico’s Treasure Quest**\\n\\n ...   \n",
              "2    Title: The Enchanted Doorway\\n\\n---\\n\\n# Cove...   \n",
              "3    Title: \"The Cave of Dragon Friends\"\\n\\n---\\n\\...   \n",
              "4    Title: Pip's Quest for the Golden Cheese\\n\\n ...   \n",
              "..                                                ...   \n",
              "95   Title: **The Bear Cubs' Prehistoric Express**...   \n",
              "96   Title: Ember's Quest for the Rainbow Feather\\...   \n",
              "97   Title: **Stella and Fidget in Starlight Adven...   \n",
              "98   Title: The Quest for the Wishing Carrot\\n\\n C...   \n",
              "99   Title: \"Milo's Forest Adventure\"\\n\\n---\\n\\n# ...   \n",
              "\n",
              "                                                 text  \n",
              "0   ### Human: Please help me create a picture boo...  \n",
              "1   ### Human: Please help me create a picture boo...  \n",
              "2   ### Human: Please help me create a picture boo...  \n",
              "3   ### Human: Please help me create a picture boo...  \n",
              "4   ### Human: Please help me create a picture boo...  \n",
              "..                                                ...  \n",
              "95  ### Human: Please help me create a picture boo...  \n",
              "96  ### Human: Please help me create a picture boo...  \n",
              "97  ### Human: Please help me create a picture boo...  \n",
              "98  ### Human: Please help me create a picture boo...  \n",
              "99  ### Human: Please help me create a picture boo...  \n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns = [\"question\", \"answer\", \"text\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv5tVOCmb7Z-"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeBQT1KubQg7"
      },
      "source": [
        "The code initializes a tokenizer with a vocabulary size of 10,000 and an out-of-vocabulary token. It fits the tokenizer on the text data from questions and answers in a DataFrame. The text is then converted to sequences of integers, which are padded to a fixed length (e.g., 10) to ensure consistent input size for a machine learning model. The padded sequences of questions and answers are concatenated to form a single dataset for training. Finally, the prepared sample data, now tokenized and padded, is printed for review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYqU3XK-F03z",
        "outputId": "906baf71-4039-4071-9645-e6550e437601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample data (tokenized and padded):\n",
            " [[ 136  369    2 ...    9    4   73]\n",
            " [  15  333  354 ...    9    4   73]\n",
            " [ 242    4  796 ...    9    4   73]\n",
            " ...\n",
            " [ 153  529   16 ...  458 1595  100]\n",
            " [ 393  408  651 ...  458  516   65]\n",
            " [ 246  440    4 ... 1179   12 1606]]\n",
            "Dimension of sample data:  (200, 30)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "\n",
        "# Fit the tokenizer on the questions and answers\n",
        "tokenizer.fit_on_texts(df['question'].tolist() + df['answer'].tolist())\n",
        "\n",
        "# Convert texts to sequences\n",
        "question_sequences = tokenizer.texts_to_sequences(df['question'].tolist())\n",
        "answer_sequences = tokenizer.texts_to_sequences(df['answer'].tolist())\n",
        "\n",
        "# Pad sequences to ensure consistent input size for the model\n",
        "max_length = 30  # Example fixed length; this can be adjusted as needed\n",
        "question_padded = pad_sequences(question_sequences, maxlen=max_length, padding='post')\n",
        "answer_padded = pad_sequences(answer_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Combine questions and answers for training\n",
        "sample_data = np.concatenate((question_padded, answer_padded), axis=0)\n",
        "\n",
        "# Display the prepared sample data\n",
        "print(\"Sample data (tokenized and padded):\\n\", sample_data)\n",
        "\n",
        "# Display the dimension of sample data\n",
        "print(\"Dimension of sample data: \", sample_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0mv6X0tbUIZ"
      },
      "source": [
        "The provided code defines a function `sequences_to_text` that converts numerical sequences back into text using a tokenizer's word index. It creates a reverse mapping of indices to words, including a placeholder `<PAD>` for padding indices. The function iterates over sequences, retrieves corresponding words, and constructs text sentences, removing padding. The code then tests this function by converting padded sequences of questions and answers back into their original text form, printing the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VJy2UEYb-4o"
      },
      "source": [
        "## Recover texts by `sequences_to_text`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3PVAmJ4F4BN",
        "outputId": "c690f382-3898-42a3-f776-bbb110e883ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original token:\n",
            "[[ 136  369    2 ...    9    4   73]\n",
            " [  15  333  354 ...    9    4   73]\n",
            " [ 242    4  796 ...    9    4   73]\n",
            " ...\n",
            " [ 153    4 1595 ...    9    4   73]\n",
            " [  13 2950  228 ...    9    4   73]\n",
            " [1377  369    2 ...    9    4   73]]\n",
            "\n",
            "Converted back to text (questions):\n",
            "['creatures along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'her clever pet monkey the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'animals and enchanting adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'civilization of friendly dragons the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'friends along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'vibrancy to the land the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'source of the rainbow the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'army of hungry aphids the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'flowers and friendly insects the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'of an evil sorcerer the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'on the high seas the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'trees and magical creatures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'challenges along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'within the enchanted forest the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'a land of wonder the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'with danger and discovery the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'obstacles along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the kind hearted bear the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'an evil ice queen the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and friendly garden creatures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'strength along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'a land of enchantment the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'from a terrible drought the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'about friendship and perseverance the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'characters along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'toys and whimsical adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'happiness to their village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and making groundbreaking discoveries the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and big adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'between the forest animals the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'find their happy endings the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'of an evil sorcerer the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and hidden islands the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'series of hilarious misadventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'dinosaurs and prehistoric adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'to her silent village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'said to come true the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'giants and hidden wonders the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and saving the forest the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'characters along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'to an unforgettable adventure the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'darkness from their land the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the power of invisibility the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'toys and whimsical adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and saving his village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'dragons save their kingdom the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'freeing their captured family the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'friends along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'islands and sky pirates the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'world from eternal darkness the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and sweet adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'including those of animals the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'said to become reality the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'journey through classic stories the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'balance to the forest the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the kind hearted bear the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and underwater adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'those pure of heart the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the importance of teamwork the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'trees and magical creatures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'never goes hungry again the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'with music and wonder the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'their world from unraveling the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and hidden treasures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'robots and futuristic adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'hope in her village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'clouds and sky adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'enough to find it the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'to be banished forever the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'objects and tiny adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'prosperity to her village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'characters along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and temporal adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'power of breathing underwater the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'messages and solving mysteries the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'sweets and confectionery adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and saving the forest the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'her on literary adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the evil snake queen the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'and making colorful friends the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'plants and melodic adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'back to her world the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'monsters and spooky adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'enough to eat it the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'are said to meet the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'their own artistic creations the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'that plague her village the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'characters along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and imaginative adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'glowing in the dark the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'the importance of responsibility the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'insects and miniature adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'with art and wonder the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'between the forest animals the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'creatures and bioluminescent wonders the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'dinosaurs and prehistoric adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'black and white world the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'stars and celestial adventures the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'they carry inside themselves the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations', 'obstacles along the way the format should include a title followed by a cover page with an illustration only and the remaining pages should each have both text and illustrations']\n",
            "Original token:\n",
            "[[ 458  257   80 ...  440    4  385]\n",
            " [  40   62   35 ...  333  354  441]\n",
            " [   7  209    3 ...   16 1148 1612]\n",
            " ...\n",
            " [ 153  529   16 ...  458 1595  100]\n",
            " [ 393  408  651 ...  458  516   65]\n",
            " [ 246  440    4 ... 1179   12 1606]]\n",
            "\n",
            "Converted back to text (answers):\n",
            "['own magic this format brings whiskers’ adventure to life engaging young readers with its vibrant illustrations and whimsical narrative that sparks imagination and teaches the value of curiosity and friendship', 'adventure picture book not only sparks the imagination but also teaches kids the values of bravery teamwork and perseverance through the exciting story of mia and her clever pet mico', 'illustration showing a close up of the mysterious door now closed with faint magical glimmers hinting at the next adventure text no text just the illustration hinting at future possibilities', 'full of adventure and new friendships this format combines engaging narrative with vibrant illustrations designed to captivate and inspire young readers to explore the values of friendship curiosity and cooperation', 'cheese shared among them back cover illustration the silhouette of pip standing triumphantly on the peak with a cheese shaped moon behind him casting a golden light over the land', 'celebrates the power of creativity and resilience using lush visuals to spark the imaginations of young readers inspiring them to see and color their world with their own unique palette', 'heading back home along a flower lined path the rainbow softly fading in the evening sky a symbol of their enduring friendship and the promise of more adventures to come', 'garden lush and vibrant in the background this format blends an engaging narrative with vibrant illustrations fostering a love for reading and teaching lessons on bravery teamwork and environmental care', \"this picture book combines vivid illustrations and a charming story to captivate and inspire young readers encouraging them to explore the world's beauty and always remember the way back home\", 'this engaging tale blends the excitement of a knightly quest with the charm of a clever animal companion perfect for sparking imagination and a love of reading in young children', 'and drums back cover illustration the pirate ship sailing into the sunset max sitting proudly on captain blackwhisker’s shoulder both looking out over the horizon ready for their next adventure', \"and eyes full of wonder back cover illustration the silhouette of the tree door closed the key glowing in elsie's pocket with a starry sky above hinting at hidden wonders\", 'ready for more stories to unfold illustration the kittens asleep in a cozy bed a small city toy model next to them under the soft glow of a night lamp', \"with a hero's welcome this book not only ignites the imagination but also teaches the value of bravery persistence and the joy of a journey shared with a true friend\", 'adventure discovery and belief text join lily on more adventures as she explores the wonders of a world where belief in the magical brings the most extraordinary experiences to life', 'in daylight peaceful with the hidden hole barely visible text join max and millie again as they continue to explore the wonders of their world both above and below ground', 'text with vivid illustrations to bring the story of sparky and his adventures to life teaching young readers about the values of bravery friendship and perseverance in an enchanting way', 'illustration a serene image of the whispering woods at night the moon casting a gentle glow over the forest hinting at countless future adventures for finley bernard and their friends', 'endless possibilities ahead this picture book encourages young readers to find the courage to face challenges the wisdom to seek help and the power of kindness to change the world', 'drift off to sleep with smiles on their faces back cover illustration a soft moonlit garden with the portal quietly shimmering between the trees hinting at more adventures to come', 'entered the village his friends and family gathered cheering finn had set out to find a sword but he returned with so much more—he had found courage deep within himself', 'open beside them sharing their story with grandma who listens smiling warmly back cover text join mia and fizz on their next adventure where will the map lead them tomorrow', 'milo and max who are now draped in flower garlands back cover illustration the village fully revitalized with streams flowing plants blooming and the mice playing happily under a rainbow', 'the sky behind them this picture book aims to inspire young readers with themes of determination perseverance and the value of friendship through the adventurous tale of spike the hedgehog', 'also encourages values like friendship bravery and the joy of sharing each page with its vivid illustrations and engaging text captures the essence of adventure and the magic of discovery', 'book would encourage children to explore imagine and value friendships and adventures using the engaging visuals of the story and the lively characterizations of bella benny and their whimsical friends', 'of the celebration back cover illustration stella and whisp sitting on a hill looking up at the stars the star flower safely tucked in stella’s bag emitting a gentle glow', 'against the night back cover illustration max and bolty walking hand in hand into a sunrise silhouettes against a brightly lit sky symbolizing the dawn of their next great adventure', 'quiet with a faint glow from the floorboard crack beneath the rug text mango and smudge back in their beds dreamed of their next visit to the world just ahead', \"tree now thriving with blossoms and surrounded by happy animals text rusty's courage and cleverness brought harmony back to whispering woods proving that even the smallest can change the world\", 'and fairy tales come to life back cover illustration the book closed resting on a window sill moonlight shining on its spine text where will the book take ellie next', 'they could face any challenge that came their way this picture book not only provides an engaging adventure but also instills values of bravery teamwork and perseverance in young readers', 'be illustrated with vibrant colors and detailed imagery to capture the imagination of young readers fostering a sense of adventure and wonder about the natural world and its hidden treasures', 'golden acorn displayed proudly on a small pedestal back cover illustration the forest at sunset with sammy and charlie resting against the oak tree smiling contentedly at their successful adventure', 'picture book combines an engaging narrative with vibrant illustrations that transport young readers to a magical world igniting their imagination and teaching them about the wonders of exploration and friendship', 'and friends back cover illustration a distant view of the lively village with children playing instruments and adults dancing around with aria and the glowing singing stone at the center', 'with the panoramic view of the world below them back cover illustration the silhouette of eli and pepper descending the mountain the horizon bright with the promise of more adventures', 'proudly on a pedestal made of stacked buttons this engaging picture book encourages exploration and teamwork as well as showing young readers the excitement of small wonders and big dreams', 'admiration and gratitude this picture book tells the story of bravery persistence and the power of believing in oneself all set against a backdrop of a magical engaging forest world', 'return back cover a simple elegant illustration of the forest and beach in the twilight the stars beginning to twinkle in the sky above hinting at more adventures to come', 'where wonders await at every turn this format provides a comprehensive journey through the secret garden with engaging text and vivid illustrations making it a captivating experience for young readers', 'book would blend adventurous text with vibrant illustrations encouraging bravery and exploration in young readers while capturing their imagination with the mystical journey of jasper and his loyal raven shadow', 'asleep in her lap both content and tired text and so mila and max learned that some legends are not just tales waiting for brave hearts to prove them true', 'mantle a reminder of their incredible journey as they settled down to sleep the key glimmered softly as if alive with the magic of toyland promising more adventures to come', 'friends end page illustration a serene sunset over whispering woods acorn sitting on a branch of the ancient oak looking out over the revitalized forest the golden nut beside him', '3 text as mia reached the bottom she found herself in a lush vibrant forest giant flowers and towering trees whispered secrets in the breeze welcome to the dragon kingdom', 'the burrow were peaceful once again max and millie heroes of their own epic tale watched the stars knowing that together no journey was too perilous no night too dark', 'come back cover illustration toby placing his magical skateboard under his bed its glow softly fading out with the city skyline silhouetted against the early morning light outside his window', 'stone gate the ground trembled slowly rising from the earth was a tree made entirely of gold its leaves shimmering with the promise of endless adventures illustration the golden tree', 'above back cover illustration scarlet curled up under a tree resting with her eyes content and a subtle smile as the world around her thrives in the sunlight she restored', 'a complete story with vibrant illustrations and engaging text perfect for sparking the imagination of young readers and inviting them into a world of sweet adventures and candy filled fun', 'looking up the magical carrot glinting softly beside them text optional and so the forest whispered on alive with new stories thanks to the brave hearts of two little rabbits', 'colors of dusk stars beginning to twinkle this picture book encourages children to pursue their dreams with determination and to cherish the companionship and support that make every adventure possible', 'glow around them this picture book combines the charm of classic fairy tales with the thrill of new adventures inspiring children to read and imagine themselves in their favorite stories', 'balance restored this picture book weaves a tale of bravery determination and friendship ideal for engaging young readers and inspiring them to explore and face their own adventures with courage', 'proudly this format provides a vibrant engaging storyline accompanied by colorful illustrations that depict the value of friendship and creativity in gift giving perfect for sparking imagination in young readers', 'hidden world just beneath this story not only captivates with its vibrant illustrations and magical underwater world but also encourages children to explore imagine and cherish the wonders of nature', 'adventures back cover text join luna and whimsy on more magical journeys illustration a silhouette of luna and whimsy looking out over a vast starlit landscape hinting at future adventures', 'cleverness of a boy and his robot illustration toby and gizmo at home enjoying a peaceful sunny day through the window with gizmo plugged in for a well deserved recharge', 'burrow the treasure box open with light shining out around them parts of the map and their little adventure items scattered creating a scene of fulfilled adventure and brotherly love', 'and secured her village’s future hazel’s journey was a tale of bravery and heart a story passed down through generations as she became a legend herself back cover illustration a', 'in her hand this book not only tells the tale of a magical adventure but also encourages children to explore the world around them and find wonder in the everyday', 'and max back cover a simple beautiful illustration of the tapestry fully mended glowing softly with millie and max sitting happily beside it enjoying a well deserved piece of cheese', 'at more adventures to come this book filled with luminous illustrations and engaging text will inspire children to explore their own worlds with courage curiosity and a sense of wonder', 'to sleep this adventure story picture book combines elements of fantasy friendship and discovery encouraging children to imagine beyond their surroundings and dream about the possibilities of technology and connection', 'in a place of honor back cover a simple elegant illustration of ember sitting on a hill looking up at the starry sky the phoenix feather beside her glowing gently', \"world of imagination and adventure teaching them the values of courage curiosity and the joy of helping others each illustration is vibrant and engaging perfect for sparking young readers' imagination\", 'of pride and joy they shared their adventure with their family who listened in awe the invisible carrot was safe but their tales of bravery would be told for generations', 'laughter where will your adventures take you illustration the silhouettes of arlo and buttercup hand in hoof looking out over the valley stars beginning to twinkle in the twilight sky', 'waiting for them this format balances vibrant illustrations with engaging text to captivate young readers and spark their imagination perfect for an adventure themed picture book about exploration and discovery', 'in the magical back cover a serene illustration of the village in prosperity clover playing joyfully with other young animals the four leaf clover framed proudly in the village square', 'watches fondly from above back cover illustration only a peaceful scene showing the oak tree at sunset finn and olly visible in their new home looking out at the forest', 'second spent together was its own adventure back cover illustration the clock now still as the kittens curl up asleep beside it dreaming of their next great adventure text blank', 'heart to discover its magic the adventure is just beginning she whispered this book not only promises an engaging story but also emphasizes the importance of courage curiosity and conservation', \"illustration a simple image of the bottle of invisible ink now half empty on max's desk with a window showing a starry night outside hinting at more adventures to come\", 'with all the creatures enjoying the sweets text and so the meadow was filled with stories and sweets laughter and adventures as the brothers dreamed of their next great quest', 'young squirrels gathered around him listening intently to his story this picture book aims to inspire courage wisdom and kindness through the adventurous and heartfelt journey of rusty the squirrel', \"hinting at the endless adventures that await her next visit this format combines vibrant illustrations with engaging text perfect for young readers to immerse themselves in ellie's magical library adventures\", 'came back to life page 10 illustration of the siblings returning to their village as heroes welcomed by the joyful residents text max and millie returned as heroes their hearts', 'rainbows to find out this book not only takes children on a journey through imaginative landscapes but also teaches them about problem solving friendship and the joy of helping others', 'forest with plants that subtly resemble musical instruments flowers like trumpets vines like strings of violins and trees with bark like the keys of a piano text with a buzz', 'on a pedestal nearby this picture book combines the thrill of adventure with the warmth of triumph making it a cherished tale for young readers to explore courage and perseverance', 'beside a sketchbook filled with drawings of their adventure this format creates a vivid and engaging story that not only entertains but also instills values of bravery and the joy', 'courage teamwork and the joys of discovering the unknown together each illustration aims to capture the essence of the journey pulling children into the magical world of lily and max', 'truth in their hearts illustration toby and lila walking back through the village greeted by the cheerful villagers children run up to hear the tales of their adventure back cover', 'next artistic adventure this picture book not only celebrates creativity and imagination but also subtly encourages children to discover the joy of creating their own worlds through art and storytelling', 'good for all this picture book encourages not only an adventurous spirit but also the values of bravery persistence and the power of honesty and self belief in overcoming difficulties', 'book not only tells the story of a thrilling adventure but also teaches values such as teamwork wisdom from listening to others and the joy of sharing experiences with friends', 'their beds max and lily drifted to sleep the toy box quietly glowing in the corner in their dreams they revisited the wonderful plushland a place of endless adventures end', \"moonflower luna's adventure had brought light to the whole village text no text just the illustration showing the end of luna's journey and the start of new tales to come\", 'for any challenge back cover illustration a serene view of tomorrow town at dawn with robbie and spark silhouetted against the rising sun looking out over the city they protected', 'softly next to them back cover illustration the moonlit burrow with a light shining from within the compass visible on a small table through the window suggesting more adventures await', 'up of the locked iron gate covered in ivy hinting at the hidden wonders within text the end of one adventure is just the beginning of another discover your garden', 'thrived in harmony thanks to the bravery of two little mice and their quest for the invisible thread a journey that reminded everyone about the power of friendship and understanding', 'sailed home their hearts full of memories from a night where the sea shone like the stars finn knew this was only the beginning of many more adventures the end', 'fire this book provides a thrilling adventure for young readers enhancing their imagination and teaching them the value of exploration and the joy of returning home enriched by their experiences', 'amidst vibrant trees and flowers back cover illustration a serene image of ember resting under a colorful tree the rainbow feather beside her the world around her rich with color', 'stars hinting at future adventures this picture book encourages curiosity and bravery with fantastical elements that will captivate young readers and invite them to dream of their own celestial adventures', 'will always lead you back to where the heart grows fonder together lily and max learned that the best wishes are the ones you find within your own courageous heart', \"bravery curiosity and the beauty of exploring the unknown perfectly suited for young readers each illustration would be colorful and detailed drawing children into milo's world and sparking their imaginations\"]\n"
          ]
        }
      ],
      "source": [
        "# Function to convert sequences back to text\n",
        "def sequences_to_text(sequences, tokenizer):\n",
        "    reverse_word_index = dict([(value, key) for (key, value) in tokenizer.word_index.items()])\n",
        "    reverse_word_index[0] = '<PAD>'  # For padding indices\n",
        "    texts = []\n",
        "    for seq in sequences:\n",
        "        words = [reverse_word_index.get(i, '?') for i in seq]\n",
        "        texts.append(' '.join(words).replace('<PAD>', '').strip())\n",
        "    return texts\n",
        "\n",
        "# Testing the function to convert back to text\n",
        "print(\"Original token:\")\n",
        "print(question_padded)\n",
        "print(\"\\nConverted back to text (questions):\")\n",
        "print(sequences_to_text(question_padded, tokenizer))\n",
        "\n",
        "print(\"Original token:\")\n",
        "print(answer_padded)\n",
        "print(\"\\nConverted back to text (answers):\")\n",
        "print(sequences_to_text(answer_padded, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKwhZllTbYP8"
      },
      "source": [
        "The code snippet demonstrates the setup and training of a Transformer model using prepared data. It defines hyperparameters such as the number of layers, model dimensions, feed-forward network size, number of attention heads, input vocabulary size, and maximum position encoding. A Transformer model is instantiated with these parameters. The model is then compiled using the Adam optimizer and sparse categorical cross-entropy loss function, with accuracy as the metric. Finally, the model is trained on tokenized and padded sample data for 100 epochs using the `fit` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6Wo3kJYcBvd"
      },
      "source": [
        "## Training a Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TawCJSFC3Jl",
        "outputId": "ae8234e2-eb7a-4d23-d82c-28b2e81426f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y86PJZLbDOVw"
      },
      "source": [
        "After verify that GPU is present in the instance, we can train the model below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajD17KSUL9On"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCK7mOU4F55e",
        "outputId": "739d7458-6ef1-439e-bdb6-801ad30b2679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 751: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 751/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0302 - loss: 8.4206 - val_accuracy: 0.0833 - val_loss: 11.6898 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 752: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 752/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0300 - loss: 8.0663 - val_accuracy: 0.0833 - val_loss: 11.6895 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 753: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 753/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 8.5331 - val_accuracy: 0.0833 - val_loss: 11.6893 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 754: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 754/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0324 - loss: 8.1890 - val_accuracy: 0.0833 - val_loss: 11.6890 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 755: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 755/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0323 - loss: 8.0280 - val_accuracy: 0.0833 - val_loss: 11.6887 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 756: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 756/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0340 - loss: 8.3319 - val_accuracy: 0.0833 - val_loss: 11.6886 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 757: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 757/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0302 - loss: 8.3026 - val_accuracy: 0.0833 - val_loss: 11.6884 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 758: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 758/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0335 - loss: 7.8489 - val_accuracy: 0.0833 - val_loss: 11.6882 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 759: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 759/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0305 - loss: 8.2778 - val_accuracy: 0.0833 - val_loss: 11.6878 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 760: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 760/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0288 - loss: 8.3306 - val_accuracy: 0.0833 - val_loss: 11.6875 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 761: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 761/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0294 - loss: 8.1954 - val_accuracy: 0.0833 - val_loss: 11.6871 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 762: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 762/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0326 - loss: 8.3126 - val_accuracy: 0.0833 - val_loss: 11.6867 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 763: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 763/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0319 - loss: 8.3556 - val_accuracy: 0.0833 - val_loss: 11.6864 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 764: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 764/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0278 - loss: 8.0155 - val_accuracy: 0.0833 - val_loss: 11.6861 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 765: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 765/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0297 - loss: 8.0546 - val_accuracy: 0.0833 - val_loss: 11.6858 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 766: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 766/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0294 - loss: 8.4500 - val_accuracy: 0.0833 - val_loss: 11.6854 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 767: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 767/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0266 - loss: 8.4112 - val_accuracy: 0.0833 - val_loss: 11.6856 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 768: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 768/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0281 - loss: 8.1869 - val_accuracy: 0.0833 - val_loss: 11.6858 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 769: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 769/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0298 - loss: 8.2588 - val_accuracy: 0.0833 - val_loss: 11.6859 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 770: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 770/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0280 - loss: 8.2286 - val_accuracy: 0.0833 - val_loss: 11.6859 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 771: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 771/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0293 - loss: 8.1016 - val_accuracy: 0.0833 - val_loss: 11.6858 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 772: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 772/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0324 - loss: 8.0639 - val_accuracy: 0.0833 - val_loss: 11.6855 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 773: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 773/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0372 - loss: 8.2846 - val_accuracy: 0.0833 - val_loss: 11.6852 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 774: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 774/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.2618 - val_accuracy: 0.0833 - val_loss: 11.6853 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 775: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 775/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0300 - loss: 8.3380 - val_accuracy: 0.0833 - val_loss: 11.6853 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 776: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 776/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0320 - loss: 8.4823 - val_accuracy: 0.0833 - val_loss: 11.6852 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 777: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 777/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0324 - loss: 8.2845 - val_accuracy: 0.0833 - val_loss: 11.6851 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 778: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 778/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0320 - loss: 8.3328 - val_accuracy: 0.0833 - val_loss: 11.6850 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 779: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 779/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0318 - loss: 8.1989 - val_accuracy: 0.0833 - val_loss: 11.6854 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 780: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 780/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0289 - loss: 8.2608 - val_accuracy: 0.0833 - val_loss: 11.6855 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 781: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 781/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0284 - loss: 8.4106 - val_accuracy: 0.0833 - val_loss: 11.6855 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 782: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 782/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0333 - loss: 8.1042 - val_accuracy: 0.0833 - val_loss: 11.6853 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 783: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 783/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0299 - loss: 8.2914 - val_accuracy: 0.0833 - val_loss: 11.6850 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 784: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 784/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0299 - loss: 8.3451 - val_accuracy: 0.0833 - val_loss: 11.6847 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 785: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 785/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0273 - loss: 8.1454 - val_accuracy: 0.0833 - val_loss: 11.6845 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 786: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 786/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0281 - loss: 8.1146 - val_accuracy: 0.0833 - val_loss: 11.6830 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 787: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 787/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0295 - loss: 8.1861 - val_accuracy: 0.0833 - val_loss: 11.6823 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 788: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 788/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0274 - loss: 8.2894 - val_accuracy: 0.0833 - val_loss: 11.6819 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 789: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 789/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0295 - loss: 8.4343 - val_accuracy: 0.0833 - val_loss: 11.6816 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 790: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 790/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0321 - loss: 8.2753 - val_accuracy: 0.0833 - val_loss: 11.6813 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 791: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 791/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0277 - loss: 8.3589 - val_accuracy: 0.0833 - val_loss: 11.6811 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 792: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 792/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0310 - loss: 8.3556 - val_accuracy: 0.0833 - val_loss: 11.6813 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 793: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 793/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0281 - loss: 8.1859 - val_accuracy: 0.0833 - val_loss: 11.6816 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 794: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 794/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0309 - loss: 8.3187 - val_accuracy: 0.0833 - val_loss: 11.6820 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 795: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 795/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0332 - loss: 8.2170 - val_accuracy: 0.0833 - val_loss: 11.6823 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 796: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 796/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0277 - loss: 8.4813 - val_accuracy: 0.0833 - val_loss: 11.6821 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 797: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 797/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0327 - loss: 7.9832 - val_accuracy: 0.0833 - val_loss: 11.6820 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 798: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 798/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0380 - loss: 8.3686 - val_accuracy: 0.0833 - val_loss: 11.6817 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 799: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 799/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0317 - loss: 8.0376 - val_accuracy: 0.0833 - val_loss: 11.6814 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 800: LearningRateScheduler setting learning rate to 4.999999987376214e-07.\n",
            "Epoch 800/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0299 - loss: 8.4936 - val_accuracy: 0.0833 - val_loss: 11.6811 - learning_rate: 5.0000e-07\n",
            "\n",
            "Epoch 801: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 801/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0277 - loss: 8.1155 - val_accuracy: 0.0833 - val_loss: 11.6811 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 802: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 802/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0333 - loss: 8.1410 - val_accuracy: 0.0833 - val_loss: 11.6812 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 803: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 803/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0330 - loss: 8.3054 - val_accuracy: 0.0833 - val_loss: 11.6812 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 804: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 804/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0297 - loss: 8.3168 - val_accuracy: 0.0833 - val_loss: 11.6814 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 805: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 805/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0269 - loss: 8.1714 - val_accuracy: 0.0833 - val_loss: 11.6815 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 806: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 806/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0306 - loss: 8.0732 - val_accuracy: 0.0833 - val_loss: 11.6815 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 807: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 807/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0322 - loss: 8.1912 - val_accuracy: 0.0833 - val_loss: 11.6814 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 808: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 808/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0320 - loss: 8.0728 - val_accuracy: 0.0833 - val_loss: 11.6815 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 809: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 809/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0294 - loss: 8.1242 - val_accuracy: 0.0833 - val_loss: 11.6815 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 810: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 810/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0315 - loss: 8.3464 - val_accuracy: 0.0833 - val_loss: 11.6814 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 811: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 811/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0320 - loss: 8.4595 - val_accuracy: 0.0833 - val_loss: 11.6813 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 812: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 812/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0320 - loss: 8.3708 - val_accuracy: 0.0833 - val_loss: 11.6811 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 813: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 813/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0322 - loss: 8.3176 - val_accuracy: 0.0833 - val_loss: 11.6810 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 814: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 814/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0331 - loss: 8.2091 - val_accuracy: 0.0833 - val_loss: 11.6808 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 815: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 815/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0276 - loss: 8.2065 - val_accuracy: 0.0833 - val_loss: 11.6808 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 816: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 816/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0281 - loss: 8.5671 - val_accuracy: 0.0833 - val_loss: 11.6810 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 817: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 817/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0321 - loss: 8.0419 - val_accuracy: 0.0833 - val_loss: 11.6807 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 818: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 818/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0331 - loss: 8.2772 - val_accuracy: 0.0833 - val_loss: 11.6799 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 819: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 819/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0289 - loss: 8.4545 - val_accuracy: 0.0833 - val_loss: 11.6794 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 820: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 820/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0319 - loss: 8.0509 - val_accuracy: 0.0833 - val_loss: 11.6791 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 821: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 821/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0272 - loss: 7.9801 - val_accuracy: 0.0833 - val_loss: 11.6790 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 822: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 822/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0336 - loss: 8.0593 - val_accuracy: 0.0833 - val_loss: 11.6789 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 823: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 823/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0284 - loss: 8.3775 - val_accuracy: 0.0833 - val_loss: 11.6787 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 824: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 824/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0317 - loss: 8.3151 - val_accuracy: 0.0833 - val_loss: 11.6786 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 825: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 825/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0309 - loss: 8.3261 - val_accuracy: 0.0833 - val_loss: 11.6784 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 826: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 826/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0328 - loss: 8.5564 - val_accuracy: 0.0833 - val_loss: 11.6782 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 827: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 827/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.2610 - val_accuracy: 0.0833 - val_loss: 11.6781 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 828: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 828/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0364 - loss: 8.4339 - val_accuracy: 0.0833 - val_loss: 11.6779 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 829: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 829/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0322 - loss: 8.0552 - val_accuracy: 0.0833 - val_loss: 11.6779 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 830: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 830/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0276 - loss: 8.2169 - val_accuracy: 0.0833 - val_loss: 11.6778 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 831: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 831/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0269 - loss: 8.4034 - val_accuracy: 0.0833 - val_loss: 11.6778 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 832: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 832/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.0991 - val_accuracy: 0.0833 - val_loss: 11.6778 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 833: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 833/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0311 - loss: 8.3650 - val_accuracy: 0.0833 - val_loss: 11.6779 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 834: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 834/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0338 - loss: 8.2937 - val_accuracy: 0.0833 - val_loss: 11.6780 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 835: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 835/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0303 - loss: 8.3693 - val_accuracy: 0.0833 - val_loss: 11.6780 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 836: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 836/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0346 - loss: 8.4606 - val_accuracy: 0.0833 - val_loss: 11.6779 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 837: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 837/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0330 - loss: 7.9754 - val_accuracy: 0.0833 - val_loss: 11.6779 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 838: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 838/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0278 - loss: 8.3021 - val_accuracy: 0.0833 - val_loss: 11.6777 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 839: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 839/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0339 - loss: 8.2402 - val_accuracy: 0.0833 - val_loss: 11.6776 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 840: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 840/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0324 - loss: 8.0958 - val_accuracy: 0.0833 - val_loss: 11.6775 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 841: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 841/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0275 - loss: 8.4162 - val_accuracy: 0.0833 - val_loss: 11.6773 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 842: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 842/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0307 - loss: 8.4053 - val_accuracy: 0.0833 - val_loss: 11.6773 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 843: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 843/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0325 - loss: 8.2552 - val_accuracy: 0.0833 - val_loss: 11.6772 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 844: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 844/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0320 - loss: 8.1361 - val_accuracy: 0.0833 - val_loss: 11.6771 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 845: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 845/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0288 - loss: 8.3000 - val_accuracy: 0.0833 - val_loss: 11.6771 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 846: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 846/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0299 - loss: 7.9528 - val_accuracy: 0.0833 - val_loss: 11.6771 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 847: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 847/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0288 - loss: 8.5543 - val_accuracy: 0.0833 - val_loss: 11.6771 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 848: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 848/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0377 - loss: 8.1128 - val_accuracy: 0.0833 - val_loss: 11.6770 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 849: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 849/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.3995 - val_accuracy: 0.0833 - val_loss: 11.6768 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 850: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 850/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0305 - loss: 8.2507 - val_accuracy: 0.0833 - val_loss: 11.6768 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 851: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 851/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0307 - loss: 8.3379 - val_accuracy: 0.0833 - val_loss: 11.6767 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 852: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 852/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0315 - loss: 8.3433 - val_accuracy: 0.0833 - val_loss: 11.6766 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 853: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 853/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0330 - loss: 8.1367 - val_accuracy: 0.0833 - val_loss: 11.6765 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 854: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 854/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0322 - loss: 8.0402 - val_accuracy: 0.0833 - val_loss: 11.6764 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 855: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 855/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0300 - loss: 8.3889 - val_accuracy: 0.0833 - val_loss: 11.6763 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 856: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 856/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0308 - loss: 8.0174 - val_accuracy: 0.0833 - val_loss: 11.6762 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 857: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 857/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0305 - loss: 8.3126 - val_accuracy: 0.0833 - val_loss: 11.6760 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 858: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 858/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0347 - loss: 7.9889 - val_accuracy: 0.0833 - val_loss: 11.6759 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 859: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 859/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0294 - loss: 8.2426 - val_accuracy: 0.0833 - val_loss: 11.6759 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 860: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 860/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0319 - loss: 8.3274 - val_accuracy: 0.0833 - val_loss: 11.6759 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 861: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 861/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0302 - loss: 8.0261 - val_accuracy: 0.0833 - val_loss: 11.6758 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 862: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 862/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0306 - loss: 8.1791 - val_accuracy: 0.0833 - val_loss: 11.6757 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 863: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 863/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0314 - loss: 8.2903 - val_accuracy: 0.0833 - val_loss: 11.6756 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 864: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 864/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0294 - loss: 8.2135 - val_accuracy: 0.0833 - val_loss: 11.6754 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 865: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 865/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0301 - loss: 8.3536 - val_accuracy: 0.0833 - val_loss: 11.6751 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 866: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 866/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0349 - loss: 8.3894 - val_accuracy: 0.0833 - val_loss: 11.6750 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 867: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 867/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0342 - loss: 8.0986 - val_accuracy: 0.0833 - val_loss: 11.6748 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 868: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 868/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0325 - loss: 8.3097 - val_accuracy: 0.0833 - val_loss: 11.6748 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 869: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 869/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0272 - loss: 8.3161 - val_accuracy: 0.0833 - val_loss: 11.6749 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 870: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 870/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0279 - loss: 8.1809 - val_accuracy: 0.0833 - val_loss: 11.6749 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 871: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 871/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0322 - loss: 8.2017 - val_accuracy: 0.0833 - val_loss: 11.6749 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 872: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 872/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0280 - loss: 8.4061 - val_accuracy: 0.0833 - val_loss: 11.6747 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 873: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 873/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0311 - loss: 8.3349 - val_accuracy: 0.0833 - val_loss: 11.6746 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 874: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 874/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0297 - loss: 8.4802 - val_accuracy: 0.0833 - val_loss: 11.6744 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 875: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 875/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0303 - loss: 8.4427 - val_accuracy: 0.0833 - val_loss: 11.6742 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 876: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 876/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0350 - loss: 8.1580 - val_accuracy: 0.0833 - val_loss: 11.6741 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 877: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 877/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0337 - loss: 8.2174 - val_accuracy: 0.0833 - val_loss: 11.6740 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 878: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 878/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0293 - loss: 8.4146 - val_accuracy: 0.0833 - val_loss: 11.6738 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 879: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 879/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0309 - loss: 8.3380 - val_accuracy: 0.0833 - val_loss: 11.6736 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 880: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 880/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0287 - loss: 8.5475 - val_accuracy: 0.0833 - val_loss: 11.6735 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 881: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 881/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.1459 - val_accuracy: 0.0833 - val_loss: 11.6734 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 882: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 882/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0282 - loss: 8.2102 - val_accuracy: 0.0833 - val_loss: 11.6733 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 883: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 883/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0313 - loss: 8.3148 - val_accuracy: 0.0833 - val_loss: 11.6732 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 884: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 884/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0304 - loss: 8.1532 - val_accuracy: 0.0833 - val_loss: 11.6730 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 885: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 885/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0329 - loss: 8.1618 - val_accuracy: 0.0833 - val_loss: 11.6728 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 886: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 886/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0318 - loss: 8.1360 - val_accuracy: 0.0833 - val_loss: 11.6732 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 887: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 887/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0290 - loss: 8.4981 - val_accuracy: 0.0833 - val_loss: 11.6735 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 888: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 888/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0352 - loss: 7.8745 - val_accuracy: 0.0833 - val_loss: 11.6736 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 889: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 889/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0282 - loss: 8.3655 - val_accuracy: 0.0833 - val_loss: 11.6738 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 890: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 890/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0376 - loss: 8.0940 - val_accuracy: 0.0833 - val_loss: 11.6741 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 891: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 891/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0329 - loss: 8.2456 - val_accuracy: 0.0833 - val_loss: 11.6743 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 892: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 892/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0346 - loss: 8.2820 - val_accuracy: 0.0833 - val_loss: 11.6743 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 893: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 893/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.2886 - val_accuracy: 0.0833 - val_loss: 11.6742 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 894: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 894/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0274 - loss: 8.2181 - val_accuracy: 0.0833 - val_loss: 11.6742 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 895: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 895/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0281 - loss: 8.0061 - val_accuracy: 0.0833 - val_loss: 11.6743 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 896: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 896/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0264 - loss: 8.3226 - val_accuracy: 0.0833 - val_loss: 11.6742 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 897: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 897/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.4594 - val_accuracy: 0.0833 - val_loss: 11.6741 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 898: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 898/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0312 - loss: 8.4158 - val_accuracy: 0.0833 - val_loss: 11.6740 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 899: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 899/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0284 - loss: 8.2434 - val_accuracy: 0.0833 - val_loss: 11.6740 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 900: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 900/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0293 - loss: 7.9977 - val_accuracy: 0.0833 - val_loss: 11.6739 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 901: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 901/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0291 - loss: 8.1323 - val_accuracy: 0.0833 - val_loss: 11.6738 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 902: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 902/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0285 - loss: 8.4142 - val_accuracy: 0.0833 - val_loss: 11.6736 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 903: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 903/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0284 - loss: 8.0423 - val_accuracy: 0.0833 - val_loss: 11.6735 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 904: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 904/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0339 - loss: 8.3264 - val_accuracy: 0.0833 - val_loss: 11.6733 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 905: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 905/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0293 - loss: 8.1354 - val_accuracy: 0.0833 - val_loss: 11.6733 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 906: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 906/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0294 - loss: 8.3671 - val_accuracy: 0.0833 - val_loss: 11.6732 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 907: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 907/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0288 - loss: 8.3190 - val_accuracy: 0.0833 - val_loss: 11.6731 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 908: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 908/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0265 - loss: 8.1218 - val_accuracy: 0.0833 - val_loss: 11.6730 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 909: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 909/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0390 - loss: 8.0738 - val_accuracy: 0.0833 - val_loss: 11.6729 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 910: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 910/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0360 - loss: 8.2155 - val_accuracy: 0.0833 - val_loss: 11.6727 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 911: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 911/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0293 - loss: 8.1683 - val_accuracy: 0.0833 - val_loss: 11.6726 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 912: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 912/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.4208 - val_accuracy: 0.0833 - val_loss: 11.6724 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 913: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 913/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0291 - loss: 8.5394 - val_accuracy: 0.0833 - val_loss: 11.6722 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 914: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 914/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0272 - loss: 8.5323 - val_accuracy: 0.0833 - val_loss: 11.6720 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 915: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 915/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0306 - loss: 8.1868 - val_accuracy: 0.0833 - val_loss: 11.6719 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 916: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 916/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0277 - loss: 8.1184 - val_accuracy: 0.0833 - val_loss: 11.6720 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 917: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 917/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.4616 - val_accuracy: 0.0833 - val_loss: 11.6721 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 918: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 918/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 8.3041 - val_accuracy: 0.0833 - val_loss: 11.6725 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 919: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 919/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0297 - loss: 8.2778 - val_accuracy: 0.0833 - val_loss: 11.6727 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 920: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 920/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0304 - loss: 8.4900 - val_accuracy: 0.0833 - val_loss: 11.6726 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 921: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 921/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.1974 - val_accuracy: 0.0833 - val_loss: 11.6726 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 922: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 922/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0313 - loss: 8.0517 - val_accuracy: 0.0833 - val_loss: 11.6725 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 923: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 923/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0320 - loss: 8.2899 - val_accuracy: 0.0833 - val_loss: 11.6724 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 924: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 924/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.3220 - val_accuracy: 0.0833 - val_loss: 11.6722 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 925: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 925/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0351 - loss: 8.1811 - val_accuracy: 0.0833 - val_loss: 11.6720 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 926: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 926/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0315 - loss: 8.2253 - val_accuracy: 0.0833 - val_loss: 11.6718 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 927: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 927/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0279 - loss: 8.3143 - val_accuracy: 0.0833 - val_loss: 11.6716 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 928: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 928/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0331 - loss: 8.4921 - val_accuracy: 0.0833 - val_loss: 11.6714 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 929: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 929/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.5362 - val_accuracy: 0.0833 - val_loss: 11.6713 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 930: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 930/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0280 - loss: 8.2435 - val_accuracy: 0.0833 - val_loss: 11.6712 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 931: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 931/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0308 - loss: 8.1981 - val_accuracy: 0.0833 - val_loss: 11.6712 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 932: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 932/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0316 - loss: 8.0593 - val_accuracy: 0.0833 - val_loss: 11.6712 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 933: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 933/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0330 - loss: 8.1599 - val_accuracy: 0.0833 - val_loss: 11.6711 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 934: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 934/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.5722 - val_accuracy: 0.0833 - val_loss: 11.6714 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 935: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 935/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0305 - loss: 7.9185 - val_accuracy: 0.0833 - val_loss: 11.6717 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 936: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 936/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0281 - loss: 8.2225 - val_accuracy: 0.0833 - val_loss: 11.6718 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 937: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 937/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0298 - loss: 8.0855 - val_accuracy: 0.0833 - val_loss: 11.6718 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 938: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 938/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0288 - loss: 8.3223 - val_accuracy: 0.0833 - val_loss: 11.6717 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 939: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 939/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0294 - loss: 8.1915 - val_accuracy: 0.0833 - val_loss: 11.6715 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 940: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 940/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0244 - loss: 8.2676 - val_accuracy: 0.0833 - val_loss: 11.6714 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 941: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 941/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0299 - loss: 8.0021 - val_accuracy: 0.0833 - val_loss: 11.6712 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 942: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 942/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0328 - loss: 8.2560 - val_accuracy: 0.0833 - val_loss: 11.6710 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 943: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 943/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0249 - loss: 8.3854 - val_accuracy: 0.0833 - val_loss: 11.6709 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 944: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 944/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0333 - loss: 8.1483 - val_accuracy: 0.0833 - val_loss: 11.6708 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 945: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 945/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0306 - loss: 8.1921 - val_accuracy: 0.0833 - val_loss: 11.6706 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 946: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 946/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0284 - loss: 8.3429 - val_accuracy: 0.0833 - val_loss: 11.6706 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 947: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 947/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0356 - loss: 8.2487 - val_accuracy: 0.0833 - val_loss: 11.6706 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 948: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 948/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0338 - loss: 8.1980 - val_accuracy: 0.0833 - val_loss: 11.6706 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 949: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 949/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0364 - loss: 8.0483 - val_accuracy: 0.0833 - val_loss: 11.6705 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 950: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 950/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0293 - loss: 8.3442 - val_accuracy: 0.0833 - val_loss: 11.6704 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 951: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 951/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0311 - loss: 8.1705 - val_accuracy: 0.0833 - val_loss: 11.6702 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 952: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 952/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0287 - loss: 8.4234 - val_accuracy: 0.0833 - val_loss: 11.6700 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 953: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 953/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0314 - loss: 8.2908 - val_accuracy: 0.0833 - val_loss: 11.6699 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 954: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 954/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0304 - loss: 8.1220 - val_accuracy: 0.0833 - val_loss: 11.6697 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 955: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 955/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0323 - loss: 8.3721 - val_accuracy: 0.0833 - val_loss: 11.6695 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 956: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 956/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0348 - loss: 8.1025 - val_accuracy: 0.0833 - val_loss: 11.6693 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 957: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 957/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0302 - loss: 8.0918 - val_accuracy: 0.0833 - val_loss: 11.6695 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 958: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 958/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0271 - loss: 8.1314 - val_accuracy: 0.0833 - val_loss: 11.6696 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 959: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 959/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.1463 - val_accuracy: 0.0833 - val_loss: 11.6697 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 960: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 960/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0356 - loss: 8.1718 - val_accuracy: 0.0833 - val_loss: 11.6696 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 961: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 961/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0266 - loss: 8.3231 - val_accuracy: 0.0833 - val_loss: 11.6699 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 962: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 962/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0272 - loss: 8.3857 - val_accuracy: 0.0833 - val_loss: 11.6702 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 963: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 963/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0322 - loss: 8.2447 - val_accuracy: 0.0833 - val_loss: 11.6703 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 964: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 964/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0318 - loss: 7.9660 - val_accuracy: 0.0833 - val_loss: 11.6703 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 965: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 965/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0266 - loss: 8.4432 - val_accuracy: 0.0833 - val_loss: 11.6702 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 966: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 966/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 8.0237 - val_accuracy: 0.0833 - val_loss: 11.6702 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 967: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 967/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0357 - loss: 8.3122 - val_accuracy: 0.0833 - val_loss: 11.6700 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 968: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 968/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0282 - loss: 8.1628 - val_accuracy: 0.0833 - val_loss: 11.6700 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 969: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 969/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0312 - loss: 8.4914 - val_accuracy: 0.0833 - val_loss: 11.6698 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 970: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 970/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0382 - loss: 8.3057 - val_accuracy: 0.0833 - val_loss: 11.6697 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 971: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 971/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0335 - loss: 8.3625 - val_accuracy: 0.0833 - val_loss: 11.6695 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 972: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 972/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0292 - loss: 8.2814 - val_accuracy: 0.0833 - val_loss: 11.6693 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 973: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 973/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0325 - loss: 8.3728 - val_accuracy: 0.0833 - val_loss: 11.6693 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 974: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 974/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0261 - loss: 8.2714 - val_accuracy: 0.0833 - val_loss: 11.6693 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 975: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 975/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 7.9322 - val_accuracy: 0.0833 - val_loss: 11.6692 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 976: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 976/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0336 - loss: 8.1508 - val_accuracy: 0.0833 - val_loss: 11.6691 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 977: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 977/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0293 - loss: 8.3051 - val_accuracy: 0.0833 - val_loss: 11.6689 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 978: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 978/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0365 - loss: 8.2855 - val_accuracy: 0.0833 - val_loss: 11.6688 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 979: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 979/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0348 - loss: 8.1014 - val_accuracy: 0.0833 - val_loss: 11.6685 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 980: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 980/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0266 - loss: 8.3327 - val_accuracy: 0.0833 - val_loss: 11.6683 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 981: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 981/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.2394 - val_accuracy: 0.0833 - val_loss: 11.6680 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 982: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 982/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.2340 - val_accuracy: 0.0833 - val_loss: 11.6678 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 983: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 983/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 8.3208 - val_accuracy: 0.0833 - val_loss: 11.6677 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 984: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 984/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0294 - loss: 8.3545 - val_accuracy: 0.0833 - val_loss: 11.6674 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 985: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 985/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.0880 - val_accuracy: 0.0833 - val_loss: 11.6672 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 986: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 986/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0260 - loss: 8.1993 - val_accuracy: 0.0833 - val_loss: 11.6671 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 987: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 987/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0320 - loss: 8.1574 - val_accuracy: 0.0833 - val_loss: 11.6669 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 988: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 988/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.1917 - val_accuracy: 0.0833 - val_loss: 11.6667 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 989: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 989/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.1431 - val_accuracy: 0.0833 - val_loss: 11.6665 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 990: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 990/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0279 - loss: 8.2591 - val_accuracy: 0.0833 - val_loss: 11.6664 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 991: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 991/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 7.9612 - val_accuracy: 0.0833 - val_loss: 11.6662 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 992: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 992/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.4289 - val_accuracy: 0.0833 - val_loss: 11.6660 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 993: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 993/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0338 - loss: 7.9626 - val_accuracy: 0.0833 - val_loss: 11.6659 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 994: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 994/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0301 - loss: 8.3284 - val_accuracy: 0.0833 - val_loss: 11.6657 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 995: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 995/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0341 - loss: 8.0080 - val_accuracy: 0.0833 - val_loss: 11.6657 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 996: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 996/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0301 - loss: 8.1285 - val_accuracy: 0.0833 - val_loss: 11.6656 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 997: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 997/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0316 - loss: 8.1679 - val_accuracy: 0.0833 - val_loss: 11.6655 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 998: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 998/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 7.9785 - val_accuracy: 0.0833 - val_loss: 11.6655 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 999: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 999/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0302 - loss: 8.4036 - val_accuracy: 0.0833 - val_loss: 11.6654 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 1000: LearningRateScheduler setting learning rate to 2.499999993688107e-07.\n",
            "Epoch 1000/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0334 - loss: 8.3891 - val_accuracy: 0.0833 - val_loss: 11.6653 - learning_rate: 2.5000e-07\n",
            "\n",
            "Epoch 1001: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1001/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0332 - loss: 8.3207 - val_accuracy: 0.0833 - val_loss: 11.6653 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1002: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1002/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0278 - loss: 8.4334 - val_accuracy: 0.0833 - val_loss: 11.6652 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1003: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1003/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0321 - loss: 8.3644 - val_accuracy: 0.0833 - val_loss: 11.6651 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1004: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1004/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0289 - loss: 8.3476 - val_accuracy: 0.0833 - val_loss: 11.6651 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1005: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1005/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0297 - loss: 8.0520 - val_accuracy: 0.0833 - val_loss: 11.6651 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1006: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1006/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0300 - loss: 8.6222 - val_accuracy: 0.0833 - val_loss: 11.6651 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1007: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1007/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0358 - loss: 8.0344 - val_accuracy: 0.0833 - val_loss: 11.6651 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1008: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1008/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0336 - loss: 8.2093 - val_accuracy: 0.0833 - val_loss: 11.6650 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1009: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1009/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0369 - loss: 8.0968 - val_accuracy: 0.0833 - val_loss: 11.6649 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1010: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1010/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0283 - loss: 8.2308 - val_accuracy: 0.0833 - val_loss: 11.6648 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1011: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1011/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0362 - loss: 8.3702 - val_accuracy: 0.0833 - val_loss: 11.6647 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1012: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1012/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0277 - loss: 8.3570 - val_accuracy: 0.0833 - val_loss: 11.6647 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1013: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1013/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0323 - loss: 8.2255 - val_accuracy: 0.0833 - val_loss: 11.6646 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1014: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1014/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0336 - loss: 8.0073 - val_accuracy: 0.0833 - val_loss: 11.6645 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1015: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1015/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0346 - loss: 8.0539 - val_accuracy: 0.0833 - val_loss: 11.6645 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1016: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1016/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0335 - loss: 7.9108 - val_accuracy: 0.0833 - val_loss: 11.6644 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1017: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1017/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0293 - loss: 8.2849 - val_accuracy: 0.0833 - val_loss: 11.6644 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1018: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1018/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0288 - loss: 8.3862 - val_accuracy: 0.0833 - val_loss: 11.6643 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1019: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1019/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0307 - loss: 8.2056 - val_accuracy: 0.0833 - val_loss: 11.6642 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1020: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1020/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.0564 - val_accuracy: 0.0833 - val_loss: 11.6641 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1021: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1021/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0325 - loss: 8.2996 - val_accuracy: 0.0833 - val_loss: 11.6640 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1022: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1022/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0384 - loss: 8.1777 - val_accuracy: 0.0833 - val_loss: 11.6640 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1023: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1023/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0297 - loss: 8.0305 - val_accuracy: 0.0833 - val_loss: 11.6639 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1024: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1024/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0367 - loss: 8.0923 - val_accuracy: 0.0833 - val_loss: 11.6639 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1025: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1025/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0308 - loss: 8.2747 - val_accuracy: 0.0833 - val_loss: 11.6638 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1026: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1026/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.1329 - val_accuracy: 0.0833 - val_loss: 11.6637 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1027: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1027/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0294 - loss: 8.3704 - val_accuracy: 0.0833 - val_loss: 11.6635 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1028: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1028/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.1335 - val_accuracy: 0.0833 - val_loss: 11.6634 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1029: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1029/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0308 - loss: 8.1986 - val_accuracy: 0.0833 - val_loss: 11.6634 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1030: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1030/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 8.1517 - val_accuracy: 0.0833 - val_loss: 11.6633 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1031: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1031/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0356 - loss: 8.2230 - val_accuracy: 0.0833 - val_loss: 11.6633 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1032: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1032/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0341 - loss: 8.1638 - val_accuracy: 0.0833 - val_loss: 11.6632 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1033: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1033/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0268 - loss: 8.2370 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1034: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1034/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.3271 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1035: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1035/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.2200 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1036: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1036/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0334 - loss: 8.3369 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1037: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1037/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0278 - loss: 8.6290 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1038: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1038/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0337 - loss: 8.1770 - val_accuracy: 0.0833 - val_loss: 11.6631 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1039: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1039/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 8.0977 - val_accuracy: 0.0833 - val_loss: 11.6630 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1040: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1040/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0363 - loss: 8.3571 - val_accuracy: 0.0833 - val_loss: 11.6629 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1041: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1041/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0303 - loss: 8.1652 - val_accuracy: 0.0833 - val_loss: 11.6628 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1042: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1042/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0322 - loss: 8.2488 - val_accuracy: 0.0833 - val_loss: 11.6628 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1043: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1043/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0329 - loss: 8.1067 - val_accuracy: 0.0833 - val_loss: 11.6628 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1044: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1044/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.0467 - val_accuracy: 0.0833 - val_loss: 11.6628 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1045: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1045/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0345 - loss: 7.9857 - val_accuracy: 0.0833 - val_loss: 11.6627 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1046: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1046/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.3480 - val_accuracy: 0.0833 - val_loss: 11.6627 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1047: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1047/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 8.0865 - val_accuracy: 0.0833 - val_loss: 11.6626 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1048: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1048/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0322 - loss: 8.1805 - val_accuracy: 0.0833 - val_loss: 11.6625 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1049: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1049/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0298 - loss: 8.1707 - val_accuracy: 0.0833 - val_loss: 11.6624 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1050: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1050/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.3861 - val_accuracy: 0.0833 - val_loss: 11.6623 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1051: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1051/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0296 - loss: 8.4123 - val_accuracy: 0.0833 - val_loss: 11.6623 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1052: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1052/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0363 - loss: 8.0584 - val_accuracy: 0.0833 - val_loss: 11.6622 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1053: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1053/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0319 - loss: 8.1749 - val_accuracy: 0.0833 - val_loss: 11.6622 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1054: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1054/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.2861 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1055: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1055/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0366 - loss: 8.2924 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1056: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1056/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.2644 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1057: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1057/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.0927 - val_accuracy: 0.0833 - val_loss: 11.6620 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1058: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1058/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0274 - loss: 8.1411 - val_accuracy: 0.0833 - val_loss: 11.6619 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1059: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1059/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0346 - loss: 8.1082 - val_accuracy: 0.0833 - val_loss: 11.6620 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1060: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1060/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0333 - loss: 8.3348 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1061: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1061/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0312 - loss: 8.0904 - val_accuracy: 0.0833 - val_loss: 11.6622 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1062: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1062/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0295 - loss: 8.2990 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1063: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1063/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0310 - loss: 8.0705 - val_accuracy: 0.0833 - val_loss: 11.6621 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1064: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1064/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.2625 - val_accuracy: 0.0833 - val_loss: 11.6620 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1065: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1065/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0329 - loss: 8.3827 - val_accuracy: 0.0833 - val_loss: 11.6619 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1066: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1066/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.4530 - val_accuracy: 0.0833 - val_loss: 11.6618 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1067: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1067/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0322 - loss: 8.4140 - val_accuracy: 0.0833 - val_loss: 11.6617 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1068: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1068/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0265 - loss: 8.3635 - val_accuracy: 0.0833 - val_loss: 11.6616 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1069: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1069/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0340 - loss: 8.1409 - val_accuracy: 0.0833 - val_loss: 11.6616 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1070: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1070/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0276 - loss: 8.2203 - val_accuracy: 0.0833 - val_loss: 11.6615 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1071: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1071/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0313 - loss: 8.0888 - val_accuracy: 0.0833 - val_loss: 11.6615 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1072: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1072/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0293 - loss: 8.2566 - val_accuracy: 0.0833 - val_loss: 11.6614 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1073: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1073/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0306 - loss: 8.0275 - val_accuracy: 0.0833 - val_loss: 11.6614 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1074: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1074/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0338 - loss: 8.2522 - val_accuracy: 0.0833 - val_loss: 11.6613 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1075: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1075/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 8.1609 - val_accuracy: 0.0833 - val_loss: 11.6612 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1076: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1076/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0366 - loss: 8.0322 - val_accuracy: 0.0833 - val_loss: 11.6611 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1077: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1077/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0329 - loss: 8.1795 - val_accuracy: 0.0833 - val_loss: 11.6610 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1078: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1078/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0301 - loss: 8.0352 - val_accuracy: 0.0833 - val_loss: 11.6609 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1079: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1079/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0325 - loss: 8.1917 - val_accuracy: 0.0833 - val_loss: 11.6609 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1080: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1080/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0331 - loss: 8.4763 - val_accuracy: 0.0833 - val_loss: 11.6609 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1081: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1081/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0295 - loss: 8.3277 - val_accuracy: 0.0833 - val_loss: 11.6609 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1082: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1082/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0307 - loss: 8.4331 - val_accuracy: 0.0833 - val_loss: 11.6609 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1083: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1083/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0323 - loss: 8.2851 - val_accuracy: 0.0833 - val_loss: 11.6608 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1084: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1084/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0272 - loss: 8.4502 - val_accuracy: 0.0833 - val_loss: 11.6607 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1085: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1085/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0339 - loss: 8.2128 - val_accuracy: 0.0833 - val_loss: 11.6606 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1086: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1086/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.2541 - val_accuracy: 0.0833 - val_loss: 11.6605 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1087: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1087/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0313 - loss: 8.0717 - val_accuracy: 0.0833 - val_loss: 11.6604 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1088: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1088/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0300 - loss: 8.3503 - val_accuracy: 0.0833 - val_loss: 11.6603 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1089: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1089/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0306 - loss: 8.1952 - val_accuracy: 0.0833 - val_loss: 11.6602 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1090: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1090/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0303 - loss: 8.2377 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1091: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1091/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0301 - loss: 8.0959 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1092: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1092/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0321 - loss: 8.1845 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1093: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1093/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0328 - loss: 7.9240 - val_accuracy: 0.0833 - val_loss: 11.6600 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1094: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1094/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0321 - loss: 8.1193 - val_accuracy: 0.0833 - val_loss: 11.6599 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1095: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1095/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0318 - loss: 8.4259 - val_accuracy: 0.0833 - val_loss: 11.6599 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1096: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1096/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 7.9592 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1097: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1097/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0385 - loss: 8.0028 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1098: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1098/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.4398 - val_accuracy: 0.0833 - val_loss: 11.6601 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1099: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1099/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0281 - loss: 8.2290 - val_accuracy: 0.0833 - val_loss: 11.6600 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1100: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1100/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0352 - loss: 8.2055 - val_accuracy: 0.0833 - val_loss: 11.6599 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1101: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1101/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0275 - loss: 8.0668 - val_accuracy: 0.0833 - val_loss: 11.6598 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1102: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1102/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0296 - loss: 8.2545 - val_accuracy: 0.0833 - val_loss: 11.6597 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1103: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1103/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.4291 - val_accuracy: 0.0833 - val_loss: 11.6596 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1104: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1104/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0296 - loss: 8.1940 - val_accuracy: 0.0833 - val_loss: 11.6596 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1105: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1105/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0324 - loss: 8.3854 - val_accuracy: 0.0833 - val_loss: 11.6595 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1106: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1106/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.2414 - val_accuracy: 0.0833 - val_loss: 11.6595 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1107: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1107/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.3634 - val_accuracy: 0.0833 - val_loss: 11.6595 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1108: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1108/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0279 - loss: 8.1055 - val_accuracy: 0.0833 - val_loss: 11.6594 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1109: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1109/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0298 - loss: 8.3223 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1110: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1110/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 7.9994 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1111: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1111/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0351 - loss: 8.1386 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1112: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1112/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0295 - loss: 8.4834 - val_accuracy: 0.0833 - val_loss: 11.6594 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1113: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1113/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.2203 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1114: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1114/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.1854 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1115: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1115/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0325 - loss: 8.4270 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1116: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1116/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 8.1296 - val_accuracy: 0.0833 - val_loss: 11.6593 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1117: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1117/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0308 - loss: 8.6215 - val_accuracy: 0.0833 - val_loss: 11.6592 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1118: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1118/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.4837 - val_accuracy: 0.0833 - val_loss: 11.6592 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1119: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1119/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0359 - loss: 7.9887 - val_accuracy: 0.0833 - val_loss: 11.6591 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1120: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1120/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0362 - loss: 8.0073 - val_accuracy: 0.0833 - val_loss: 11.6590 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1121: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1121/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0353 - loss: 8.1352 - val_accuracy: 0.0833 - val_loss: 11.6590 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1122: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1122/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.3369 - val_accuracy: 0.0833 - val_loss: 11.6589 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1123: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1123/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 8.1351 - val_accuracy: 0.0833 - val_loss: 11.6588 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1124: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1124/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.3910 - val_accuracy: 0.0833 - val_loss: 11.6587 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1125: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1125/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0340 - loss: 7.9644 - val_accuracy: 0.0833 - val_loss: 11.6587 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1126: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1126/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0314 - loss: 8.2975 - val_accuracy: 0.0833 - val_loss: 11.6587 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1127: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1127/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0277 - loss: 8.1284 - val_accuracy: 0.0833 - val_loss: 11.6586 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1128: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1128/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0353 - loss: 8.1223 - val_accuracy: 0.0833 - val_loss: 11.6586 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1129: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1129/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0301 - loss: 8.3464 - val_accuracy: 0.0833 - val_loss: 11.6586 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1130: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1130/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0274 - loss: 8.4324 - val_accuracy: 0.0833 - val_loss: 11.6586 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1131: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1131/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0344 - loss: 7.9910 - val_accuracy: 0.0833 - val_loss: 11.6585 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1132: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1132/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.2968 - val_accuracy: 0.0833 - val_loss: 11.6584 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1133: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1133/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0331 - loss: 8.3320 - val_accuracy: 0.0833 - val_loss: 11.6584 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1134: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1134/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0319 - loss: 8.4094 - val_accuracy: 0.0833 - val_loss: 11.6583 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1135: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1135/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0319 - loss: 8.1468 - val_accuracy: 0.0833 - val_loss: 11.6582 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1136: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1136/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0281 - loss: 8.0936 - val_accuracy: 0.0833 - val_loss: 11.6582 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1137: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1137/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.3538 - val_accuracy: 0.0833 - val_loss: 11.6581 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1138: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1138/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0359 - loss: 8.1205 - val_accuracy: 0.0833 - val_loss: 11.6580 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1139: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1139/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0322 - loss: 8.3322 - val_accuracy: 0.0833 - val_loss: 11.6579 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1140: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1140/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0301 - loss: 8.3674 - val_accuracy: 0.0833 - val_loss: 11.6578 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1141: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1141/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.4626 - val_accuracy: 0.0833 - val_loss: 11.6577 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1142: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1142/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0297 - loss: 7.9613 - val_accuracy: 0.0833 - val_loss: 11.6576 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1143: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1143/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.0183 - val_accuracy: 0.0833 - val_loss: 11.6575 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1144: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1144/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0292 - loss: 8.3198 - val_accuracy: 0.0833 - val_loss: 11.6574 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1145: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1145/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.3997 - val_accuracy: 0.0833 - val_loss: 11.6573 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1146: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1146/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.4570 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1147: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1147/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.2580 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1148: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1148/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.5934 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1149: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1149/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 8.1883 - val_accuracy: 0.0833 - val_loss: 11.6573 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1150: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1150/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0286 - loss: 8.4200 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1151: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1151/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0345 - loss: 8.1827 - val_accuracy: 0.0833 - val_loss: 11.6571 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1152: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1152/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0268 - loss: 8.3131 - val_accuracy: 0.0833 - val_loss: 11.6571 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1153: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1153/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0298 - loss: 8.2823 - val_accuracy: 0.0833 - val_loss: 11.6570 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1154: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1154/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.1566 - val_accuracy: 0.0833 - val_loss: 11.6570 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1155: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1155/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0292 - loss: 8.2778 - val_accuracy: 0.0833 - val_loss: 11.6571 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1156: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1156/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0306 - loss: 8.0511 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1157: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1157/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0289 - loss: 8.3734 - val_accuracy: 0.0833 - val_loss: 11.6573 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1158: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1158/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.2285 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1159: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1159/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0308 - loss: 8.3095 - val_accuracy: 0.0833 - val_loss: 11.6572 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1160: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1160/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0282 - loss: 8.1615 - val_accuracy: 0.0833 - val_loss: 11.6571 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1161: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1161/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.2652 - val_accuracy: 0.0833 - val_loss: 11.6571 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1162: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1162/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0312 - loss: 7.9004 - val_accuracy: 0.0833 - val_loss: 11.6570 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1163: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1163/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0338 - loss: 8.3236 - val_accuracy: 0.0833 - val_loss: 11.6569 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1164: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1164/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0314 - loss: 8.2091 - val_accuracy: 0.0833 - val_loss: 11.6569 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1165: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1165/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.3374 - val_accuracy: 0.0833 - val_loss: 11.6568 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1166: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1166/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0297 - loss: 8.1837 - val_accuracy: 0.0833 - val_loss: 11.6567 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1167: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1167/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0368 - loss: 8.0055 - val_accuracy: 0.0833 - val_loss: 11.6566 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1168: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1168/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0304 - loss: 8.4372 - val_accuracy: 0.0833 - val_loss: 11.6566 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1169: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1169/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.5077 - val_accuracy: 0.0833 - val_loss: 11.6564 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1170: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1170/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0288 - loss: 7.9567 - val_accuracy: 0.0833 - val_loss: 11.6564 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1171: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1171/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0339 - loss: 7.9902 - val_accuracy: 0.0833 - val_loss: 11.6563 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1172: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1172/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 8.3983 - val_accuracy: 0.0833 - val_loss: 11.6563 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1173: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1173/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0337 - loss: 8.3228 - val_accuracy: 0.0833 - val_loss: 11.6562 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1174: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1174/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0286 - loss: 8.1329 - val_accuracy: 0.0833 - val_loss: 11.6561 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1175: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1175/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0338 - loss: 7.9849 - val_accuracy: 0.0833 - val_loss: 11.6560 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1176: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1176/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0324 - loss: 8.1994 - val_accuracy: 0.0833 - val_loss: 11.6560 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1177: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1177/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0265 - loss: 8.1718 - val_accuracy: 0.0833 - val_loss: 11.6559 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1178: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1178/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0272 - loss: 8.2489 - val_accuracy: 0.0833 - val_loss: 11.6563 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1179: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1179/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0375 - loss: 8.2984 - val_accuracy: 0.0833 - val_loss: 11.6564 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1180: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1180/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0304 - loss: 8.4141 - val_accuracy: 0.0833 - val_loss: 11.6565 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1181: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1181/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.3281 - val_accuracy: 0.0833 - val_loss: 11.6564 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1182: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1182/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0324 - loss: 8.2492 - val_accuracy: 0.0833 - val_loss: 11.6564 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1183: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1183/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0366 - loss: 8.0054 - val_accuracy: 0.0833 - val_loss: 11.6563 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1184: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1184/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0282 - loss: 8.4353 - val_accuracy: 0.0833 - val_loss: 11.6561 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1185: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1185/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.2141 - val_accuracy: 0.0833 - val_loss: 11.6560 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1186: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1186/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0282 - loss: 8.1769 - val_accuracy: 0.0833 - val_loss: 11.6559 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1187: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1187/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.3926 - val_accuracy: 0.0833 - val_loss: 11.6558 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1188: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1188/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0274 - loss: 8.5983 - val_accuracy: 0.0833 - val_loss: 11.6557 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1189: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1189/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0327 - loss: 8.1295 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1190: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1190/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.4271 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1191: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1191/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0390 - loss: 7.8530 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1192: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1192/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0349 - loss: 8.2792 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1193: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1193/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 8.4409 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1194: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1194/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0287 - loss: 8.2485 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1195: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1195/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 8.3915 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1196: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1196/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.0671 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1197: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1197/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.3972 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1198: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1198/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0351 - loss: 8.1394 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1199: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1199/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.3985 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1200: LearningRateScheduler setting learning rate to 1.2499999968440534e-07.\n",
            "Epoch 1200/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.1858 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 1.2500e-07\n",
            "\n",
            "Epoch 1201: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1201/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0320 - loss: 8.3700 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1202: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1202/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0275 - loss: 8.4976 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1203: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1203/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0371 - loss: 8.1468 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1204: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1204/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.4221 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1205: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1205/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0350 - loss: 8.1824 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1206: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1206/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0328 - loss: 8.2835 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1207: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1207/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0323 - loss: 8.0330 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1208: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1208/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0335 - loss: 8.3342 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1209: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1209/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.0463 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1210: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1210/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0308 - loss: 8.3225 - val_accuracy: 0.0833 - val_loss: 11.6555 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1211: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1211/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.1397 - val_accuracy: 0.0833 - val_loss: 11.6555 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1212: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1212/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0301 - loss: 8.0792 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1213: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1213/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0289 - loss: 8.3997 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1214: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1214/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0262 - loss: 8.3338 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1215: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1215/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0345 - loss: 7.9867 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1216: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1216/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.1719 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1217: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1217/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0384 - loss: 8.1135 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1218: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1218/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 7.8211 - val_accuracy: 0.0833 - val_loss: 11.6556 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1219: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1219/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0332 - loss: 8.1743 - val_accuracy: 0.0833 - val_loss: 11.6555 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1220: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1220/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 8.2194 - val_accuracy: 0.0833 - val_loss: 11.6555 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1221: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1221/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0338 - loss: 8.1776 - val_accuracy: 0.0833 - val_loss: 11.6555 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1222: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1222/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0277 - loss: 8.2088 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1223: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1223/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0285 - loss: 8.1869 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1224: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1224/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0298 - loss: 8.1007 - val_accuracy: 0.0833 - val_loss: 11.6554 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1225: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1225/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0333 - loss: 8.1240 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1226: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1226/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0323 - loss: 8.1594 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1227: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1227/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0360 - loss: 7.9700 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1228: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1228/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0283 - loss: 8.3798 - val_accuracy: 0.0833 - val_loss: 11.6553 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1229: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1229/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0334 - loss: 8.2368 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1230: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1230/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 8.2343 - val_accuracy: 0.0833 - val_loss: 11.6552 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1231: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1231/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 8.2259 - val_accuracy: 0.0833 - val_loss: 11.6551 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1232: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1232/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.3665 - val_accuracy: 0.0833 - val_loss: 11.6551 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1233: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1233/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0310 - loss: 8.4087 - val_accuracy: 0.0833 - val_loss: 11.6551 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1234: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1234/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0330 - loss: 8.3491 - val_accuracy: 0.0833 - val_loss: 11.6551 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1235: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1235/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0273 - loss: 8.5807 - val_accuracy: 0.0833 - val_loss: 11.6551 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1236: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1236/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.2833 - val_accuracy: 0.0833 - val_loss: 11.6550 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1237: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1237/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 7.9655 - val_accuracy: 0.0833 - val_loss: 11.6550 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1238: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1238/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0348 - loss: 8.1459 - val_accuracy: 0.0833 - val_loss: 11.6549 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1239: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1239/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.2112 - val_accuracy: 0.0833 - val_loss: 11.6549 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1240: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1240/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0328 - loss: 8.1229 - val_accuracy: 0.0833 - val_loss: 11.6549 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1241: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1241/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.1133 - val_accuracy: 0.0833 - val_loss: 11.6548 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1242: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1242/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.2162 - val_accuracy: 0.0833 - val_loss: 11.6548 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1243: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1243/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.0335 - val_accuracy: 0.0833 - val_loss: 11.6547 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1244: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1244/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0348 - loss: 8.3551 - val_accuracy: 0.0833 - val_loss: 11.6547 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1245: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1245/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0324 - loss: 8.1920 - val_accuracy: 0.0833 - val_loss: 11.6547 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1246: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1246/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.3125 - val_accuracy: 0.0833 - val_loss: 11.6546 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1247: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1247/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.3204 - val_accuracy: 0.0833 - val_loss: 11.6546 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1248: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1248/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 8.3363 - val_accuracy: 0.0833 - val_loss: 11.6545 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1249: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1249/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0293 - loss: 8.0827 - val_accuracy: 0.0833 - val_loss: 11.6545 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1250: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1250/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0288 - loss: 8.4996 - val_accuracy: 0.0833 - val_loss: 11.6544 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1251: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1251/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 8.1481 - val_accuracy: 0.0833 - val_loss: 11.6544 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1252: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1252/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.6135 - val_accuracy: 0.0833 - val_loss: 11.6543 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1253: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1253/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0280 - loss: 8.2310 - val_accuracy: 0.0833 - val_loss: 11.6543 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1254: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1254/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0329 - loss: 8.3614 - val_accuracy: 0.0833 - val_loss: 11.6542 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1255: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1255/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0325 - loss: 7.9721 - val_accuracy: 0.0833 - val_loss: 11.6541 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1256: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1256/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.2804 - val_accuracy: 0.0833 - val_loss: 11.6541 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1257: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1257/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0296 - loss: 8.0885 - val_accuracy: 0.0833 - val_loss: 11.6541 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1258: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1258/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.3438 - val_accuracy: 0.0833 - val_loss: 11.6540 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1259: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1259/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0305 - loss: 8.2198 - val_accuracy: 0.0833 - val_loss: 11.6540 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1260: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1260/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0320 - loss: 8.1167 - val_accuracy: 0.0833 - val_loss: 11.6540 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1261: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1261/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0335 - loss: 8.1681 - val_accuracy: 0.0833 - val_loss: 11.6540 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1262: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1262/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0295 - loss: 8.3656 - val_accuracy: 0.0833 - val_loss: 11.6539 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1263: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1263/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0285 - loss: 8.4261 - val_accuracy: 0.0833 - val_loss: 11.6539 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1264: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1264/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0354 - loss: 8.0456 - val_accuracy: 0.0833 - val_loss: 11.6538 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1265: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1265/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.5077 - val_accuracy: 0.0833 - val_loss: 11.6538 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1266: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1266/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.3702 - val_accuracy: 0.0833 - val_loss: 11.6537 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1267: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1267/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0294 - loss: 8.1284 - val_accuracy: 0.0833 - val_loss: 11.6537 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1268: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1268/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0353 - loss: 8.2464 - val_accuracy: 0.0833 - val_loss: 11.6537 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1269: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1269/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0295 - loss: 8.1796 - val_accuracy: 0.0833 - val_loss: 11.6536 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1270: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1270/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0334 - loss: 8.2959 - val_accuracy: 0.0833 - val_loss: 11.6536 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1271: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1271/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0315 - loss: 8.2285 - val_accuracy: 0.0833 - val_loss: 11.6536 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1272: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1272/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.2273 - val_accuracy: 0.0833 - val_loss: 11.6535 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1273: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1273/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.1876 - val_accuracy: 0.0833 - val_loss: 11.6535 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1274: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1274/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0287 - loss: 8.2091 - val_accuracy: 0.0833 - val_loss: 11.6535 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1275: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1275/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0302 - loss: 8.1379 - val_accuracy: 0.0833 - val_loss: 11.6534 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1276: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1276/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0293 - loss: 8.2224 - val_accuracy: 0.0833 - val_loss: 11.6534 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1277: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1277/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0332 - loss: 8.0907 - val_accuracy: 0.0833 - val_loss: 11.6534 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1278: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1278/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0343 - loss: 8.1485 - val_accuracy: 0.0833 - val_loss: 11.6534 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1279: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1279/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0308 - loss: 8.3979 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1280: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1280/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.1184 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1281: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1281/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0278 - loss: 8.2738 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1282: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1282/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0298 - loss: 8.0932 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1283: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1283/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0300 - loss: 8.6389 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1284: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1284/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0364 - loss: 8.0635 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1285: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1285/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0369 - loss: 8.1253 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1286: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1286/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0364 - loss: 8.5079 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1287: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1287/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0384 - loss: 8.2328 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1288: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1288/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0296 - loss: 8.2612 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1289: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1289/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 8.3813 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1290: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1290/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.1038 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1291: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1291/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.2733 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1292: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1292/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 8.3795 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1293: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1293/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0345 - loss: 8.2145 - val_accuracy: 0.0833 - val_loss: 11.6530 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1294: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1294/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0281 - loss: 8.2607 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1295: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1295/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0274 - loss: 8.4579 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1296: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1296/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.2976 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1297: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1297/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.3995 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1298: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1298/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 7.9843 - val_accuracy: 0.0833 - val_loss: 11.6533 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1299: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1299/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.1211 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1300: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1300/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.4632 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1301: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1301/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0298 - loss: 8.2959 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1302: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1302/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0299 - loss: 8.5024 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1303: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1303/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0313 - loss: 7.7373 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1304: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1304/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0277 - loss: 8.1080 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1305: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1305/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.0597 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1306: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1306/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0354 - loss: 8.0946 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1307: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1307/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0347 - loss: 7.8509 - val_accuracy: 0.0833 - val_loss: 11.6530 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1308: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1308/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.2907 - val_accuracy: 0.0833 - val_loss: 11.6530 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1309: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1309/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0334 - loss: 8.1685 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1310: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1310/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 7.9577 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1311: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1311/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0319 - loss: 8.1077 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1312: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1312/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.2917 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1313: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1313/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 8.1175 - val_accuracy: 0.0833 - val_loss: 11.6532 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1314: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1314/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0359 - loss: 8.1523 - val_accuracy: 0.0833 - val_loss: 11.6531 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1315: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1315/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0304 - loss: 8.0341 - val_accuracy: 0.0833 - val_loss: 11.6530 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1316: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1316/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.1995 - val_accuracy: 0.0833 - val_loss: 11.6528 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1317: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1317/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.1953 - val_accuracy: 0.0833 - val_loss: 11.6526 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1318: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1318/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0299 - loss: 8.4630 - val_accuracy: 0.0833 - val_loss: 11.6526 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1319: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1319/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0348 - loss: 8.2660 - val_accuracy: 0.0833 - val_loss: 11.6525 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1320: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1320/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.0966 - val_accuracy: 0.0833 - val_loss: 11.6524 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1321: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1321/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0342 - loss: 8.0884 - val_accuracy: 0.0833 - val_loss: 11.6524 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1322: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1322/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0271 - loss: 8.6715 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1323: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1323/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0284 - loss: 8.4715 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1324: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1324/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0360 - loss: 8.3325 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1325: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1325/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.1823 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1326: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1326/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0340 - loss: 8.3836 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1327: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1327/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0366 - loss: 8.3959 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1328: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1328/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.3576 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1329: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1329/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 8.1405 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1330: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1330/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 8.3754 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1331: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1331/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.0183 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1332: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1332/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 8.0801 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1333: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1333/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 7.9625 - val_accuracy: 0.0833 - val_loss: 11.6523 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1334: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1334/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0348 - loss: 8.1495 - val_accuracy: 0.0833 - val_loss: 11.6522 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1335: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1335/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0324 - loss: 8.2309 - val_accuracy: 0.0833 - val_loss: 11.6522 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1336: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1336/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0313 - loss: 8.4758 - val_accuracy: 0.0833 - val_loss: 11.6521 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1337: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1337/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0279 - loss: 8.2646 - val_accuracy: 0.0833 - val_loss: 11.6521 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1338: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1338/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.0242 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1339: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1339/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0337 - loss: 8.2897 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1340: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1340/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.1219 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1341: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1341/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0297 - loss: 8.1546 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1342: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1342/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0304 - loss: 8.0857 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1343: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1343/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.1649 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1344: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1344/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0281 - loss: 8.4177 - val_accuracy: 0.0833 - val_loss: 11.6520 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1345: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1345/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0294 - loss: 8.1417 - val_accuracy: 0.0833 - val_loss: 11.6519 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1346: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1346/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0350 - loss: 8.1312 - val_accuracy: 0.0833 - val_loss: 11.6519 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1347: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1347/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.0536 - val_accuracy: 0.0833 - val_loss: 11.6519 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1348: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1348/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0325 - loss: 8.5131 - val_accuracy: 0.0833 - val_loss: 11.6519 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1349: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1349/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0310 - loss: 8.2774 - val_accuracy: 0.0833 - val_loss: 11.6518 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1350: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1350/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.3529 - val_accuracy: 0.0833 - val_loss: 11.6518 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1351: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1351/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.5109 - val_accuracy: 0.0833 - val_loss: 11.6518 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1352: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1352/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.3112 - val_accuracy: 0.0833 - val_loss: 11.6517 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1353: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1353/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.3158 - val_accuracy: 0.0833 - val_loss: 11.6517 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1354: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1354/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0270 - loss: 8.1717 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1355: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1355/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0334 - loss: 8.0383 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1356: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1356/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0299 - loss: 8.5251 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1357: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1357/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.5325 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1358: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1358/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0310 - loss: 8.4819 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1359: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1359/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0359 - loss: 8.2980 - val_accuracy: 0.0833 - val_loss: 11.6516 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1360: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1360/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 7.9312 - val_accuracy: 0.0833 - val_loss: 11.6515 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1361: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1361/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0355 - loss: 8.2163 - val_accuracy: 0.0833 - val_loss: 11.6515 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1362: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1362/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0328 - loss: 8.3170 - val_accuracy: 0.0833 - val_loss: 11.6515 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1363: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1363/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0342 - loss: 7.9363 - val_accuracy: 0.0833 - val_loss: 11.6514 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1364: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1364/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0298 - loss: 8.0626 - val_accuracy: 0.0833 - val_loss: 11.6514 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1365: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1365/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.0943 - val_accuracy: 0.0833 - val_loss: 11.6513 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1366: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1366/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0333 - loss: 8.0760 - val_accuracy: 0.0833 - val_loss: 11.6513 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1367: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1367/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0360 - loss: 8.0078 - val_accuracy: 0.0833 - val_loss: 11.6512 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1368: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1368/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0337 - loss: 8.2821 - val_accuracy: 0.0833 - val_loss: 11.6512 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1369: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1369/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0251 - loss: 8.1527 - val_accuracy: 0.0833 - val_loss: 11.6511 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1370: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1370/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.1154 - val_accuracy: 0.0833 - val_loss: 11.6511 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1371: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1371/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0278 - loss: 8.3323 - val_accuracy: 0.0833 - val_loss: 11.6511 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1372: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1372/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0329 - loss: 8.2078 - val_accuracy: 0.0833 - val_loss: 11.6510 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1373: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1373/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.0529 - val_accuracy: 0.0833 - val_loss: 11.6510 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1374: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1374/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.4381 - val_accuracy: 0.0833 - val_loss: 11.6510 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1375: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1375/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0313 - loss: 7.9579 - val_accuracy: 0.0833 - val_loss: 11.6509 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1376: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1376/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0297 - loss: 8.2455 - val_accuracy: 0.0833 - val_loss: 11.6509 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1377: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1377/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.2388 - val_accuracy: 0.0833 - val_loss: 11.6509 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1378: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1378/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0301 - loss: 8.1344 - val_accuracy: 0.0833 - val_loss: 11.6509 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1379: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1379/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.1847 - val_accuracy: 0.0833 - val_loss: 11.6508 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1380: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1380/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0333 - loss: 7.9538 - val_accuracy: 0.0833 - val_loss: 11.6508 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1381: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1381/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.2519 - val_accuracy: 0.0833 - val_loss: 11.6508 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1382: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1382/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0308 - loss: 8.1187 - val_accuracy: 0.0833 - val_loss: 11.6507 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1383: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1383/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0301 - loss: 7.9667 - val_accuracy: 0.0833 - val_loss: 11.6507 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1384: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1384/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0301 - loss: 8.3715 - val_accuracy: 0.0833 - val_loss: 11.6507 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1385: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1385/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0350 - loss: 8.4599 - val_accuracy: 0.0833 - val_loss: 11.6506 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1386: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1386/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0301 - loss: 8.4405 - val_accuracy: 0.0833 - val_loss: 11.6505 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1387: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1387/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0324 - loss: 8.1992 - val_accuracy: 0.0833 - val_loss: 11.6505 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1388: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1388/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0305 - loss: 8.0510 - val_accuracy: 0.0833 - val_loss: 11.6505 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1389: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1389/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0284 - loss: 8.0305 - val_accuracy: 0.0833 - val_loss: 11.6504 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1390: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1390/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.5083 - val_accuracy: 0.0833 - val_loss: 11.6505 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1391: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1391/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0295 - loss: 8.2193 - val_accuracy: 0.0833 - val_loss: 11.6504 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1392: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1392/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0296 - loss: 8.3320 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1393: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1393/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0294 - loss: 8.4453 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1394: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1394/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0308 - loss: 8.8290 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1395: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1395/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0272 - loss: 8.1922 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1396: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1396/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.2199 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1397: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1397/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0353 - loss: 8.2854 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1398: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1398/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.3258 - val_accuracy: 0.0833 - val_loss: 11.6504 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1399: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1399/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 8.3919 - val_accuracy: 0.0833 - val_loss: 11.6504 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1400: LearningRateScheduler setting learning rate to 6.249999984220267e-08.\n",
            "Epoch 1400/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0293 - loss: 8.5089 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 6.2500e-08\n",
            "\n",
            "Epoch 1401: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1401/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0283 - loss: 8.7196 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1402: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1402/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0346 - loss: 8.3648 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1403: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1403/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0323 - loss: 8.3671 - val_accuracy: 0.0833 - val_loss: 11.6503 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1404: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1404/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0320 - loss: 8.1786 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1405: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1405/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.2307 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1406: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1406/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0360 - loss: 8.0626 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1407: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1407/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0309 - loss: 8.0656 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1408: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1408/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0289 - loss: 8.1227 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1409: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1409/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.2418 - val_accuracy: 0.0833 - val_loss: 11.6502 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1410: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1410/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0345 - loss: 8.3047 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1411: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1411/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.2432 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1412: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1412/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.2809 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1413: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1413/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.4736 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1414: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1414/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0329 - loss: 8.3542 - val_accuracy: 0.0833 - val_loss: 11.6501 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1415: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1415/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0312 - loss: 8.0494 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1416: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1416/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.1755 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1417: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1417/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0335 - loss: 8.5172 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1418: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1418/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0288 - loss: 8.2999 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1419: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1419/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0319 - loss: 8.2334 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1420: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1420/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0359 - loss: 8.2102 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1421: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1421/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0287 - loss: 8.0352 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1422: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1422/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0279 - loss: 8.2172 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1423: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1423/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0292 - loss: 8.3046 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1424: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1424/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0285 - loss: 8.3881 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1425: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1425/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.2939 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1426: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1426/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.2168 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1427: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1427/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0353 - loss: 8.3612 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1428: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1428/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0346 - loss: 8.0143 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1429: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1429/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0350 - loss: 8.2141 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1430: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1430/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.1718 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1431: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1431/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0340 - loss: 8.2117 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1432: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1432/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0276 - loss: 8.2842 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1433: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1433/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0284 - loss: 8.2539 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1434: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1434/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0296 - loss: 8.0564 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1435: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1435/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.1367 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1436: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1436/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0339 - loss: 8.2710 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1437: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1437/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0295 - loss: 8.4167 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1438: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1438/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.2885 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1439: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1439/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0345 - loss: 8.1260 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1440: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1440/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0316 - loss: 8.0538 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1441: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1441/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0357 - loss: 8.4495 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1442: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1442/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0353 - loss: 8.2692 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1443: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1443/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0319 - loss: 8.2829 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1444: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1444/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0328 - loss: 7.9099 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1445: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1445/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.3241 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1446: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1446/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0328 - loss: 8.0954 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1447: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1447/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.5454 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1448: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1448/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0328 - loss: 8.1198 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1449: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1449/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.1619 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1450: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1450/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0320 - loss: 8.2561 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1451: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1451/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0303 - loss: 8.1931 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1452: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1452/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0331 - loss: 8.2941 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1453: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1453/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0341 - loss: 8.2004 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1454: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1454/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0341 - loss: 8.1117 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1455: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1455/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0311 - loss: 8.4115 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1456: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1456/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0381 - loss: 8.1650 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1457: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1457/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0323 - loss: 8.1919 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1458: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1458/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0278 - loss: 8.3849 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1459: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1459/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0302 - loss: 8.2498 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1460: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1460/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.1685 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1461: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1461/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0294 - loss: 8.4119 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1462: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1462/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0306 - loss: 8.1598 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1463: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1463/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0307 - loss: 8.4950 - val_accuracy: 0.0833 - val_loss: 11.6500 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1464: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1464/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.1239 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1465: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1465/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0329 - loss: 8.2642 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1466: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1466/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0358 - loss: 8.2332 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1467: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1467/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.1413 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1468: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1468/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0334 - loss: 8.0473 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1469: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1469/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 8.1977 - val_accuracy: 0.0833 - val_loss: 11.6499 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1470: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1470/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.4346 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1471: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1471/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 8.0572 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1472: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1472/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0371 - loss: 8.1922 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1473: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1473/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.3739 - val_accuracy: 0.0833 - val_loss: 11.6498 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1474: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1474/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.2357 - val_accuracy: 0.0833 - val_loss: 11.6497 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1475: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1475/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0278 - loss: 8.2537 - val_accuracy: 0.0833 - val_loss: 11.6497 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1476: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1476/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.2515 - val_accuracy: 0.0833 - val_loss: 11.6497 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1477: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1477/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.2646 - val_accuracy: 0.0833 - val_loss: 11.6497 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1478: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1478/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0318 - loss: 8.3909 - val_accuracy: 0.0833 - val_loss: 11.6497 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1479: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1479/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0333 - loss: 8.2374 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1480: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1480/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.0757 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1481: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1481/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0294 - loss: 8.5867 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1482: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1482/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.2199 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1483: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1483/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0319 - loss: 8.1373 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1484: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1484/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0346 - loss: 8.1633 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1485: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1485/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0299 - loss: 8.1764 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1486: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1486/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0291 - loss: 8.2868 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1487: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1487/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0279 - loss: 8.1954 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1488: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1488/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.3230 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1489: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1489/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0305 - loss: 8.3168 - val_accuracy: 0.0833 - val_loss: 11.6496 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1490: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1490/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.4052 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1491: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1491/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.2529 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1492: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1492/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0323 - loss: 8.2780 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1493: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1493/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0324 - loss: 7.9347 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1494: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1494/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0366 - loss: 8.2325 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1495: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1495/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0343 - loss: 8.0845 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1496: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1496/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0361 - loss: 8.1928 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1497: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1497/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0295 - loss: 8.4289 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1498: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1498/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.5853 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1499: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1499/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0321 - loss: 8.1444 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1500: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1500/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0324 - loss: 8.2762 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1501: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1501/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0337 - loss: 8.2743 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1502: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1502/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.4347 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1503: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1503/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0305 - loss: 8.3514 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1504: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1504/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0363 - loss: 8.0918 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1505: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1505/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0298 - loss: 8.3390 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1506: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1506/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0333 - loss: 8.1171 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1507: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1507/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0293 - loss: 8.2717 - val_accuracy: 0.0833 - val_loss: 11.6495 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1508: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1508/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0340 - loss: 8.4242 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1509: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1509/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0324 - loss: 8.0597 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1510: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1510/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 8.1411 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1511: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1511/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.2770 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1512: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1512/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0356 - loss: 8.3175 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1513: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1513/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0273 - loss: 8.4296 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1514: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1514/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.0728 - val_accuracy: 0.0833 - val_loss: 11.6494 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1515: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1515/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.1156 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1516: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1516/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.1407 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1517: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1517/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.4402 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1518: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1518/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0292 - loss: 8.1456 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1519: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1519/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0350 - loss: 8.3690 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1520: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1520/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0303 - loss: 8.1596 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1521: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1521/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0299 - loss: 8.2352 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1522: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1522/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 7.9392 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1523: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1523/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0283 - loss: 8.4333 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1524: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1524/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 8.2522 - val_accuracy: 0.0833 - val_loss: 11.6493 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1525: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1525/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0337 - loss: 8.3226 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1526: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1526/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0343 - loss: 8.1373 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1527: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1527/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0323 - loss: 8.0115 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1528: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1528/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0316 - loss: 8.0033 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1529: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1529/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 7.9627 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1530: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1530/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0302 - loss: 8.4000 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1531: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1531/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0313 - loss: 8.4117 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1532: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1532/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0333 - loss: 8.3046 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1533: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1533/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0287 - loss: 8.2899 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1534: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1534/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.0937 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1535: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1535/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.1789 - val_accuracy: 0.0833 - val_loss: 11.6492 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1536: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1536/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0266 - loss: 8.2092 - val_accuracy: 0.0833 - val_loss: 11.6491 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1537: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1537/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0382 - loss: 8.3072 - val_accuracy: 0.0833 - val_loss: 11.6491 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1538: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1538/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.0512 - val_accuracy: 0.0833 - val_loss: 11.6491 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1539: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1539/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0270 - loss: 8.2837 - val_accuracy: 0.0833 - val_loss: 11.6491 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1540: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1540/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.3230 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1541: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1541/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0363 - loss: 8.2753 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1542: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1542/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0321 - loss: 8.0814 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1543: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1543/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0324 - loss: 8.2481 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1544: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1544/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0328 - loss: 8.0276 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1545: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1545/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 8.4830 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1546: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1546/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0372 - loss: 8.1658 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1547: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1547/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0296 - loss: 8.2619 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1548: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1548/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0307 - loss: 8.3497 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1549: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1549/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0328 - loss: 8.4272 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1550: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1550/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0335 - loss: 8.3819 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1551: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1551/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0329 - loss: 8.1702 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1552: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1552/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0279 - loss: 8.3439 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1553: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1553/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.4427 - val_accuracy: 0.0833 - val_loss: 11.6490 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1554: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1554/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.2324 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1555: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1555/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 8.0009 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1556: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1556/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0287 - loss: 8.1966 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1557: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1557/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.2141 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1558: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1558/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 8.2001 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1559: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1559/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.2436 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1560: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1560/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0349 - loss: 7.9773 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1561: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1561/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.2378 - val_accuracy: 0.0833 - val_loss: 11.6489 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1562: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1562/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.1710 - val_accuracy: 0.0833 - val_loss: 11.6488 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1563: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1563/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0293 - loss: 7.8126 - val_accuracy: 0.0833 - val_loss: 11.6488 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1564: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1564/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.1433 - val_accuracy: 0.0833 - val_loss: 11.6488 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1565: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1565/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.2356 - val_accuracy: 0.0833 - val_loss: 11.6488 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1566: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1566/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0296 - loss: 8.0792 - val_accuracy: 0.0833 - val_loss: 11.6487 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1567: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1567/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 8.3005 - val_accuracy: 0.0833 - val_loss: 11.6487 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1568: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1568/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0373 - loss: 8.4242 - val_accuracy: 0.0833 - val_loss: 11.6487 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1569: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1569/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0351 - loss: 8.1369 - val_accuracy: 0.0833 - val_loss: 11.6487 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1570: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1570/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0351 - loss: 8.2490 - val_accuracy: 0.0833 - val_loss: 11.6487 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1571: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1571/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0350 - loss: 8.1645 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1572: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1572/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0338 - loss: 8.1303 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1573: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1573/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.2019 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1574: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1574/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0322 - loss: 8.2826 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1575: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1575/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0269 - loss: 8.2353 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1576: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1576/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0305 - loss: 8.2961 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1577: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1577/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 8.0576 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1578: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1578/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.1138 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1579: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1579/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.2790 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1580: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1580/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0421 - loss: 8.0745 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1581: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1581/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0314 - loss: 8.3293 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1582: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1582/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0338 - loss: 8.0195 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1583: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1583/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0289 - loss: 8.3501 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1584: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1584/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.1971 - val_accuracy: 0.0833 - val_loss: 11.6486 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1585: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1585/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0374 - loss: 8.0960 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1586: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1586/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0297 - loss: 8.4284 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1587: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1587/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0370 - loss: 8.1907 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1588: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1588/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0342 - loss: 8.1573 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1589: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1589/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0285 - loss: 8.1303 - val_accuracy: 0.0833 - val_loss: 11.6485 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1590: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1590/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0265 - loss: 8.3243 - val_accuracy: 0.0833 - val_loss: 11.6484 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1591: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1591/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.2577 - val_accuracy: 0.0833 - val_loss: 11.6484 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1592: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1592/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.4017 - val_accuracy: 0.0833 - val_loss: 11.6484 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1593: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1593/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.3623 - val_accuracy: 0.0833 - val_loss: 11.6484 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1594: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1594/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0267 - loss: 8.4039 - val_accuracy: 0.0833 - val_loss: 11.6484 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1595: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1595/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0319 - loss: 8.0992 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1596: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1596/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0328 - loss: 8.0837 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1597: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1597/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.2300 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1598: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1598/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.1517 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1599: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1599/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0320 - loss: 8.1856 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1600: LearningRateScheduler setting learning rate to 3.1249999921101335e-08.\n",
            "Epoch 1600/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0248 - loss: 8.3490 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 3.1250e-08\n",
            "\n",
            "Epoch 1601: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1601/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 8.0069 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1602: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1602/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 8.3946 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1603: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1603/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.2274 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1604: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1604/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0333 - loss: 7.9817 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1605: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1605/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0331 - loss: 8.4511 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1606: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1606/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0314 - loss: 8.3161 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1607: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1607/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0329 - loss: 8.3580 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1608: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1608/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0322 - loss: 8.0341 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1609: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1609/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0300 - loss: 8.2241 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1610: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1610/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0334 - loss: 8.0801 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1611: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1611/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0342 - loss: 8.3545 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1612: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1612/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0298 - loss: 8.3278 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1613: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1613/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0320 - loss: 8.2213 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1614: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1614/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0337 - loss: 8.0275 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1615: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1615/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 8.3180 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1616: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1616/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.3332 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1617: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1617/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.1196 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1618: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1618/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0333 - loss: 8.4882 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1619: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1619/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0319 - loss: 8.3095 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1620: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1620/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0325 - loss: 8.4427 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1621: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1621/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0304 - loss: 8.4825 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1622: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1622/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0274 - loss: 8.4607 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1623: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1623/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 8.2539 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1624: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1624/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0280 - loss: 8.3364 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1625: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1625/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.3497 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1626: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1626/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0345 - loss: 8.2141 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1627: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1627/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0301 - loss: 8.1443 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1628: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1628/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 8.3910 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1629: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1629/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.1979 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1630: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1630/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.3113 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1631: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1631/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0245 - loss: 8.3062 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1632: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1632/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0323 - loss: 8.2134 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1633: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1633/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0282 - loss: 8.5994 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1634: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1634/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0348 - loss: 8.1284 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1635: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1635/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0346 - loss: 8.2511 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1636: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1636/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 7.9968 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1637: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1637/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.1484 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1638: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1638/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0323 - loss: 8.2461 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1639: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1639/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 8.6694 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1640: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1640/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.3423 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1641: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1641/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.0786 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1642: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1642/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.3536 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1643: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1643/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.1205 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1644: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1644/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0341 - loss: 8.2406 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1645: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1645/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0373 - loss: 8.3200 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1646: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1646/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 8.4105 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1647: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1647/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0344 - loss: 8.2342 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1648: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1648/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0286 - loss: 8.2067 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1649: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1649/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0342 - loss: 8.1610 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1650: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1650/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.3004 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1651: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1651/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.4603 - val_accuracy: 0.0833 - val_loss: 11.6483 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1652: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1652/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0365 - loss: 8.0649 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1653: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1653/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0271 - loss: 8.2754 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1654: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1654/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.0805 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1655: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1655/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 8.1983 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1656: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1656/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0334 - loss: 8.3991 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1657: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1657/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.2676 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1658: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1658/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 8.4552 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1659: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1659/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0345 - loss: 8.1879 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1660: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1660/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.1669 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1661: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1661/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 8.1666 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1662: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1662/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.4216 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1663: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1663/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0318 - loss: 8.2391 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1664: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1664/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0276 - loss: 8.0511 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1665: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1665/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0355 - loss: 8.3325 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1666: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1666/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.2224 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1667: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1667/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0288 - loss: 8.1649 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1668: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1668/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.1278 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1669: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1669/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0273 - loss: 8.3772 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1670: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1670/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0319 - loss: 8.1699 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1671: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1671/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0323 - loss: 8.2703 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1672: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1672/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.1459 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1673: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1673/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0292 - loss: 8.0690 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1674: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1674/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0296 - loss: 8.4312 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1675: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1675/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0312 - loss: 8.1746 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1676: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1676/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0323 - loss: 8.3140 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1677: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1677/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0300 - loss: 8.1226 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1678: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1678/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0352 - loss: 8.1979 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1679: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1679/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.1478 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1680: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1680/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0339 - loss: 8.2049 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1681: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1681/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0306 - loss: 8.3509 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1682: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1682/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.2304 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1683: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1683/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0272 - loss: 8.3857 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1684: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1684/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0262 - loss: 8.1631 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1685: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1685/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0327 - loss: 8.5131 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1686: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1686/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.3833 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1687: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1687/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 8.1213 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1688: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1688/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.4551 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1689: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1689/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.1077 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1690: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1690/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0320 - loss: 8.2444 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1691: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1691/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0295 - loss: 8.1249 - val_accuracy: 0.0833 - val_loss: 11.6482 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1692: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1692/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0321 - loss: 8.3990 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1693: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1693/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0276 - loss: 8.1278 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1694: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1694/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0346 - loss: 8.3034 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1695: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1695/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.2320 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1696: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1696/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0291 - loss: 8.4090 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1697: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1697/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0303 - loss: 8.2738 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1698: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1698/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 8.1750 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1699: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1699/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0300 - loss: 8.0073 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1700: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1700/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.2784 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1701: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1701/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0313 - loss: 8.3308 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1702: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1702/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0317 - loss: 8.1396 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1703: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1703/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0317 - loss: 8.1686 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1704: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1704/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0294 - loss: 8.1643 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1705: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1705/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0306 - loss: 8.0766 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1706: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1706/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0270 - loss: 8.5635 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1707: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1707/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.0678 - val_accuracy: 0.0833 - val_loss: 11.6481 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1708: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1708/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0317 - loss: 8.2629 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1709: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1709/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 8.1735 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1710: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1710/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0352 - loss: 8.1266 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1711: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1711/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0346 - loss: 8.3394 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1712: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1712/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0351 - loss: 8.3430 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1713: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1713/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0294 - loss: 8.0905 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1714: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1714/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0301 - loss: 8.5279 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1715: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1715/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 8.0381 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1716: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1716/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0355 - loss: 8.1772 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1717: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1717/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0305 - loss: 8.2852 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1718: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1718/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.3707 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1719: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1719/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.1942 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1720: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1720/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.1715 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1721: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1721/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.1418 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1722: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1722/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0360 - loss: 8.3947 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1723: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1723/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.4940 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1724: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1724/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0346 - loss: 8.0036 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1725: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1725/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0294 - loss: 8.1420 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1726: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1726/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0325 - loss: 8.0514 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1727: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1727/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0289 - loss: 8.2650 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1728: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1728/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0296 - loss: 8.2122 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1729: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1729/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.4967 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1730: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1730/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0360 - loss: 8.0944 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1731: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1731/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0292 - loss: 8.1813 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1732: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1732/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0366 - loss: 8.4254 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1733: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1733/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.5044 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1734: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1734/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0353 - loss: 8.2461 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1735: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1735/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0272 - loss: 8.1587 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1736: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1736/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0352 - loss: 8.3740 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1737: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1737/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0306 - loss: 8.1808 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1738: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1738/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0333 - loss: 8.1738 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1739: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1739/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0345 - loss: 7.9783 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1740: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1740/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0278 - loss: 8.2785 - val_accuracy: 0.0833 - val_loss: 11.6480 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1741: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1741/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0333 - loss: 8.2908 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1742: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1742/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0365 - loss: 8.0724 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1743: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1743/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0335 - loss: 8.5649 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1744: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1744/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.5486 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1745: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1745/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0271 - loss: 8.5432 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1746: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1746/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0279 - loss: 8.1804 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1747: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1747/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0322 - loss: 8.1869 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1748: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1748/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0282 - loss: 8.6471 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1749: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1749/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0332 - loss: 8.0429 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1750: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1750/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0314 - loss: 8.1535 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1751: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1751/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0316 - loss: 8.2445 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1752: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1752/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0323 - loss: 8.1014 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1753: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1753/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0320 - loss: 8.0819 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1754: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1754/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 8.3145 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1755: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1755/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0352 - loss: 8.3797 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1756: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1756/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.3172 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1757: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1757/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0310 - loss: 8.1173 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1758: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1758/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0318 - loss: 8.2086 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1759: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1759/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0366 - loss: 8.2546 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1760: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1760/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.0932 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1761: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1761/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0323 - loss: 8.2616 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1762: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1762/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0343 - loss: 8.2544 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1763: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1763/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0305 - loss: 8.3009 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1764: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1764/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0289 - loss: 8.1464 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1765: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1765/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0314 - loss: 8.2319 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1766: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1766/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0314 - loss: 8.4316 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1767: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1767/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.2705 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1768: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1768/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0340 - loss: 8.1564 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1769: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1769/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.1708 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1770: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1770/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 8.3848 - val_accuracy: 0.0833 - val_loss: 11.6479 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1771: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1771/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0294 - loss: 8.0492 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1772: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1772/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.0312 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1773: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1773/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0323 - loss: 8.0848 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1774: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1774/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0308 - loss: 8.1921 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1775: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1775/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0343 - loss: 8.3922 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1776: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1776/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.1894 - val_accuracy: 0.0833 - val_loss: 11.6478 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1777: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1777/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0318 - loss: 8.2118 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1778: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1778/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 8.1751 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1779: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1779/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0328 - loss: 8.1528 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1780: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1780/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0316 - loss: 8.4444 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1781: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1781/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.0430 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1782: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1782/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0301 - loss: 8.1687 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1783: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1783/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0349 - loss: 8.2004 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1784: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1784/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0320 - loss: 8.2328 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1785: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1785/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0345 - loss: 8.0581 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1786: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1786/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.2108 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1787: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1787/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.3039 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1788: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1788/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0351 - loss: 8.1060 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1789: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1789/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0264 - loss: 8.2819 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1790: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1790/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0344 - loss: 7.9738 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1791: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1791/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0310 - loss: 8.1305 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1792: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1792/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.3678 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1793: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1793/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0322 - loss: 8.2661 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1794: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1794/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0276 - loss: 8.3765 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1795: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1795/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0331 - loss: 8.4042 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1796: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1796/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0255 - loss: 8.1403 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1797: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1797/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0308 - loss: 8.5075 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1798: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1798/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0307 - loss: 8.1791 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1799: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1799/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0289 - loss: 8.3571 - val_accuracy: 0.0833 - val_loss: 11.6477 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1800: LearningRateScheduler setting learning rate to 1.5624999960550667e-08.\n",
            "Epoch 1800/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0310 - loss: 8.4348 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 1.5625e-08\n",
            "\n",
            "Epoch 1801: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1801/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0327 - loss: 8.2332 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1802: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1802/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0320 - loss: 8.1317 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1803: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1803/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0313 - loss: 8.3525 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1804: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1804/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0271 - loss: 8.6390 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1805: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1805/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0274 - loss: 8.5436 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1806: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1806/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.4549 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1807: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1807/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0361 - loss: 7.8408 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1808: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1808/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0282 - loss: 8.4707 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1809: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1809/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.2120 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1810: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1810/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0283 - loss: 8.1571 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1811: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1811/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0290 - loss: 8.2556 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1812: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1812/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0346 - loss: 7.9850 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1813: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1813/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0299 - loss: 8.2655 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1814: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1814/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0307 - loss: 8.2859 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1815: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1815/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0303 - loss: 8.1767 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1816: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1816/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0289 - loss: 8.2345 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1817: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1817/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0281 - loss: 8.1794 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1818: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1818/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0337 - loss: 8.1717 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1819: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1819/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0305 - loss: 8.2202 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1820: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1820/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0327 - loss: 8.3065 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1821: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1821/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0322 - loss: 8.3172 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1822: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1822/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.3796 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1823: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1823/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0301 - loss: 8.3749 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1824: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1824/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0350 - loss: 8.0149 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1825: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1825/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0294 - loss: 8.3211 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1826: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1826/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0324 - loss: 8.5777 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1827: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1827/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0337 - loss: 8.2452 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1828: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1828/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0296 - loss: 8.3897 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1829: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1829/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0377 - loss: 8.4531 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1830: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1830/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0323 - loss: 8.7671 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1831: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1831/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0354 - loss: 8.2260 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1832: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1832/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.3526 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1833: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1833/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0326 - loss: 8.5493 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1834: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1834/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0299 - loss: 8.3008 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1835: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1835/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0290 - loss: 8.2125 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1836: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1836/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0328 - loss: 8.4565 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1837: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1837/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0317 - loss: 8.1886 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1838: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1838/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0300 - loss: 8.3210 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1839: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1839/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.2782 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1840: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1840/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0295 - loss: 8.2321 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1841: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1841/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0265 - loss: 8.1002 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1842: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1842/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0369 - loss: 8.0669 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1843: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1843/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0354 - loss: 8.2282 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1844: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1844/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0309 - loss: 8.2867 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1845: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1845/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0327 - loss: 8.2147 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1846: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1846/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 8.2518 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1847: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1847/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0365 - loss: 7.8756 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1848: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1848/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0302 - loss: 8.0938 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1849: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1849/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0315 - loss: 8.2428 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1850: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1850/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 8.0693 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1851: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1851/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0330 - loss: 7.9091 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1852: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1852/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.2591 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1853: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1853/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.4570 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1854: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1854/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.2681 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1855: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1855/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0311 - loss: 8.3303 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1856: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1856/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0304 - loss: 8.2901 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1857: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1857/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0266 - loss: 8.0838 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1858: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1858/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 8.2966 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1859: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1859/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.1019 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1860: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1860/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0266 - loss: 8.5045 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1861: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1861/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0343 - loss: 8.2873 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1862: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1862/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0324 - loss: 8.1781 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1863: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1863/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0332 - loss: 8.2235 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1864: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1864/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0327 - loss: 8.2193 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1865: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1865/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.2343 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1866: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1866/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.3196 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1867: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1867/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.3972 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1868: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1868/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0319 - loss: 8.2755 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1869: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1869/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.0715 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1870: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1870/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.3733 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1871: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1871/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.1046 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1872: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1872/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0314 - loss: 8.2644 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1873: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1873/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0314 - loss: 8.3344 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1874: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1874/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0392 - loss: 8.0634 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1875: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1875/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0285 - loss: 8.2937 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1876: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1876/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 8.4466 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1877: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1877/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0350 - loss: 8.0813 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1878: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1878/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0350 - loss: 8.2971 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1879: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1879/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.0860 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1880: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1880/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.2007 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1881: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1881/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0344 - loss: 8.0849 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1882: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1882/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0297 - loss: 8.4170 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1883: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1883/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0317 - loss: 8.2438 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1884: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1884/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0336 - loss: 7.8913 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1885: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1885/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0320 - loss: 8.4234 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1886: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1886/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.4445 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1887: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1887/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0310 - loss: 8.2663 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1888: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1888/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 8.3406 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1889: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1889/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0291 - loss: 8.3212 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1890: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1890/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0281 - loss: 8.1665 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1891: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1891/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0329 - loss: 8.3196 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1892: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1892/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0325 - loss: 8.2541 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1893: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1893/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.2756 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1894: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1894/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.0424 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1895: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1895/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.2720 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1896: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1896/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0324 - loss: 8.0645 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1897: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1897/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0289 - loss: 8.4606 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1898: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1898/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0388 - loss: 8.1743 - val_accuracy: 0.0833 - val_loss: 11.6476 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1899: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1899/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0259 - loss: 8.2771 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1900: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1900/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0332 - loss: 8.3784 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1901: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1901/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0370 - loss: 8.1416 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1902: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1902/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0311 - loss: 7.9824 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1903: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1903/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0348 - loss: 8.0353 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1904: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1904/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0292 - loss: 8.6823 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1905: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1905/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0344 - loss: 8.1969 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1906: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1906/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0291 - loss: 8.3403 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1907: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1907/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0344 - loss: 8.2030 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1908: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1908/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0361 - loss: 7.8923 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1909: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1909/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0272 - loss: 8.1496 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1910: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1910/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 8.0127 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1911: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1911/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0332 - loss: 8.1017 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1912: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1912/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0325 - loss: 8.1427 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1913: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1913/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0298 - loss: 8.2424 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1914: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1914/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0289 - loss: 8.1994 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1915: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1915/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0365 - loss: 8.2098 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1916: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1916/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0334 - loss: 7.9368 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1917: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1917/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0343 - loss: 8.2888 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1918: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1918/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0300 - loss: 8.2828 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1919: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1919/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 8.0112 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1920: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1920/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 8.1738 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1921: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1921/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0347 - loss: 8.3278 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1922: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1922/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 8.0076 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1923: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1923/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0350 - loss: 8.2325 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1924: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1924/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0345 - loss: 8.1218 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1925: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1925/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0359 - loss: 8.0497 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1926: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1926/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0306 - loss: 8.1980 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1927: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1927/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0318 - loss: 8.5287 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1928: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1928/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 8.2526 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1929: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1929/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0295 - loss: 8.0734 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1930: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1930/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0340 - loss: 8.2673 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1931: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1931/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0328 - loss: 8.3225 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1932: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1932/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0287 - loss: 8.2934 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1933: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1933/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0322 - loss: 8.2418 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1934: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1934/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0302 - loss: 8.1706 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1935: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1935/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.0544 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1936: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1936/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0331 - loss: 7.8774 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1937: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1937/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0344 - loss: 8.1584 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1938: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1938/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0355 - loss: 8.3915 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1939: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1939/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0300 - loss: 8.2943 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1940: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1940/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0296 - loss: 8.2590 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1941: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1941/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0337 - loss: 8.3230 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1942: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1942/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0313 - loss: 8.2126 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1943: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1943/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0317 - loss: 8.4276 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1944: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1944/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0274 - loss: 8.4298 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1945: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1945/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0275 - loss: 8.1734 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1946: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1946/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0354 - loss: 7.9251 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1947: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1947/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0314 - loss: 8.3057 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1948: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1948/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0309 - loss: 8.1198 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1949: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1949/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0330 - loss: 8.2368 - val_accuracy: 0.0833 - val_loss: 11.6475 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1950: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1950/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0309 - loss: 7.9669 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1951: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1951/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0341 - loss: 8.3866 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1952: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1952/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0294 - loss: 8.3105 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1953: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1953/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0336 - loss: 7.9669 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1954: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1954/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0272 - loss: 8.2522 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1955: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1955/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0318 - loss: 7.9604 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1956: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1956/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0284 - loss: 8.1160 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1957: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1957/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0345 - loss: 8.0979 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1958: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1958/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0347 - loss: 8.1222 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1959: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1959/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.4036 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1960: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1960/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0306 - loss: 8.2915 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1961: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1961/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0270 - loss: 8.3042 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1962: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1962/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0295 - loss: 8.2483 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1963: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1963/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0325 - loss: 8.2929 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1964: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1964/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0256 - loss: 8.3812 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1965: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1965/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0311 - loss: 8.1831 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1966: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1966/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0374 - loss: 8.0880 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1967: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1967/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0271 - loss: 8.1381 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1968: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1968/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0320 - loss: 8.3825 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1969: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1969/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0317 - loss: 8.4987 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1970: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1970/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0296 - loss: 8.1327 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1971: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1971/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0331 - loss: 7.8910 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1972: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1972/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0345 - loss: 8.3241 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1973: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1973/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0302 - loss: 8.1593 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1974: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1974/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0310 - loss: 8.0316 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1975: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1975/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.1143 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1976: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1976/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0342 - loss: 8.3911 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1977: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1977/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0284 - loss: 8.3837 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1978: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1978/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0327 - loss: 8.3824 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1979: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1979/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0364 - loss: 8.1797 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1980: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1980/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0309 - loss: 8.2569 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1981: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1981/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0290 - loss: 8.3323 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1982: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1982/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0316 - loss: 8.3820 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1983: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1983/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0322 - loss: 8.1898 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1984: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1984/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0308 - loss: 8.1313 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1985: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1985/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0356 - loss: 8.1531 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1986: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1986/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0369 - loss: 8.1375 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1987: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1987/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0270 - loss: 8.1613 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1988: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1988/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0281 - loss: 8.1444 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1989: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1989/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0343 - loss: 8.2337 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1990: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1990/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0281 - loss: 8.4126 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1991: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1991/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0303 - loss: 8.2353 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1992: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1992/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0315 - loss: 8.3380 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1993: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1993/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0357 - loss: 8.0570 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1994: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1994/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0349 - loss: 8.2797 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1995: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1995/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0306 - loss: 8.1878 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1996: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1996/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0293 - loss: 8.4917 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1997: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1997/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 8.2939 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1998: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1998/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0320 - loss: 8.2321 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 1999: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 1999/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0311 - loss: 8.4497 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n",
            "\n",
            "Epoch 2000: LearningRateScheduler setting learning rate to 7.812499980275334e-09.\n",
            "Epoch 2000/2000\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0357 - loss: 8.2161 - val_accuracy: 0.0833 - val_loss: 11.6474 - learning_rate: 7.8125e-09\n"
          ]
        }
      ],
      "source": [
        "# Now, let's use this prepared data in our Transformer model\n",
        "# Assuming the TransformerModel is defined as in the previous code snippet\n",
        "\n",
        "# Hyperparameters\n",
        "num_layers = 10\n",
        "d_model = 64\n",
        "dff = 128\n",
        "num_heads = 8\n",
        "input_vocab_size = 10000  # Adjusted based on the tokenizer\n",
        "maximum_position_encoding = 10000\n",
        "\n",
        "# Instantiate the Transformer model\n",
        "transformer = TransformerModel(num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding)\n",
        "\n",
        "# Define a function for step decay\n",
        "def step_decay(epoch, lr):\n",
        "    \"\"\"\n",
        "    Reduces the learning rate by a factor every `decay_step` epochs.\n",
        "\n",
        "    Args:\n",
        "        epoch (int): The current epoch number.\n",
        "        lr (float): The current learning rate.\n",
        "\n",
        "    Returns:\n",
        "        float: The updated learning rate.\n",
        "    \"\"\"\n",
        "    decay_rate = 0.7  # Decay rate to reduce learning rate\n",
        "    decay_step = 200  # Number of epochs after which to apply decay\n",
        "\n",
        "    if epoch % decay_step == 0 and epoch != 0:\n",
        "        return lr * decay_rate\n",
        "    return lr\n",
        "\n",
        "# Compile the model with the initial learning rate\n",
        "initial_learning_rate = 0.001\n",
        "transformer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler callback to reduce learning rate every 200 steps\n",
        "lr_scheduler = LearningRateScheduler(step_decay, verbose=1)\n",
        "\n",
        "# Reduce learning rate when a metric has stopped improving\n",
        "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
        "    monitor='val_loss',       # Monitored metric (validation loss)\n",
        "    factor=0.98,               # Factor by which to reduce the learning rate\n",
        "    patience=10,              # Number of epochs with no improvement after which to reduce learning rate\n",
        "    verbose=1,                # Verbosity mode\n",
        "    min_lr=1e-6               # Lower bound on the learning rate\n",
        ")\n",
        "\n",
        "# Fit the model on the tokenized and padded sample data\n",
        "if \"GPU\" in device_name:\n",
        "    print(\"GPU is present.\")\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        transformer.fit(sample_data, sample_data, epochs=2000, validation_split=0.05, callbacks=[lr_scheduler, reduce_lr_on_plateau])\n",
        "else:\n",
        "    print(\"GPU is not present.\")\n",
        "    transformer.fit(sample_data, sample_data, epochs=2, validation_split=0.05, callbacks=[lr_scheduler, reduce_lr_on_plateau])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-0RWM4iNDqvw",
        "outputId": "6763ac97-d5e8-4830-b1d4-01ccb3b25aeb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(transformer.history.history['loss'])\n",
        "plt.plot(transformer.history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otRfGC4pcEvp"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6oiMXaTbdUw"
      },
      "source": [
        "The `predict_text` function generates a text prediction using a trained Transformer model. It takes an input string, tokenizes it, and pads the sequence to a specified maximum length to match the model's input size. The function then uses the Transformer model to predict the output based on the padded sequence. The predicted output is converted back to text by identifying the highest probability token indices and mapping them back to words using the tokenizer. Finally, the function returns the predicted text as a string. This process allows the Transformer model to generate a response based on the input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDrWzX2IGB-9"
      },
      "outputs": [],
      "source": [
        "def predict_text(input_text, transformer, tokenizer, max_length=10):\n",
        "    \"\"\"\n",
        "    Function to predict the response from the Transformer model for a given input text.\n",
        "\n",
        "    Parameters:\n",
        "    input_text (str): The input string to predict.\n",
        "    transformer (tf.keras.Model): The trained Transformer model.\n",
        "    tokenizer (Tokenizer): The tokenizer used for training.\n",
        "    max_length (int): The maximum length for padding sequences.\n",
        "\n",
        "    Returns:\n",
        "    str: The predicted text output.\n",
        "    \"\"\"\n",
        "    # Step 1: Tokenize the input text\n",
        "    input_sequence = tokenizer.texts_to_sequences([input_text])\n",
        "\n",
        "    # Step 2: Pad the sequence to match the model's input size\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=max_length, padding='post')\n",
        "\n",
        "    # Step 3: Make prediction using the Transformer model\n",
        "    predicted_output = transformer.predict(input_padded)\n",
        "\n",
        "    # Step 4: Convert predicted output back to text\n",
        "    predicted_sequence = np.argmax(predicted_output, axis=-1)  # Get the index of the highest probability for each token\n",
        "    predicted_text = sequences_to_text(predicted_sequence, tokenizer)\n",
        "\n",
        "    return predicted_text[0]  # Return the first element as a single string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDZRPRoHoNT",
        "outputId": "30e41b18-aa54-4489-969b-ae7d4b80b1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "Predicted Response: what is ? capital france france\n"
          ]
        }
      ],
      "source": [
        "# Test the function with the example input\n",
        "input_text = \"What is the capital of France?\"\n",
        "predicted_response = predict_text(input_text, transformer, tokenizer)\n",
        "print(\"Predicted Response:\", predicted_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP3Lus1XbijG"
      },
      "source": [
        "The provided code defines a function, `push_model_to_huggingface`, to upload a TensorFlow Transformer model to the Hugging Face Hub. It authenticates using a token, creates a repository, and uploads the model, configuration file, and optionally, a tokenizer. The function also generates and uploads a README file containing a model card with YAML metadata, describing the model’s details, usage, and limitations. It handles potential exceptions and returns success or error messages accordingly. After uploading, it cleans up temporary files created during the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqz5LYn9cGlq"
      },
      "source": [
        "## Save to HuggingFace cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEjvr43eS3Ns"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfFolder, create_repo, upload_file\n",
        "from transformers import AutoConfig\n",
        "import os\n",
        "import json\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6anqpKjnS1f1"
      },
      "outputs": [],
      "source": [
        "def push_model_to_huggingface(token, account_name, transformer_model, model_name, tokenizer=None):\n",
        "    \"\"\"\n",
        "    Push a TensorFlow Transformer model to Hugging Face Hub, including config.json and tokenizer (if available),\n",
        "    and add a model card with YAML metadata.\n",
        "\n",
        "    Parameters:\n",
        "    token (str): Hugging Face token for authentication.\n",
        "    account_name (str): Hugging Face account username.\n",
        "    transformer_model (tf.keras.Model): Trained Transformer model to upload.\n",
        "    model_name (str): Desired model name on Hugging Face Hub.\n",
        "    tokenizer (Tokenizer, optional): The tokenizer used for training the model.\n",
        "\n",
        "    Returns:\n",
        "    str: Success or error statement based on the result of the upload.\n",
        "    \"\"\"\n",
        "    # Authenticate with Hugging Face Hub\n",
        "    HfFolder.save_token(token)\n",
        "\n",
        "    # Create repository name in \"account_name/model_name\" format\n",
        "    repo_id = f\"{account_name}/{model_name}\"\n",
        "\n",
        "    try:\n",
        "        # Create the repository on Hugging Face Hub\n",
        "        create_repo(repo_id, exist_ok=True)\n",
        "\n",
        "        # Save the model locally with a .keras extension\n",
        "        model_save_path = \"./tmp_model.keras\"\n",
        "        transformer_model.save(model_save_path)\n",
        "\n",
        "        # Extract model configuration and save to config.json\n",
        "        config = transformer_model.get_config()  # Get the model configuration as a dictionary\n",
        "        config_save_path = \"./config.json\"\n",
        "        with open(config_save_path, \"w\") as config_file:\n",
        "            json.dump(config, config_file)\n",
        "\n",
        "        # Upload the saved model file to Hugging Face Hub\n",
        "        upload_file(\n",
        "            path_or_fileobj=model_save_path,\n",
        "            path_in_repo=model_name + \".keras\",\n",
        "            repo_id=repo_id,\n",
        "            repo_type=\"model\"\n",
        "        )\n",
        "\n",
        "        # Upload the config.json to Hugging Face Hub\n",
        "        upload_file(\n",
        "            path_or_fileobj=config_save_path,\n",
        "            path_in_repo=\"config.json\",\n",
        "            repo_id=repo_id,\n",
        "            repo_type=\"model\"\n",
        "        )\n",
        "\n",
        "        # Optionally, upload the tokenizer if provided\n",
        "        if tokenizer:\n",
        "            # Save tokenizer configuration and vocabulary manually\n",
        "            tokenizer_config_path = \"./tokenizer_config.json\"\n",
        "            vocab_path = \"./vocab.pkl\"\n",
        "\n",
        "            # Save tokenizer configuration to JSON\n",
        "            tokenizer_config = {\n",
        "                \"word_index\": tokenizer.word_index,\n",
        "                \"index_word\": tokenizer.index_word,\n",
        "                \"num_words\": tokenizer.num_words,\n",
        "                \"filters\": tokenizer.filters,\n",
        "                \"lower\": tokenizer.lower,\n",
        "                \"split\": tokenizer.split,\n",
        "                \"char_level\": tokenizer.char_level\n",
        "            }\n",
        "            with open(tokenizer_config_path, \"w\") as f:\n",
        "                json.dump(tokenizer_config, f)\n",
        "\n",
        "            # Save tokenizer word index to a pickle file\n",
        "            with open(vocab_path, \"wb\") as f:\n",
        "                pickle.dump(tokenizer.word_index, f)\n",
        "\n",
        "            # Upload tokenizer files to Hugging Face Hub\n",
        "            upload_file(\n",
        "                path_or_fileobj=tokenizer_config_path,\n",
        "                path_in_repo=\"tokenizer_config.json\",\n",
        "                repo_id=repo_id,\n",
        "                repo_type=\"model\"\n",
        "            )\n",
        "            upload_file(\n",
        "                path_or_fileobj=vocab_path,\n",
        "                path_in_repo=\"vocab.pkl\",\n",
        "                repo_id=repo_id,\n",
        "                repo_type=\"model\"\n",
        "            )\n",
        "\n",
        "        # Define YAML metadata for the model card\n",
        "        yaml_metadata = \"\"\"\n",
        "        ---\n",
        "        language: en\n",
        "        license: apache-2.0\n",
        "        tags:\n",
        "          - question-answering\n",
        "          - transformer\n",
        "          - educational\n",
        "        datasets:\n",
        "          - custom\n",
        "        metrics:\n",
        "          - accuracy\n",
        "        ---\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Define a template for the model card with YAML metadata\n",
        "        model_card_content = \"\"\"\n",
        "        # Model Card for {model_name}\n",
        "\n",
        "        ## Model Details\n",
        "        This is a Transformer model trained for demonstration purposes. The model was trained using a dataset of question-answer pairs and is designed to understand simple natural language questions.\n",
        "\n",
        "        ## Intended Use\n",
        "        This model is intended for educational purposes and demonstrations. It is not suitable for production use or handling sensitive data.\n",
        "\n",
        "        ## Limitations\n",
        "        The model may not perform well on out-of-domain questions or complex natural language understanding tasks.\n",
        "\n",
        "        ## Training Data\n",
        "        The model was trained on a small dataset of questions and answers created for this demonstration.\n",
        "        \"\"\".format(model_name=model_name)\n",
        "\n",
        "        # Combine YAML metadata and model card content\n",
        "        full_model_card_content = yaml_metadata + model_card_content\n",
        "\n",
        "        # Save the model card content to a local README.md file\n",
        "        readme_path = \"./README.md\"\n",
        "        with open(readme_path, \"w\") as f:\n",
        "            f.write(full_model_card_content)\n",
        "\n",
        "        # Upload the README.md (model card) to Hugging Face Hub\n",
        "        upload_file(\n",
        "            path_or_fileobj=readme_path,\n",
        "            path_in_repo=\"README.md\",\n",
        "            repo_id=repo_id,\n",
        "            repo_type=\"model\"\n",
        "        )\n",
        "\n",
        "        # Clean up local saved files after uploading\n",
        "        os.remove(model_save_path)\n",
        "        os.remove(config_save_path)\n",
        "        os.remove(readme_path)\n",
        "        if tokenizer:\n",
        "            os.remove(tokenizer_config_path)\n",
        "            os.remove(vocab_path)\n",
        "\n",
        "        return \"Model, config, tokenizer, and model card pushed successfully to Hugging Face Hub with YAML metadata.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error occurred while pushing the model: {str(e)}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8V1g-KXOyqN"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "26a96443546c49508b4c8ddd24b56125",
            "528250bae8e94fb780d2ae34c4eebdda",
            "893c956764f844738543d5ba4175ede0",
            "703fbee4070e49468859db98451aebdb",
            "e0c589fdc115427391db491eec1fd4c6",
            "9b84eb06bf9541828f37f6c6bceaceab",
            "12883088e8084bec8382350e987c2efc",
            "f244a1bfaefb4917b21f500e6d65fe99",
            "a87d0fbca9d24f3c99941ab7501fc893",
            "f76c5487643c4c4b9ced2fc4390372ba",
            "164beee45cfd434bb00d31456991feb2",
            "ccdfab3d761045dabb4f9f51d411dc2f",
            "8b8903402d104ae5b9abfe506a7f05cd",
            "eaf4ffcb687d45e6a2a3f4d3d3364ecf",
            "a870e9a7f52043beaadf3125b66f39bb",
            "b37778af8caf44298b42a385189a8820",
            "7c0b45b13db74a3cacb0b197f67cf8a1",
            "dc25ffd442514a7f8228c892240456c7",
            "9ea1b42a94914685a40e8362a3dd6904",
            "989b82ceb1794f438cda3ff8b08e57c4",
            "984cb805510744648f9b876b381f2ed4",
            "97ac7d8d4d15440d95eeb8f6f7d1656b"
          ]
        },
        "id": "OV4hu9nsOvO6",
        "outputId": "3d5f57a7-ecaa-4079-c61d-c2cf0f5c33ac"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26a96443546c49508b4c8ddd24b56125",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tmp_model.keras:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccdfab3d761045dabb4f9f51d411dc2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.pkl:   0%|          | 0.00/258 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py:3664: UserWarning: Warnings while validating metadata in README.md:\n",
            "- empty or missing yaml metadata in repo card\n",
            "  warnings.warn(f\"Warnings while validating metadata in README.md:\\n{message}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, config, tokenizer, and model card pushed successfully to Hugging Face Hub with YAML metadata.\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "huggingface_token = HF_TOKEN\n",
        "account_name = \"eagle0504\"\n",
        "model_name = \"pretrained_transformer_model_v5\"\n",
        "\n",
        "# Call the function to push the model\n",
        "# result = push_model_to_huggingface(huggingface_token, account_name, transformer, model_name)\n",
        "result = push_model_to_huggingface(huggingface_token, account_name, transformer, model_name, tokenizer)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlGVL7meboWH"
      },
      "source": [
        "The code downloads a pre-trained Transformer model and its tokenizer from the Hugging Face Hub using specified repository and model names. It loads the model into TensorFlow, compiles it for further training, and retrieves tokenizer configuration and vocabulary files. The tokenizer is recreated using TensorFlow's `Tokenizer` class, configured with the loaded settings and vocabulary. After setting up the model and tokenizer, it cleans up by removing the downloaded configuration and vocabulary files. The model is then ready for further training or inference tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mndBiwNacJgl"
      },
      "source": [
        "## Load model from cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "970c0ab3ece043d7aa934f4048c8be14",
            "7cc3ff73ff4d44c8a4fcda12f8c689ec",
            "ef8637bc36bd4ab384a6b826e19472af",
            "4d354614c165404f913a755e25add9ae",
            "d6cc72d59a434e2dac8d07e4f1af26a4",
            "681c5f702a3f4ffeab48ea74b746e164",
            "8896d9ec31a0496d8c48962fc08a561e",
            "bdcd71695b124c1e8c29dbacde3e7458",
            "8415a0af51924324ae69c612f1698ca9",
            "498fb6bb74324e4cb4d1773cf7a24138",
            "e6d101ac418b44129e32fb4cd0475af5",
            "cf55983301d24af6a5af6d6e162a4153",
            "591a4068736943e1a3464d3a5a42e88b",
            "65c45eff860f40859b3875ff912d5d47",
            "c70db52cacd84b3e976b02ef063a35dc",
            "2ee812550d614861bdcdfc68868f9b39",
            "16ef628f99df44d08a2d0c86fb86f99c",
            "7b1ac917777644fe9241613d129b2c10",
            "ec9ab4c8855b45e99d14a5af24e04e3f",
            "d57be254ec3f4002a688e87ea9a45131",
            "d461fd1e14814180bdb0ce3b5a1bb3d4",
            "b0cb57e20b0c440fa5c1736a59c6a851",
            "6dfacaf71c8e487284b83971fa1996a2",
            "9114388ca2bb4e8e81f0123dd65df0b2",
            "05e7f67fd7dd4a97b26a058f39d88e49",
            "d8a232c63b4d43438eca71f3de1024cc",
            "1f947923f8144462a33149012f8f2f5a",
            "5b9caa25e9874d229fe03a2669b766c9",
            "9a6a653a8acf4ebf9beb1c31d9baf15a",
            "fd3b196200ed441ebdab25ca7c2b9572",
            "db5ea2601c33457087dbdd87e985545d",
            "f57b44860a84461d863bc48df7232012",
            "1f7c9d9cef844787bd9a5d62dde6b4ad"
          ]
        },
        "id": "XIaziHzZQcBD",
        "outputId": "0f11628d-5d9f-49ff-8a74-eeee3e3146bb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "970c0ab3ece043d7aa934f4048c8be14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pretrained_transformer_model_v5.keras:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf55983301d24af6a5af6d6e162a4153",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/812 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dfacaf71c8e487284b83971fa1996a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.pkl:   0%|          | 0.00/258 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "# Define the Hugging Face model repository path\n",
        "model_repo_url = f\"{account_name}/{model_name}\"\n",
        "\n",
        "# Step 1: Download the model file from Hugging Face\n",
        "model_filename = f\"{model_name}.keras\"\n",
        "model_file_path = hf_hub_download(repo_id=model_repo_url, filename=model_filename, use_auth_token=huggingface_token)\n",
        "\n",
        "# Step 2: Load the pre-trained model from the downloaded file\n",
        "pre_trained_transformer = tf.keras.models.load_model(model_file_path, custom_objects={\"TransformerModel\": TransformerModel})\n",
        "\n",
        "# Step 3: Compile the model to prepare for further training\n",
        "pre_trained_transformer.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Reload the tokenizer (if used) by downloading tokenizer files from Hugging Face\n",
        "tokenizer_config_path = hf_hub_download(repo_id=model_repo_url, filename=\"tokenizer_config.json\", use_auth_token=huggingface_token)\n",
        "vocab_path = hf_hub_download(repo_id=model_repo_url, filename=\"vocab.pkl\", use_auth_token=huggingface_token)\n",
        "\n",
        "# Load the tokenizer configuration from the downloaded file\n",
        "with open(tokenizer_config_path, \"r\") as f:\n",
        "    tokenizer_config = json.load(f)\n",
        "\n",
        "# Recreate the tokenizer using TensorFlow's Tokenizer class\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(\n",
        "    num_words=tokenizer_config.get(\"num_words\"),\n",
        "    filters=tokenizer_config.get(\"filters\"),\n",
        "    lower=tokenizer_config.get(\"lower\"),\n",
        "    split=tokenizer_config.get(\"split\"),\n",
        "    char_level=tokenizer_config.get(\"char_level\")\n",
        ")\n",
        "tokenizer.word_index = tokenizer_config.get(\"word_index\")\n",
        "tokenizer.index_word = tokenizer_config.get(\"index_word\")\n",
        "\n",
        "# Load the vocabulary from the pickle file\n",
        "with open(vocab_path, \"rb\") as f:\n",
        "    tokenizer.word_index = pickle.load(f)\n",
        "\n",
        "# Clean up downloaded files\n",
        "os.remove(tokenizer_config_path)\n",
        "os.remove(vocab_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ2Tc_ozcMOC"
      },
      "source": [
        "### Training again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN3WSuu3SHxI",
        "outputId": "6b707393-d4e2-4fa1-9e0f-0cc239a7d8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7375 - loss: 2.4196\n",
            "Epoch 2/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 3/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 4/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7375 - loss: 2.4196\n",
            "Epoch 5/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 6/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7375 - loss: 2.4253\n",
            "Epoch 7/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7375 - loss: 2.5372\n",
            "Epoch 8/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 9/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 10/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7375 - loss: 2.4219\n",
            "Epoch 11/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 12/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7375 - loss: 2.4206\n",
            "Epoch 13/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 14/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.5389\n",
            "Epoch 15/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 16/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 17/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7375 - loss: 2.4199\n",
            "Epoch 18/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7375 - loss: 2.4197\n",
            "Epoch 19/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7375 - loss: 2.4206\n",
            "Epoch 20/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7375 - loss: 2.5346\n",
            "Epoch 21/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7375 - loss: 2.4238\n",
            "Epoch 22/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 23/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7375 - loss: 2.5360\n",
            "Epoch 24/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 25/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 26/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 27/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7375 - loss: 2.4214\n",
            "Epoch 28/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7375 - loss: 2.4196\n",
            "Epoch 29/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7375 - loss: 2.5345\n",
            "Epoch 30/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 31/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 32/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7375 - loss: 2.4197\n",
            "Epoch 33/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4198\n",
            "Epoch 34/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7375 - loss: 2.4198\n",
            "Epoch 35/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 36/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7375 - loss: 2.4216\n",
            "Epoch 37/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7375 - loss: 2.4198\n",
            "Epoch 38/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7375 - loss: 2.4221\n",
            "Epoch 39/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4244\n",
            "Epoch 40/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 41/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7375 - loss: 2.4238\n",
            "Epoch 42/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7500 - loss: 2.4198\n",
            "Epoch 43/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7375 - loss: 2.4202\n",
            "Epoch 44/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 45/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7375 - loss: 2.4235\n",
            "Epoch 46/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 47/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7375 - loss: 2.4214\n",
            "Epoch 48/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 49/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7375 - loss: 2.4198\n",
            "Epoch 50/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 51/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 52/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 53/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 54/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7375 - loss: 2.4201\n",
            "Epoch 55/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 56/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 57/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 58/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 59/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7375 - loss: 2.4221\n",
            "Epoch 60/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 61/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7375 - loss: 2.4214\n",
            "Epoch 62/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 63/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7375 - loss: 2.4210\n",
            "Epoch 64/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7375 - loss: 2.4215\n",
            "Epoch 65/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4222\n",
            "Epoch 66/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7375 - loss: 2.4200\n",
            "Epoch 67/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7375 - loss: 2.4264\n",
            "Epoch 68/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7375 - loss: 2.4207\n",
            "Epoch 69/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 70/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 71/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7375 - loss: 2.4228\n",
            "Epoch 72/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7375 - loss: 2.4207\n",
            "Epoch 73/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7375 - loss: 2.4217\n",
            "Epoch 74/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7375 - loss: 2.4232\n",
            "Epoch 75/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 76/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7375 - loss: 2.4191\n",
            "Epoch 77/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.7375 - loss: 2.4199\n",
            "Epoch 78/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.7375 - loss: 2.4211\n",
            "Epoch 79/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7375 - loss: 2.4191\n",
            "Epoch 80/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7375 - loss: 2.4218\n",
            "Epoch 81/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7375 - loss: 2.4208\n",
            "Epoch 82/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7375 - loss: 2.4212\n",
            "Epoch 83/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 84/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 85/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 86/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7375 - loss: 2.4201\n",
            "Epoch 87/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7375 - loss: 2.4210\n",
            "Epoch 88/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 89/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.7375 - loss: 2.4211\n",
            "Epoch 90/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 91/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 92/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 93/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 94/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 95/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7375 - loss: 2.4230\n",
            "Epoch 96/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4211\n",
            "Epoch 97/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7375 - loss: 2.4230\n",
            "Epoch 98/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7375 - loss: 2.5345\n",
            "Epoch 99/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 100/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 101/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7375 - loss: 2.4201\n",
            "Epoch 102/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 103/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 104/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 105/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 106/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7375 - loss: 2.4205\n",
            "Epoch 107/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7375 - loss: 2.4197\n",
            "Epoch 108/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4714\n",
            "Epoch 109/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.4198\n",
            "Epoch 110/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7375 - loss: 2.4192\n",
            "Epoch 111/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7375 - loss: 2.4211\n",
            "Epoch 112/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7375 - loss: 2.4191\n",
            "Epoch 113/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 114/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7375 - loss: 2.4193\n",
            "Epoch 115/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7375 - loss: 2.4201\n",
            "Epoch 116/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7375 - loss: 2.4191\n",
            "Epoch 117/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7375 - loss: 2.4194\n",
            "Epoch 118/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7375 - loss: 2.4195\n",
            "Epoch 119/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7375 - loss: 2.4260\n",
            "Epoch 120/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7375 - loss: 2.4207\n",
            "Epoch 121/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7125 - loss: 2.9997\n",
            "Epoch 122/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 3.3461\n",
            "Epoch 123/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5750 - loss: 5.3009\n",
            "Epoch 124/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.5125 - loss: 5.6442\n",
            "Epoch 125/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.4500 - loss: 6.3336\n",
            "Epoch 126/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.4125 - loss: 5.8778\n",
            "Epoch 127/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4125 - loss: 6.4498\n",
            "Epoch 128/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.3625 - loss: 6.6790\n",
            "Epoch 129/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3500 - loss: 6.3415\n",
            "Epoch 130/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.3125 - loss: 6.7939\n",
            "Epoch 131/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3375 - loss: 6.9093\n",
            "Epoch 132/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.3250 - loss: 6.8364\n",
            "Epoch 133/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2875 - loss: 6.8423\n",
            "Epoch 134/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.3250 - loss: 6.7470\n",
            "Epoch 135/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2750 - loss: 7.0320\n",
            "Epoch 136/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.3125 - loss: 6.8572\n",
            "Epoch 137/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.2875 - loss: 6.8589\n",
            "Epoch 138/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2875 - loss: 6.7970\n",
            "Epoch 139/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.2875 - loss: 6.9085\n",
            "Epoch 140/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.2750 - loss: 6.9113\n",
            "Epoch 141/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2875 - loss: 6.7933\n",
            "Epoch 142/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.3000 - loss: 6.9113\n",
            "Epoch 143/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2625 - loss: 6.7989\n",
            "Epoch 144/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2500 - loss: 6.9091\n",
            "Epoch 145/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2875 - loss: 6.9100\n",
            "Epoch 146/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3000 - loss: 6.7934\n",
            "Epoch 147/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2625 - loss: 6.9092\n",
            "Epoch 148/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2500 - loss: 7.1399\n",
            "Epoch 149/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.2625 - loss: 6.9138\n",
            "Epoch 150/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2500 - loss: 6.9126\n",
            "Epoch 151/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.2625 - loss: 7.0237\n",
            "Epoch 152/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2625 - loss: 6.7996\n",
            "Epoch 153/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2500 - loss: 6.9087\n",
            "Epoch 154/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.2500 - loss: 6.9116\n",
            "Epoch 155/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2875 - loss: 6.9119\n",
            "Epoch 156/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.2875 - loss: 6.9111\n",
            "Epoch 157/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.2625 - loss: 6.9162\n",
            "Epoch 158/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2875 - loss: 6.9114\n",
            "Epoch 159/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2625 - loss: 7.0244\n",
            "Epoch 160/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.2625 - loss: 6.8011\n",
            "Epoch 161/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2750 - loss: 6.9084\n",
            "Epoch 162/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2750 - loss: 6.8422\n",
            "Epoch 163/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.2875 - loss: 6.8033\n",
            "Epoch 164/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.3125 - loss: 6.9117\n",
            "Epoch 165/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.3000 - loss: 6.7949\n",
            "Epoch 166/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.2875 - loss: 6.9102\n",
            "Epoch 167/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.3125 - loss: 6.6792\n",
            "Epoch 168/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.3375 - loss: 6.7209\n",
            "Epoch 169/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.3125 - loss: 6.7389\n",
            "Epoch 170/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.3500 - loss: 6.3345\n",
            "Epoch 171/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3500 - loss: 6.6090\n",
            "Epoch 172/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.3750 - loss: 5.9906\n",
            "Epoch 173/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.4250 - loss: 5.6450\n",
            "Epoch 174/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.4250 - loss: 5.5282\n",
            "Epoch 175/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.4875 - loss: 5.0720\n",
            "Epoch 176/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5500 - loss: 4.7252\n",
            "Epoch 177/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.5375 - loss: 4.7296\n",
            "Epoch 178/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5500 - loss: 4.2812\n",
            "Epoch 179/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6375 - loss: 4.3836\n",
            "Epoch 180/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5875 - loss: 4.0385\n",
            "Epoch 181/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6625 - loss: 3.4642\n",
            "Epoch 182/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.7000 - loss: 2.8857\n",
            "Epoch 183/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.6875 - loss: 3.1176\n",
            "Epoch 184/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7125 - loss: 2.6599\n",
            "Epoch 185/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.6911\n",
            "Epoch 186/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.7375 - loss: 2.5520\n",
            "Epoch 187/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5502\n",
            "Epoch 188/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5485\n",
            "Epoch 189/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7250 - loss: 2.6637\n",
            "Epoch 190/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7250 - loss: 2.5460\n",
            "Epoch 191/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5414\n",
            "Epoch 192/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.6984\n",
            "Epoch 193/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7250 - loss: 2.5498\n",
            "Epoch 194/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7250 - loss: 2.5434\n",
            "Epoch 195/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5520\n",
            "Epoch 196/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5428\n",
            "Epoch 197/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7125 - loss: 2.6580\n",
            "Epoch 198/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5391\n",
            "Epoch 199/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5446\n",
            "Epoch 200/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5372\n",
            "Epoch 201/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.6566\n",
            "Epoch 202/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5366\n",
            "Epoch 203/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5365\n",
            "Epoch 204/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5414\n",
            "Epoch 205/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5444\n",
            "Epoch 206/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5375\n",
            "Epoch 207/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 208/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 209/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.6530\n",
            "Epoch 210/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5397\n",
            "Epoch 211/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5371\n",
            "Epoch 212/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5390\n",
            "Epoch 213/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.7250 - loss: 2.5364\n",
            "Epoch 214/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5369\n",
            "Epoch 215/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 216/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5395\n",
            "Epoch 217/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 218/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7250 - loss: 2.5793\n",
            "Epoch 219/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5378\n",
            "Epoch 220/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5394\n",
            "Epoch 221/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 222/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 223/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 224/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 225/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5371\n",
            "Epoch 226/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5351\n",
            "Epoch 227/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 228/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 229/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5373\n",
            "Epoch 230/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 231/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 232/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 233/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 234/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5351\n",
            "Epoch 235/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 236/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 237/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 238/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 239/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7250 - loss: 2.5382\n",
            "Epoch 240/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 241/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 242/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 243/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 244/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 245/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 246/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5375\n",
            "Epoch 247/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 248/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 249/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 250/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 251/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5369\n",
            "Epoch 252/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 253/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 254/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 255/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 256/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 257/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 258/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 259/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 260/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 261/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 262/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 263/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 264/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 265/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 266/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 267/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 268/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 269/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 270/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 271/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 272/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 273/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5387\n",
            "Epoch 274/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 275/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 276/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 277/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 278/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 279/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 280/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 281/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 282/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.6504\n",
            "Epoch 283/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 284/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 285/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 286/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 287/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 288/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 289/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.6568\n",
            "Epoch 290/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 291/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 292/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7250 - loss: 2.5379\n",
            "Epoch 293/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 294/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5369\n",
            "Epoch 295/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 296/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 297/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 298/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 299/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 300/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 301/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 302/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 303/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 304/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 305/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 306/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 307/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 308/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7250 - loss: 2.5363\n",
            "Epoch 309/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 310/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 311/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 312/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 313/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 314/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 315/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 316/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 317/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5370\n",
            "Epoch 318/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 319/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5411\n",
            "Epoch 320/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 321/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 322/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 323/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 324/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 325/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 326/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5365\n",
            "Epoch 327/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 328/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 329/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 330/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 331/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 332/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7375 - loss: 2.5352\n",
            "Epoch 333/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 334/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 335/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7250 - loss: 2.5363\n",
            "Epoch 336/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 337/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 338/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 339/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5854\n",
            "Epoch 340/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 341/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 342/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 343/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 344/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 345/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 346/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 347/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 348/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 349/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 350/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5368\n",
            "Epoch 351/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 352/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 353/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 354/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 355/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 356/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 357/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 358/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 359/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 360/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 361/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 362/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 363/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 364/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 365/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 366/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5367\n",
            "Epoch 367/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 368/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 369/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 370/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 371/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 372/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 373/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 374/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 375/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 376/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 377/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 378/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5358\n",
            "Epoch 379/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 380/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 381/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 382/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 383/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 384/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 385/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 386/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5365\n",
            "Epoch 387/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5398\n",
            "Epoch 388/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 389/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 390/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 391/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5378\n",
            "Epoch 392/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 393/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 394/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 395/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7250 - loss: 2.5378\n",
            "Epoch 396/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 397/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 398/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7375 - loss: 2.5340\n",
            "Epoch 399/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 400/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 401/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 402/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 403/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 404/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 405/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 406/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 407/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 408/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5376\n",
            "Epoch 409/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 410/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 411/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5410\n",
            "Epoch 412/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5358\n",
            "Epoch 413/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5351\n",
            "Epoch 414/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5364\n",
            "Epoch 415/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 416/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 417/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5422\n",
            "Epoch 418/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 419/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5443\n",
            "Epoch 420/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5426\n",
            "Epoch 421/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5384\n",
            "Epoch 422/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5643\n",
            "Epoch 423/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 424/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5950\n",
            "Epoch 425/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5393\n",
            "Epoch 426/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5398\n",
            "Epoch 427/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5964\n",
            "Epoch 428/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7375 - loss: 2.5349\n",
            "Epoch 429/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7250 - loss: 2.5365\n",
            "Epoch 430/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5429\n",
            "Epoch 431/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5364\n",
            "Epoch 432/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5390\n",
            "Epoch 433/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 434/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5364\n",
            "Epoch 435/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5367\n",
            "Epoch 436/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 437/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 438/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5357\n",
            "Epoch 439/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 440/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 441/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 442/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 443/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5376\n",
            "Epoch 444/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 445/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 446/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7250 - loss: 2.5358\n",
            "Epoch 447/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 448/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5377\n",
            "Epoch 449/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 450/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 451/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5356\n",
            "Epoch 452/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 453/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5366\n",
            "Epoch 454/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 455/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5827\n",
            "Epoch 456/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5970\n",
            "Epoch 457/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 458/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5992\n",
            "Epoch 459/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 460/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 461/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7375 - loss: 2.5341\n",
            "Epoch 462/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 463/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 464/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 465/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 466/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 467/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 468/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 469/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7375 - loss: 2.5357\n",
            "Epoch 470/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 471/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 472/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 473/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 474/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5373\n",
            "Epoch 475/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5805\n",
            "Epoch 476/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 477/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 478/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7250 - loss: 2.5369\n",
            "Epoch 479/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 480/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 481/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 482/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 483/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 484/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 485/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 486/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 487/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 488/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 489/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 490/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 491/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5356\n",
            "Epoch 492/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.7250 - loss: 2.5396\n",
            "Epoch 493/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 494/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 495/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 496/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 497/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 498/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 499/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 500/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 501/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 502/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 503/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 504/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 505/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 506/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5356\n",
            "Epoch 507/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 508/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 509/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 510/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5373\n",
            "Epoch 511/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 512/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 513/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 514/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 515/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 516/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 517/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 518/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 519/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 520/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 521/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7375 - loss: 2.5350\n",
            "Epoch 522/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 523/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 524/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 525/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 526/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 527/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 528/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 529/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 530/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 531/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 532/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 533/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 534/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.6493\n",
            "Epoch 535/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 536/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5368\n",
            "Epoch 537/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5853\n",
            "Epoch 538/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 539/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 540/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 541/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 542/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 543/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 544/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 545/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 546/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 547/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 548/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 549/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 550/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 551/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 552/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 553/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 554/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 555/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 556/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 557/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 558/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 559/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 560/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 561/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 562/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 563/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 564/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 565/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 566/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 567/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 568/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 569/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 570/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 571/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 572/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 573/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 574/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 575/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 576/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5378\n",
            "Epoch 577/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 578/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 579/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 580/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 581/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 582/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 583/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 584/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 585/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 586/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 587/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 588/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 589/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 590/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 591/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 592/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 593/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 594/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 595/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 596/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 597/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 598/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 599/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.6494\n",
            "Epoch 600/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 601/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 602/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5690\n",
            "Epoch 603/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 604/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 605/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 606/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 607/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 608/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 609/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 610/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 611/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 612/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 613/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 614/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 615/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 616/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 617/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 618/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 619/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 620/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 621/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 622/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 623/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 624/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 625/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 626/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 627/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 628/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 629/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 630/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 631/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 632/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 633/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5359\n",
            "Epoch 634/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 635/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5361\n",
            "Epoch 636/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 637/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 638/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 639/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 640/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 641/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5364\n",
            "Epoch 642/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 643/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 644/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 645/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 646/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.6500\n",
            "Epoch 647/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 648/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 649/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 650/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5367\n",
            "Epoch 651/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 652/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 653/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 654/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 655/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 656/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 657/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 658/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 659/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 660/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 661/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 662/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 663/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 664/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5362\n",
            "Epoch 665/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 666/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 667/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 668/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 669/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7250 - loss: 2.5351\n",
            "Epoch 670/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 671/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5358\n",
            "Epoch 672/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 673/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 674/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5384\n",
            "Epoch 675/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5358\n",
            "Epoch 676/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 677/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 678/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 679/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 680/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 681/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 682/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 683/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 684/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 685/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 686/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7375 - loss: 2.5343\n",
            "Epoch 687/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 688/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 689/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 690/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 691/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 692/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 693/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 694/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 695/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5354\n",
            "Epoch 696/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7250 - loss: 2.5367\n",
            "Epoch 697/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 698/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 699/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 700/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.6501\n",
            "Epoch 701/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 702/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 703/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 704/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 705/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 706/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 707/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 708/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 709/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 710/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 711/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 712/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 713/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 714/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 715/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 716/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 717/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 718/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 719/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 720/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 721/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 722/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 723/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 724/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 725/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 726/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 727/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 728/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 729/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 730/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 731/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 732/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 733/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 734/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 735/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 736/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 737/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 738/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 739/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 740/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 741/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 742/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 743/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 744/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 745/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 746/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 747/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 748/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 749/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 750/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 751/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 752/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 753/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 754/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 755/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 756/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 757/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5733\n",
            "Epoch 758/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 759/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 760/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 761/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 762/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 763/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 764/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 765/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 766/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 767/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 768/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 769/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 770/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 771/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 772/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 773/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 774/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 775/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 776/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 777/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 778/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 779/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 780/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 781/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 782/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7375 - loss: 2.5339\n",
            "Epoch 783/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 784/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 785/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 786/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 787/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 788/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 789/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 790/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 791/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.7125 - loss: 2.6491\n",
            "Epoch 792/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 793/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5350\n",
            "Epoch 794/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 795/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 796/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 797/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 798/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 799/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 800/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 801/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 802/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 803/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 804/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 805/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 806/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 807/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 808/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 809/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 810/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 811/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5653\n",
            "Epoch 812/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 813/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 814/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 815/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 816/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 817/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 818/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 819/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 820/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.7250 - loss: 2.5762\n",
            "Epoch 821/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 822/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 823/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 824/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 825/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 826/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 827/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.7250 - loss: 2.6493\n",
            "Epoch 828/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.7250 - loss: 2.6494\n",
            "Epoch 829/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7250 - loss: 2.6493\n",
            "Epoch 830/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 831/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 832/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 833/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 834/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7125 - loss: 2.6492\n",
            "Epoch 835/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.7250 - loss: 2.7641\n",
            "Epoch 836/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 837/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 838/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 839/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 840/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 841/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7125 - loss: 2.6492\n",
            "Epoch 842/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 843/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 844/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7250 - loss: 2.5344\n",
            "Epoch 845/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 846/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 847/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 848/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 849/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 850/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.6494\n",
            "Epoch 851/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.7643\n",
            "Epoch 852/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.6490\n",
            "Epoch 853/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 854/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 855/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 856/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 857/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.7642\n",
            "Epoch 858/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 859/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 860/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 861/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.7250 - loss: 2.6492\n",
            "Epoch 862/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 863/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 864/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 865/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7250 - loss: 2.5371\n",
            "Epoch 866/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 867/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 868/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 869/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 870/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 871/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 872/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 873/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 874/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 875/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 876/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 877/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 878/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 879/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 880/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 881/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 882/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 883/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 884/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.7250 - loss: 2.6491\n",
            "Epoch 885/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 886/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 887/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 888/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 889/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 890/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 891/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 892/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 893/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5383\n",
            "Epoch 894/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 895/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 896/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.6493\n",
            "Epoch 897/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5345\n",
            "Epoch 898/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 899/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7250 - loss: 2.5346\n",
            "Epoch 900/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 901/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 902/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 903/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 904/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 905/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 906/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 907/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7250 - loss: 2.5360\n",
            "Epoch 908/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 909/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 910/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 911/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 912/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5348\n",
            "Epoch 913/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 914/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 915/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 916/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 917/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 918/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 919/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 920/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7250 - loss: 2.5382\n",
            "Epoch 921/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 922/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 923/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7250 - loss: 2.6503\n",
            "Epoch 924/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 925/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 926/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 927/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 928/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 929/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 930/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7250 - loss: 2.6489\n",
            "Epoch 931/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 932/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 933/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 934/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 935/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 936/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5353\n",
            "Epoch 937/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 938/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 939/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 940/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5349\n",
            "Epoch 941/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 942/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5347\n",
            "Epoch 943/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 944/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 945/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 946/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.7375 - loss: 2.5340\n",
            "Epoch 947/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 948/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 949/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 950/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 951/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7250 - loss: 2.5341\n",
            "Epoch 952/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 953/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 954/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 955/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 956/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 957/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 958/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7250 - loss: 2.5972\n",
            "Epoch 959/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 960/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 961/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 962/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 963/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 964/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 965/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 966/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 967/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 968/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 969/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 970/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7250 - loss: 2.5342\n",
            "Epoch 971/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 972/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 973/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 974/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 975/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 976/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 977/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 978/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 979/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 980/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 981/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 982/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 983/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7250 - loss: 2.5355\n",
            "Epoch 984/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.7250 - loss: 2.5376\n",
            "Epoch 985/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 986/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 987/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 988/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7250 - loss: 2.5340\n",
            "Epoch 989/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 990/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 991/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 992/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.7250 - loss: 2.5352\n",
            "Epoch 993/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 994/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 995/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5338\n",
            "Epoch 996/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7250 - loss: 2.5343\n",
            "Epoch 997/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 998/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 999/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.7250 - loss: 2.5339\n",
            "Epoch 1000/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.7250 - loss: 2.5340\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e7465387520>"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 5: Now you can continue training your pre-trained model\n",
        "# Prepare your sample_data and call fit again\n",
        "pre_trained_transformer.fit(sample_data, sample_data, epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WixCvvFXWovR",
        "outputId": "dcc92322-f376-4c7f-f9f5-ec36f7b77e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Predicted Response: what is ? capital ? france\n"
          ]
        }
      ],
      "source": [
        "# Test the function with the example input\n",
        "input_text = \"What is the capital of France?\"\n",
        "predicted_response = predict_text(input_text, pre_trained_transformer, tokenizer)\n",
        "print(\"Predicted Response:\", predicted_response)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e7f67fd7dd4a97b26a058f39d88e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3b196200ed441ebdab25ca7c2b9572",
            "max": 258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db5ea2601c33457087dbdd87e985545d",
            "value": 258
          }
        },
        "12883088e8084bec8382350e987c2efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "164beee45cfd434bb00d31456991feb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16ef628f99df44d08a2d0c86fb86f99c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7c9d9cef844787bd9a5d62dde6b4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f947923f8144462a33149012f8f2f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a96443546c49508b4c8ddd24b56125": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_528250bae8e94fb780d2ae34c4eebdda",
              "IPY_MODEL_893c956764f844738543d5ba4175ede0",
              "IPY_MODEL_703fbee4070e49468859db98451aebdb"
            ],
            "layout": "IPY_MODEL_e0c589fdc115427391db491eec1fd4c6"
          }
        },
        "2ee812550d614861bdcdfc68868f9b39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498fb6bb74324e4cb4d1773cf7a24138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d354614c165404f913a755e25add9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498fb6bb74324e4cb4d1773cf7a24138",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d101ac418b44129e32fb4cd0475af5",
            "value": " 16.4M/16.4M [00:00&lt;00:00, 62.6MB/s]"
          }
        },
        "528250bae8e94fb780d2ae34c4eebdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b84eb06bf9541828f37f6c6bceaceab",
            "placeholder": "​",
            "style": "IPY_MODEL_12883088e8084bec8382350e987c2efc",
            "value": "tmp_model.keras: 100%"
          }
        },
        "591a4068736943e1a3464d3a5a42e88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ef628f99df44d08a2d0c86fb86f99c",
            "placeholder": "​",
            "style": "IPY_MODEL_7b1ac917777644fe9241613d129b2c10",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5b9caa25e9874d229fe03a2669b766c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c45eff860f40859b3875ff912d5d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9ab4c8855b45e99d14a5af24e04e3f",
            "max": 812,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d57be254ec3f4002a688e87ea9a45131",
            "value": 812
          }
        },
        "681c5f702a3f4ffeab48ea74b746e164": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfacaf71c8e487284b83971fa1996a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9114388ca2bb4e8e81f0123dd65df0b2",
              "IPY_MODEL_05e7f67fd7dd4a97b26a058f39d88e49",
              "IPY_MODEL_d8a232c63b4d43438eca71f3de1024cc"
            ],
            "layout": "IPY_MODEL_1f947923f8144462a33149012f8f2f5a"
          }
        },
        "703fbee4070e49468859db98451aebdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76c5487643c4c4b9ced2fc4390372ba",
            "placeholder": "​",
            "style": "IPY_MODEL_164beee45cfd434bb00d31456991feb2",
            "value": " 16.4M/16.4M [00:01&lt;00:00, 30.4MB/s]"
          }
        },
        "7b1ac917777644fe9241613d129b2c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0b45b13db74a3cacb0b197f67cf8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cc3ff73ff4d44c8a4fcda12f8c689ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681c5f702a3f4ffeab48ea74b746e164",
            "placeholder": "​",
            "style": "IPY_MODEL_8896d9ec31a0496d8c48962fc08a561e",
            "value": "pretrained_transformer_model_v5.keras: 100%"
          }
        },
        "8415a0af51924324ae69c612f1698ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8896d9ec31a0496d8c48962fc08a561e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893c956764f844738543d5ba4175ede0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f244a1bfaefb4917b21f500e6d65fe99",
            "max": 16387903,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a87d0fbca9d24f3c99941ab7501fc893",
            "value": 16387903
          }
        },
        "8b8903402d104ae5b9abfe506a7f05cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0b45b13db74a3cacb0b197f67cf8a1",
            "placeholder": "​",
            "style": "IPY_MODEL_dc25ffd442514a7f8228c892240456c7",
            "value": "vocab.pkl: 100%"
          }
        },
        "9114388ca2bb4e8e81f0123dd65df0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b9caa25e9874d229fe03a2669b766c9",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6a653a8acf4ebf9beb1c31d9baf15a",
            "value": "vocab.pkl: 100%"
          }
        },
        "970c0ab3ece043d7aa934f4048c8be14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cc3ff73ff4d44c8a4fcda12f8c689ec",
              "IPY_MODEL_ef8637bc36bd4ab384a6b826e19472af",
              "IPY_MODEL_4d354614c165404f913a755e25add9ae"
            ],
            "layout": "IPY_MODEL_d6cc72d59a434e2dac8d07e4f1af26a4"
          }
        },
        "97ac7d8d4d15440d95eeb8f6f7d1656b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "984cb805510744648f9b876b381f2ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989b82ceb1794f438cda3ff8b08e57c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a6a653a8acf4ebf9beb1c31d9baf15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b84eb06bf9541828f37f6c6bceaceab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea1b42a94914685a40e8362a3dd6904": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a870e9a7f52043beaadf3125b66f39bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984cb805510744648f9b876b381f2ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_97ac7d8d4d15440d95eeb8f6f7d1656b",
            "value": " 258/258 [00:00&lt;00:00, 1.88kB/s]"
          }
        },
        "a87d0fbca9d24f3c99941ab7501fc893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0cb57e20b0c440fa5c1736a59c6a851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b37778af8caf44298b42a385189a8820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdcd71695b124c1e8c29dbacde3e7458": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70db52cacd84b3e976b02ef063a35dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d461fd1e14814180bdb0ce3b5a1bb3d4",
            "placeholder": "​",
            "style": "IPY_MODEL_b0cb57e20b0c440fa5c1736a59c6a851",
            "value": " 812/812 [00:00&lt;00:00, 46.7kB/s]"
          }
        },
        "ccdfab3d761045dabb4f9f51d411dc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b8903402d104ae5b9abfe506a7f05cd",
              "IPY_MODEL_eaf4ffcb687d45e6a2a3f4d3d3364ecf",
              "IPY_MODEL_a870e9a7f52043beaadf3125b66f39bb"
            ],
            "layout": "IPY_MODEL_b37778af8caf44298b42a385189a8820"
          }
        },
        "cf55983301d24af6a5af6d6e162a4153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_591a4068736943e1a3464d3a5a42e88b",
              "IPY_MODEL_65c45eff860f40859b3875ff912d5d47",
              "IPY_MODEL_c70db52cacd84b3e976b02ef063a35dc"
            ],
            "layout": "IPY_MODEL_2ee812550d614861bdcdfc68868f9b39"
          }
        },
        "d461fd1e14814180bdb0ce3b5a1bb3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57be254ec3f4002a688e87ea9a45131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6cc72d59a434e2dac8d07e4f1af26a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a232c63b4d43438eca71f3de1024cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57b44860a84461d863bc48df7232012",
            "placeholder": "​",
            "style": "IPY_MODEL_1f7c9d9cef844787bd9a5d62dde6b4ad",
            "value": " 258/258 [00:00&lt;00:00, 16.3kB/s]"
          }
        },
        "db5ea2601c33457087dbdd87e985545d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc25ffd442514a7f8228c892240456c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c589fdc115427391db491eec1fd4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d101ac418b44129e32fb4cd0475af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf4ffcb687d45e6a2a3f4d3d3364ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea1b42a94914685a40e8362a3dd6904",
            "max": 258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_989b82ceb1794f438cda3ff8b08e57c4",
            "value": 258
          }
        },
        "ec9ab4c8855b45e99d14a5af24e04e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8637bc36bd4ab384a6b826e19472af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdcd71695b124c1e8c29dbacde3e7458",
            "max": 16387903,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8415a0af51924324ae69c612f1698ca9",
            "value": 16387903
          }
        },
        "f244a1bfaefb4917b21f500e6d65fe99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57b44860a84461d863bc48df7232012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76c5487643c4c4b9ced2fc4390372ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3b196200ed441ebdab25ca7c2b9572": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}