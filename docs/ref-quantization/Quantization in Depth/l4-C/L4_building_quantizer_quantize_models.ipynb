{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egZdxulenzjV"
      },
      "source": [
        "# L4-C - Building your own Quantizer: Quantize any Open Source PyTorch Model\n",
        "\n",
        "In this lesson, you will look at the results of open source models compressed using the custom quantizer you built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ2iclSWn05b"
      },
      "source": [
        "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Building your own Quantizer` to follow along with the video.\n",
        "\n",
        "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhROVtAEnyoj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from helper import W8A16LinearLayer, replace_linear_with_target_and_quantize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Lc3_dgn2MZ"
      },
      "source": [
        "## Step 3: Test the Implementation on Various LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShmwEHDSn3ij"
      },
      "source": [
        "### 3.1 - [Salesforce/codegen-350M-mono](https://huggingface.co/Salesforce/codegen-350M-mono)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqB00huPn4et"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_id = \"./models/Salesforce/codegen-350M-mono\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
        "                                    torch_dtype=torch.bfloat16,\n",
        "                                             low_cpu_mem_usage=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANRafQPcn5T8"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "558jfJPen7am"
      },
      "outputs": [],
      "source": [
        "print(pipe(\"def hello_world():\", max_new_tokens=20, do_sample=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6KYMrLpn8T3"
      },
      "outputs": [],
      "source": [
        "print(\"Model before:\\n\\n\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEaNMSsvn9P7"
      },
      "outputs": [],
      "source": [
        "replace_linear_with_target_and_quantize(model,\n",
        "                                        W8A16LinearLayer, [\"lm_head\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYfbEC_Yn-GP"
      },
      "outputs": [],
      "source": [
        "pipe.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNL3bxMun_M8"
      },
      "outputs": [],
      "source": [
        "print(pipe(\"def hello_world():\", max_new_tokens=20,\n",
        "           do_sample=False)[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKpe0ivboBDo"
      },
      "source": [
        "### 3.2 - [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQBC5n07oBiJ"
      },
      "outputs": [],
      "source": [
        "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# you can specify the revision tag if you don't want the timm dependency\n",
        "processor = DetrImageProcessor.from_pretrained(\n",
        "    \"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
        "model = DetrForObjectDetection.from_pretrained(\n",
        "    \"facebook/detr-resnet-50\", revision=\"no_timm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii2Z5ZtnoDZP"
      },
      "outputs": [],
      "source": [
        "previous_memory_footprint = model.get_memory_footprint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7Jm_JSzoEZd"
      },
      "outputs": [],
      "source": [
        "print(\"Footprint of the model in MBs: \",\n",
        "      previous_memory_footprint/1e+6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_02THcxoFcc"
      },
      "outputs": [],
      "source": [
        "img_path = \"dinner_with_friends.png\"\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPWZsWPsoHVI"
      },
      "outputs": [],
      "source": [
        "from helper import plot_results\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "# convert outputs (bounding boxes and class logits) to COCO API\n",
        "# let's only keep detections with score > 0.9\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLXvJ3GNoILL"
      },
      "outputs": [],
      "source": [
        "plot_results(model, image, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f94xpEC7oJEY"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgb_1wdHoJ7i"
      },
      "outputs": [],
      "source": [
        "replace_linear_with_target_and_quantize(model,\n",
        "                                        W8A16LinearLayer,\n",
        "               [\"0\", \"1\", \"2\", \"class_labels_classifier\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiEHM3WmoLD5"
      },
      "outputs": [],
      "source": [
        "### Model after quantization\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUoLiCzhoMqh"
      },
      "source": [
        "- Visualize results after quantization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXisTdNHoOpO"
      },
      "outputs": [],
      "source": [
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "# convert outputs (bounding boxes and class logits) to COCO API\n",
        "# let's only keep detections with score > 0.9\n",
        "target_sizes = torch.tensor([image.size[::-1]])\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ00d7VuoSqG"
      },
      "outputs": [],
      "source": [
        "plot_results(model, image, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzYpteA2oTkH"
      },
      "outputs": [],
      "source": [
        "new_footprint = model.get_memory_footprint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EAGOJAFoUe9"
      },
      "outputs": [],
      "source": [
        "print(\"Footprint of the model in MBs: \",\n",
        "      new_footprint/1e+6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fBigcFvoVou"
      },
      "outputs": [],
      "source": [
        "### Memory saved\n",
        "print(\"Memory saved in MBs: \",\n",
        "      (previous_memory_footprint - new_footprint)/1e+6)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
